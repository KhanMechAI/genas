{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from genotype.genotype import RandomArchitectureGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels, classes):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST('mnist_test', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Setup the RAG model and send info to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final depth:4\n",
      "Number of nodes:7\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. node_id: 0\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAHBCAYAAACMieH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVjVZf7/8dfhHATlsChgICCQJmSm/tTKzNIxdVLU0dxyK79TTpPOOE4zY42alltW02blNO3uZWY2lWaNhmlJLqUt7ha7KIuAICBn+f3hcJJxQ+TwgcPzcV1cHj7r+5y4rnhx3/f7Y3I6nU4BAAAAAC6Ll9EFAAAAAEB9RJgCAAAAgGogTAEAAABANRCmAAAAAKAaCFMAAAAAUA2EKQAAAACoBsIUAAAAAFQDYQoAAAAAqoEwBQAAAADVQJgCAAAAgGogTAEAAABANRCmAAAAAKAaCFMAAAAAUA2EKQAAAACoBsIUAAAAAFQDYQoAAAAAqoEwBQAAAADVQJgCAAAAgGogTAEAAABANRCmAAAAAKAaCFMAAAAAUA2EKQAAAACoBsIUAAAAAFQDYQoAAAAAqoEwBQAAAADVQJgCAAAAgGogTAEAAABANRCmAAAAAKAaCFMAAAAAUA2EKQAAAACoBsIUAAAAAFQDYQoAAAAAqoEwBQAAAADVQJgCAAAAgGogTAEAAABANViMLgCobTlFZVq9K137swpVWGpTgK9F8WEBGt45UsFWH6PLAwAAQD1hcjqdTqOLAGrDnrR8vZR4WJsPZkuSymwO1z5fi5ecknrGhWpij9bqEBVkUJUAAACoLwhTaBCWJSVr3rr9KrXZdbGfeJNJ8rWYNb1/vMZ2janStR999FEdPnxYy5Ytq5liAQAAUC+wZgq1IiYmRv/5z3/cfp9HH31UY8eOrbTtTJDap5LyM0EqfdFvlbZwrBynS13HnNyzQVnLH5bTKZWU2zVv3T4tS0p2e73jx49Xo0aNZLVaXV92u93t9wUAAMCVI0zBo+1Jy9e8dftVUu6ovMNh18md/77geSXlDs1bt1/fpee7uUJp6tSpKioqcn2ZzWa33xMAAABXjjCFWvfWW2+pe/fu+utf/6qmTZsqNjZW69evd+3v2bOn/v73v+vGG29UYGCgfvOb3ygvL0+SlJiYqMjIyErXqxj1+uSTTzR//ny98847slqt6tChg15KPKxS27kjPQE33anC7WvkKC06b42l6fv006uTdUObSN1www366quvXPt+/vln9ejRQ/7+/urTp49ycnIqnZuUlKRu3bopKChIHTp0UGJiYnU/KgAAANRhhCkY4uuvv1ZcXJxycnI0depU3XvvvTp7+d6SJUv0xhtvKDMzUxaLRZMnT77kNe+44w5NmzZNI0eOVFFRkTZ+uV2bD2afd41Uo/Br5NPyehVsf/+cffaSk8p+91H5dxmo6D+/rQkT/6iEhATl5uZKkkaPHq3OnTsrJydHjzzyiBYvXuw6NyMjQwkJCZoxY4by8vL0j3/8Q0OHDlV29pmmFwsWLNCAAQMq3W/RokVq1qyZOnfurPfee69Knx8AAACMR5iCIaKjozVhwgSZzWbdc889Onr0qI4dO+baP27cOLVr105+fn6aM2eOVq1addlriVbvSr/o/qBbx+jkrg9lP1VQaXvJkR2yNGsha7te8vIyy9nqFsXHx+vDDz9UamqqduzYoTlz5sjHx0e33XabBg4c6Dp32bJl6t+/v/r37y8vLy/16dNHXbp00bp16yRJDz/8sD766CPX8ZMnT9ahQ4d0/PhxzZkzR+PHj9eXX355We8TAAAAxiBMwRBhYWGu102aNJEkFRX9MuUuKirK9To6Olrl5eXnTKe7lP1ZhZXan/+vRqExatzqBhVse7fSdntRniwBzSVJpTaH9h89qejoaGVkZCgzM1NNmzaVn59fpfoqpKSk6N1331VQUJDra+vWrTp69Oh5a+jUqZOCg4NlsVjUv39/jRkzRmvWrLms9wkAAABjEKZQJ6Wlpblep6amytvbWyEhIfLz89OpU6dc++x2u2sKnSSZTCbX68JS2yXvE3TrGBXt2SD7yVzXNrO1mWyFx8+6TrlSU1MVERGh8PBwnThxQsXFxZXqqxAVFaVx48YpPz/f9VVcXKyHH364Su/bZDKJpxUAAADUD4Qp1EnLli3T3r17derUKc2cOVPDhg2T2WxWmzZtVFpaqo8//ljl5eWaO3euysrKXOddddVVSk5OlsPhUICv5ZL38W7aQn7X3qqTOz90bWvcqovK8zJV/GOinA67jn6zSXv37tWAAQMUHR2tLl26aNasWTp9+rS2bt2qDz/85dyxY8fqww8/1IYNG2S321VaWqrExESlp59/yuHq1atVVFQkh8OhTz/9VMuWLdOgQYOu4JMDAABAbSFMoU4aN26cxo8fr7CwMJWWlmrhwoWSpMDAQC1atEj33XefIiIi5OfnV6m73/DhwyVJwcHBWvPIWPlYLv0jHnjLKDnKf3nmlLlxgJoPm6nC7e8r/flR+vGTpfroo48UEhIiSVqxYoW+/vprNWvWTI899pjuvvtu17lRUVH64IMPNH/+fIWGhioqKkpPPfWUHI4z0w3nz5+vfv36uY5//vnnFRERoaCgIP3tb3/Tq6++qp49e1b/gwMAAECtMTmZU4Q6pmfPnho7dqzuu+++K7pOTlGZbnli00XXTV2Kj8VLXz3US8FWnyuqBQAAAJ6HkSl4rBCrj3q0CdVZy6gui8kk/SoulCAFAACA8yJMwaNN6tlavhZztc71tZg1sWfrGq4IAAAAnoJpfvB4y5KSNW/dPpWUV326X2NvL03vf63Gdo1xX2EAAACo1y7d7gyo5yoC0bx1+1Vqs+tifz4wmc6MSE3vH0+QAgAAwEUxMoUG47v0fC1KPKxN+888Q+q0/ZcffV+Ll5w6s0ZqYs/Wah8ZZFCVAAAAqC8IU2hQiouLFXF1nKJ6DFfvofeosLRcAb7eig/317BOkTSbAAAAQJURptBgOJ1ODR06VGvXrlWzZs2Uk5NjdEkAAACox+jmhwbj2Wef1YYNG+R0OlVcXKzU1FSjSwIAAEA9RphCg/DTTz/pb3/7m0pKSiRJJpNJGzduNLgqAAAA1GeEKTQI0dHRWr16tXr37q3g4GBJ0rfffmtwVQAAAKjPWDOFBuV3v/udOnTooIkTJ8rpdMrLi78nAAAAoHr4TRINyo4dO3TDDTfIZDIRpAAAAHBFGJlCg1FSUqLg4GDl5eXJ19fX6HIAAABQz/GneTQYe/bs0bXXXkuQAgAAQI0gTKHBqJjiBwAAANQEwhQajB07dqhLly5GlwEAAAAPQZhCg7Fz505GpgAAAFBjaECBBuHkyZMKDw9Xfn6+LBaL0eUAAADAAzAyhQZh165dat++PUEKAAAANYYwhQaBKX4AAACoaYQpNAh08gMAAEBNI0yhQaCTHwAAAGoaDSjg8XJzc3X11VfrxIkT8vLi7wcAAACoGfxmCY+3c+dOde7cmSAFAACAGsVvl/B4TPEDAACAOxCm4PHo5AcAAAB3IEzB49HJDwAAAO5AmIJHy8zMVFlZmaKjo40uBQAAAB6GMAWPVjHFz2QyGV0KAAAAPAxhCh6NKX4AAABwF8IUPBqd/AAAAOAuPLQXHsvpdCo0NFTff/+9wsPDjS4HAAAAHoaRKXis5ORk+fr6EqQAAADgFoQpeCym+AEAAMCdCFPwWDysFwAAAO5EmILHopMfAAAA3IkGFPBIDodDTZs21U8//aTg4GCjywEAAIAHYmQKHungwYMKCQkhSAEAAMBtCFPwSEzxAwAAgLsRpuCR6OQHAAAAdyNMwSPRyQ8AAADuRgMKeJzy8nI1bdpUR48elb+/v9HlAAAAwEMxMgWP8+OPP6ply5YEKQAAALgVYQoehyl+AAAAqA2EKXgcOvkBAACgNhCm4HHo5AcAAIDaQAMKeJTS0lI1a9ZMeXl58vX1NbocAAAAeDBGpuBR9uzZo7i4OIIUAAAA3I4wBY/CeikAAADUFsIUPAqd/AAAAFBbCFPwKIxMAQAAoLbQgAIe4+TJkwoLC1N+fr68vb2NLgcAAAAejpEpeIxvv/1W7du3J0gBAACgVhCm4DGY4gcAAIDaRJiCx+BhvQAAAKhNhCl4DDr5AQAAoDbRgAIeIS8vTzExMTpx4oTMZrPR5QAAAKABYGQKHmHnzp3q1KkTQQoAAAC1hjAFj8AUPwAAANQ2whQ8As0nAAAAUNsIU/AItEUHAABAbSNMod47evSoSkpKFBsba3QpAAAAaEAIU6j3du7cqS5dushkMhldCgAAABoQwhTqPab4AQAAwAiEKdR7dPIDAACAEXhoL+o1p9Op5s2ba/fu3YqIiDC6HAAAADQgjEyhXktJSZG3tzdBCgAAALWOMIV6jSl+AAAAMAphCvUaD+sFAACAUQhTqNfo5AcAAACj0IAC9ZbD4VDTpk115MgRhYSEGF0OAAAAGhhGplBvHTp0SM2aNSNIAQAAwBCEKdRbTPEDAACAkQhTqLd27txJ8wkAAAAYhjCFeouRKQAAABiJBhSol2w2m4KCgpSZmamAgACjywEAAEADxMgU6qW9e/cqMjKSIAUAAADDEKZQLzHFDwAAAEYjTKFeIkwBAADAaIQp1Et08gMAAIDRLEYXAFRFTlGZVu9K1/6sQuWfOq30yNu161RTxRWVKdjqY3R5AAAAaIDo5oc6bU9avl5KPKzNB7MlSWU2h2ufr8VLTkk940I1sUdrdYgKMqhKAAAANESEKdRZy5KSNW/dfpXa7LrYT6nJJPlazJreP15ju8bUWn0AAABo2FgzhTrpTJDap5LyiwcpSXI6pZJyu+at26dlScmXvHZiYqIiIyNrplAAAAA0WIQpXNSKFSvUpUsXWa1WhYeHq1+/ftq6datb77knLV/z1u1XSfmZKX05Hz2rlAUDVJZ5wHVM+YlMpSwYUOm8knKH5q3br+/S891aX4VevXrJZDLJZrPVyv0AAABQtxCmcEHPPPOMpkyZomnTpunYsWNKTU3VxIkT9cEHH7j1vi8lHlapzV5pm5evv/K/WHbJc0ttdi1KPOyu0lyWL19OiAIAAGjgCFM4r4KCAs2cOVMvvfSS7rzzTvn5+cnb21sDBw7UU089JUkqKyvTlClT1KJFC7Vo0UJTpkxRWVmZpF+m0j399NNq3ry5wsPD9eabb0qSkpKSFBYWJrv9l8D0/vvvq3379sopKtPmg9nnTO3zu76XTmf/rNLU789br+1kro6vnq3UZ+/SG5MH6dkXFrn2lZSUaPz48WratKnatm2rHTt2VDo3MzNTQ4cOVWhoqGJjY7Vw4cJLfjaPPfaYnnzyyap9mAAAAPBIhCmc17Zt21RaWqohQ4Zc8Jh58+YpKSlJu3fv1p49e7R9+3bNnTvXtT8rK0sFBQXKyMjQ66+/rkmTJunEiRPq2rWr/Pz8tGnTJtexK1as0OjRo7V6V/p572Xy9lXgzSOU/8XS8+7P+fdTMvuHKPIPS9Ri6DTNfGSGNm7cKEl67LHHdOTIER05ckQbNmzQ4sWLXec5HA4NHDhQHTp0UEZGhjZu3KjnnntOGzZskCRt3bpVQUGVuwROmzZNDzzwgMLCwi7xKQIAAMCTEaZwXrm5uQoJCZHFcuFHkS1fvlwzZ85U8+bNFRoaqlmzZmnp0l/Cjre3t2bOnClvb2/1799fVqtVBw6cWfc0atQorVy5UpJ08uRJrVu3TqNGjdL+rMJK7c/P5t+xn2yF2So5srPSdlthtsrS96ppz/EyWRpJIbGK7znYVcuqVas0ffp0NWvWTFFRUZo8ebLr3B07dig7O1szZ85Uo0aNdPXVV2vChAl6++23JUndu3dXfv4va7B27typL7/8Un/84x8v5+MEAACAByJM4byCg4OVk5Nz0XVBmZmZio6Odn0fHR2tzMzMStc4O4w1adJERUVFkqTRo0drzZo1Kisr05o1a9SpUydFR0ersPTC9zNZvBXYbaTytyzT2fMA7UV58vK1ysuniWtbo8DmysjIcNUZFRVVqc4KKSkpyszMVFBQkOtr/vz5Onbs2Dn3dzgcmjhxop5//vmLhkwAAAA0DIQpnNfNN98sX19frV279oLHtGjRQikpKa7vU1NT1aJFiypdv23btoqOjtb69etdU/wkKcD34iHF2r6PHGXFOnVwm2ub2dpMjtIiOcpOubaVF2QrIiJCkhQeHq60tLRKdVaIiopSbGys8vPzXV8VI2X/q7CwUDt37tTIkSMVFhamG264QZIUGRmpLVu2VOl9AwAAwHMQpnBegYGBmj17tiZNmqS1a9fq1KlTKi8v1/r16zV16lRJZ6bqzZ07V9nZ2crJydHs2bM1duzYKt9j9OjRWrhwob744gsNHz5ckhQfFiAfy4V/LE1eZgV2H63CpPdc2ywBofKJiFf+5sVy2k5LuSna/8UHGjNmjCRpxIgRevzxx3XixAmlp6frhRdecJ174403KiAgQE888YRKSkpkt9v1ww8/nNOkouIzyczM1O7du7V7925X4Nq1a5duuummKr9vAAAAeAbCFC7owQcf1DPPPKO5c+cqNDRUUVFRevHFFzV48GBJ0owZM9SlSxe1b99e119/vTp16qQZM2ZU+fqjRo1SYmKievXqpZCQEEnSsM6XfpiuX9seMlubVtoWMmiqbAXHlf7i3cp8d45mznpUffr0kSTNmjVL0dHRio2NVd++fTVu3DjXeWazWR9++KF2796t2NhYhYSE6L777lNBQYEkacuWLbJarZIkk8mksLAw11doaKgk6aqrrlKjRo2q/L4BAADgGUxO5/82oQaM9bulO/XZvmPntEevCpNJ+nXbq/Ty2C41XxgAAABwFkamUOdM6tlavhZztc71tZg1sWfrGq4IAAAAOBdhCnVOh6ggTe8fr8bel/fj2djbS9P7x6t9ZNClDwYAAACuEGEKdYrdbtdrr72mrW8t0PT+16qxt1km08XPMZmkxt5mTe9/rcZ2jamVOgEAAADWTKFOyM7O1iuvvKJnnnlGeXl5atu2rX788Ud9l56vRYmH9fmBbJkklZ71QF9fi5eckn4VF6qJPVszIgUAAIBaRZiC4b7//nt16tRJZrNZZWVlslgsev755zVx4kTXMblFZVr9Tbr2Hz2pwtJyBfh6Kz7cX8M6RSrY6mNg9QAAAGioCFMwnM1m0+9+9zstXbpUNptNfn5+2rlzp+Lj440uDQAAALgg1kzBcBaLRddee61CQkLk4+Mjs9msuLg4o8sCAAAALspidAHAmjVr9Pzzz2v79u369ttvtW/fPpku1XUCAAAAMBjT/GCo7du3KyEhQRs2bFCnTp2MLgcAAACoMqb5wTDJyckaPHiwXn/9dYIUAAAA6h3CFAxRUFCghIQEPfTQQxo0aJDR5QAAAACXjWl+qHXl5eVKSEhQmzZt9MILL7A+CgAAAPUSYQq1yul06v7771dGRoY++OADWSz0QAEAAED9xG+yqFX/+Mc/tH37dm3ZsoUgBQAAgHqN32ZRa1avXq2FCxdq27Zt8vf3N7ocAAAA4IowzQ+14uuvv9aAAQNogQ4AAACPQTc/uF1ycrKGDBmiN954gyAFAAAAj0GYglvl5+crISFBDz/8sAYOHGh0OQAAAECNYZof3Ka8vFz9+vVT27ZttXDhQqPLAQAAAGoUYQpu4XQ6NWHCBGVlZemDDz6Q2Ww2uiQAAACgRtHND27x5JNPateuXdqyZQtBCgAAAB6JMIUa9+677+rFF1/Utm3bZLVajS4HAAAAcAum+aFGJSUlaeDAgfr000/1//7f/zO6HAAAAMBt6OaHGvPzzz9ryJAhevPNNwlSAAAA8HiEKdSIihbo06ZN04ABA4wuBwAAAHA7pvnhip0+fVr9+vVTu3bt9PzzzxtdDgAAAFArCFO4Ik6nU/fdd5+ys7P1/vvv07kPAAAADQbd/HBFnnjiCX377bf64osvCFIAAABoUAhTqLZVq1Zp0aJFtEAHAABAg8Q0P1TLtm3bNGjQIH322Wfq2LGj0eUAAAAAtY5ufrhsP/30k+6880699dZbBCkAAAA0WIQpXJYTJ04oISFBM2bMUEJCgtHlAAAAAIZhmh+qrKIF+vXXX6/nnnvO6HIAAAAAQxGmUCVOp1P33nuvcnJyaIEOAAAAiG5+qKLHH39cu3fvpgU6AAAA8F+EKVzSO++8o5dffllJSUm0QAcAAAD+i2l+uKivvvpKv/nNb/Sf//xHHTp0MLocAAAAoM6gmx8u6MiRIxo6dKgWL15MkAIAAAD+B2EK51XRAv2RRx5R//79jS4HAAAAqHOY5odznD59Wr/+9a/VsWNHPfvss0aXAwAAANRJhClU4nQ69dvf/lZ5eXlas2YNnfsAAACAC6CbHyqZP3++vvvuO1qgAwAAAJdAmILLypUr9corr2jbtm3y8/MzuhwAAACgTmOaHyRJX375pQYPHqyNGzeqffv2RpcDAAAA1Hl084MOHz6soUOHaunSpQQpAAAAoIoIUw1cXl6eEhISNGvWLN1xxx1GlwMAAADUG0zza8BOnz6tvn37qnPnznr66aeNLgcAAACoVwhTDZTT6dT48eNVUFCg9957j859AAAAwGWim18DNXfuXP3444/avHkzQQoAAACoBsJUA7RixQq99tprSkpKogU6AAAAUE1M82tgtm7dqiFDhmjTpk26/vrrjS4HAAAAqLfo5teAHD58WMOGDdOyZcsIUgAAAMAVIkw1EBUt0B999FH9+te/NrocAAAAoN5jml8DUFZWpr59+6pLly60QAcAAABqCGHKwzmdTt1zzz0qKirS6tWr5eXFYCQAAABQE+jm5+HmzJmjffv2afPmzQQpAAAAoAYRpjzY8uXL9cYbbygpKUlNmjQxuhwAAADAozDNz0Nt2bJFQ4cO1aZNm9SuXTujywEAAAA8DvO+PNChQ4c0fPhwLVu2jCAFAAAAuAlhysPk5uYqISFBs2fPVt++fY0uBwAAAPBYTPPzIGVlZerTp4+6du2qJ5980uhyAAAAAI9GmPIQTqdTd999t06dOqV3332Xzn0AAACAm9HNz0PMnj1bBw4cUGJiIkEKAAAAqAWEKQ+wbNkyvfnmm7RABwAAAGoR0/zquS+++ELDhg2jBToAAABQy5gPVo8dPHhQI0aM0PLlywlSAAAAQC0jTNVTOTk5SkhI0Jw5c9SnTx+jywEAAAAaHKb51UNlZWXq3bu3unXrpieeeMLocgAAAIAGiTBVzzidTo0dO1ZlZWVatWoVnfsAAAAAg9DNr5559NFHdfjwYVqgAwAAAAYjTNUjS5Ys0ZIlS5SUlKTGjRsbXQ4AAADQoDHNr57YvHmzhg8frsTERLVt29bocgAAAIAGj3li9cCBAwc0YsQIrVixgiAFAAAA1BGEqTquogX6vHnz1Lt3b6PLAQAAAPBfTPOrw0pLS9W7d291795dCxYsMLocAAAAAGchTNVRTqdTY8aMUXl5ud555x069wEAAAB1DN386qhZs2bpp59+0ueff06QAgAAAOogwlQdtHjxYi1btowW6AAAAEAdxjS/OiYxMVEjRoygBToAAABQxzF/rA45cOCARo4cqZUrVxKkAAAAgDqOMFVHZGdnKyEhQY8//rhuv/12o8sBAAAAcAlM86sDSktLdfvtt6tHjx6aP3++0eUAAAAAqALClMEcDofGjBkjh8OhlStX0rkPAAAAqCfo5mewWbNmKTk5WZs2bSJIAQAAAPUIYcpAb731llasWKFt27bRAh0AAACoZ5jmZ5DPP/9cd911lxITE3XttdcaXQ4AAACAy8S8MgPs379fd911l1auXEmQAgAAAOopwlQtq2iBvmDBAvXq1cvocgAAAABUE9P8alFpaal69eqlX/3qV5o3b57R5QAAAAC4AoSpWuJwODR69GhJ0ooVK+jcBwAAANRzdPOrJY888ojS0tK0ceNGghQAAADgAQhTteDNN9/U22+/raSkJPn6+hpdDgAAAIAawDQ/N9u0aZNGjRqlzZs3Kz4+3uhyAAAAANQQ5pu50b59+zRq1Ci98847BCkAAADAwxCm3OT48eNKSEjQk08+qZ49expdDgAAAIAaxjS/asgpKtPqXenan1WowlKbAnwtig8L0PDOkQq2+qikpES9evVS7969NWfOHKPLBQAAAOAGhKnLsCctXy8lHtbmg9mSpDKbw7XP1+Ilp6QebUKU8dmbCig/oRUrVshkMhlULQAAAAB3IkxV0bKkZM1bt1+lNrsu/ok5ZbLbNHNQO/1f99aXvG5iYqLGjh2r9PT0GqsVAAAAgPvVqzVTK1asUJcuXWS1WhUeHq5+/fpp69atbr/vmSC1TyXldmV/+KxSFgxQWeYB1/7yE5lKWTDgv9+Z5DR768lPD2lZUrJb63r77bcVFxenwMBANW/eXPfcc48KCwvdek8AAAAAZ9SbMPXMM89oypQpmjZtmo4dO6bU1FRNnDhRH3zwgVvvuyctX/PW7VdJ+S9T+rx8/ZX/xbKLnldS7tC8dfv1XXq+22q75ZZb9OWXX6qgoEA//fSTbDabZsyY4bb7AQAAAPhFvQhTBQUFmjlzpl566SXdeeed8vPzk7e3twYOHKinnnpKklRWVqYpU6aoRYsWatGihaZMmaKysjJJZ6bSRUZG6umnn1bz5s0VHh6uN998U5KUlJSksLAw2e121/3ef/99tW/fXpL0UuJhldrslerxu76XTmf/rNLU789br+1kro6vnq2DTw3XrZ2v16uvvuraV1JSovHjx6tp06Zq27atduzYUenczMxMDR06VKGhoYqNjdXChQsv+LlERUUpJCTE9b3ZbNbhw4cv+XkCAAAAuHL1Ikxt27ZNpaWlGjJkyAWPmTdvnpKSkrR7927t2bNH27dv19y5c137s7KyVFBQoIyMDL3++uuaNGmSTpw4oa5du8rPz0+bNm1yHbtixQqNHj1aOUVl2nww+5w1UiZvXwXePEL5Xyw9by05/35KZv8QRf5hiYIGPaS//32aNm7cKEl67LHHdOTIER05ckQbNmzQ4sWLXec5HA4NHDhQHTp0UEZGhsBDpqQAACAASURBVDZu3KjnnntOGzZskCRt3bpVQUFBle61detWBQYGyt/fX++9956mTJlStQ8VAAAAwBWpF2EqNzdXISEhslgsFzxm+fLlmjlzppo3b67Q0FDNmjVLS5f+Ena8vb01c+ZMeXt7q3///rJarTpw4My6p1GjRmnlypWSpJMnT2rdunUaNWqUVu+6cFMI/479ZCvMVsmRnZW22wqzVZa+V017jpfJ0kiNw1qpyx1DXbWsWrVK06dPV7NmzRQVFaXJkye7zt2xY4eys7M1c+ZMNWrUSFdffbUmTJigt99+W5LUvXt35edXnjbYvXt3FRQUKD09XX/7298UExNThU8UAAAAwJWqF2EqODhYOTk5stlsFzwmMzNT0dHRru+jo6OVmZlZ6Rpnh7EmTZqoqKhIkjR69GitWbNGZWVlWrNmjTp16qTo6Gjtzyqs1P78bCaLtwK7jVT+lmU6e+jKXpQnL1+rvHyaSJJKbQ6V+wYrIyPDVWdUVFSlOiukpKQoMzNTQUFBrq/58+fr2LFjl/yMIiIidMcdd+iuu+665LEAAAAArly9CFM333yzfH19tXbt2gse06JFC6WkpLi+T01NVYsWLap0/bZt2yo6Olrr1693TfGTpMLSC4c3SbK27yNHWbFOHdzm2ma2NpOjtEiOslOubTnHMhURESFJCg8PV1paWqU6K0RFRSk2Nlb5+fmur4qRsqqw2Ww6cuRIlY4FAAAAcGXqRZgKDAzU7NmzNWnSJK1du1anTp1SeXm51q9fr6lTp0o6M1Vv7ty5ys7OVk5OjmbPnq2xY8dW+R6jR4/WwoUL9cUXX2j48OGSpADfC08rlCSTl1mB3UerMOk91zZLQKh8IuKVv3mxnLbTOn38Zx3e8m+NGTNGkjRixAg9/vjjOnHihNLT0/XCCy+4zr3xxhsVEBCgJ554QiUlJbLb7frhhx/OaVJRYfny5UpNTZXT6VRKSoqmT5+u22+/vcrvGQAAAED11YswJUkPPvignnnmGc2dO1ehoaGKiorSiy++qMGDB0uSZsyYoS5duqh9+/a6/vrr1alTp8tqEz5q1CglJiaqV69erg558WEB8rFc/CPya9tDZmvTSttCBk2VreC40l+8Wzlr5mnwvVPUp08fSdKsWbMUHR2t2NhY9e3bV+PGjXOdZzab9eGHH2r37t2KjY1VSEiI7rvvPhUUFEiStmzZIqvV6jp+79696tatm6xWq2655RbFxcVV6hwIAAAAwH1MTuf/9qpDhZyiMt3yxKYLrpuqCh+Ll756qJeCrT41WBkAAAAAo9WbkSkjhFh91KNNqEym6p1vMkm/igslSAEAAAAeiDB1CZN6tpavxVytc30tZk3s2bqGKwIAAABQFxCmLqFDVJCm949XY+/L+6gae3tpev94tY8MuvTBAAAAAOqdi7ergyRpbNcYSdK8dftVarPrYqvMTKYzI1LT+8e7zgMAAADgeWhAcRm+S8/XosTD+vxAtkw680DeCr4WLzl1Zo3UxJ6tGZECAAAAPBxhqhpyi8q0+pt07T96Ugd+TtWOLzfrrxNG675e7Wg2AQAAADQQhKkrdN999+n1119X586d9fXXX8tsrl6zCgAAAAD1Cw0oroDD4dCaNWsknXmA7oIFCwyuCAAAAEBtYWTqCmzfvl29evVScXGxJMnLy0t79uxRu3btDK4MAAAAgLvRze8KfPHFFzp16pR8fX0VGhqqfv36yWq1Gl0WAAAAgFrAyNQVsNvtKisr08qVK7Vlyxa99dZbRpcEAAAAoJawZuoKmM1mNWnSRHFxcdq/f7/R5QAAAACoRYxM1YCcnBxdc801ysvLk8lkMrocAAAAALWAkakaEBISIrPZrOPHjxtdCgAAAIBaQpiqIUz1AwAAABoWwlQNiY+P14EDB4wuAwAAAEAtIUzVEEamAAAAgIaFMFVDGJkCAAAAGhbCVA1hZAoAAABoWGiNXkPKy8vl7++v/Px8+fr6Gl0OAAAAADdjZKqGeHt7KyYmRocPHza6FAAAAAC1gDBVg1g3BQAAADQchKkaxLopAAAAoOEgTNUgRqYAAACAhoMwVYMYmQIAAAAaDrr51aDc3FzFxsaqoKBAJpPJ6HIAAAAAuBEjUzUoODhYvr6+ysrKMroUAAAAAG5GmKphTPUDAAAAGgbCVA2jCQUAAADQMBCmahgjUwAAAEDDQJiqYYxMAQAAAA0DYaqGMTIFAAAANAy0Rq9hNptN/v7+ysvLU+PGjY0uBwAAAICbMDJVwywWi2JjY3Xo0CGjSwEAAADgRoQpN2DdFAAAAOD5CFNuwLopAAAAwPMRptyAkSkAAADA8xGm3CA+Pp6RKQAAAMDD0c3PDfLz8xUVFaXCwkKZTCajywEAAADgBoxMuUFQUJD8/PyUmZlpdCkAAAAA3IQw5SY0oQAAAAA8G2HKTWhCAQAAAHg2wpSbMDIFAAAAeDbClJswMgUAAAB4NsKUmzAyBQAAAHg2WqO7id1ul9VqVW5urpo0aWJ0OQAAAABqGCNTbmI2m9WqVSsdPHjQ6FIAAAAAuAFhyo1YNwUAAAB4LsKUG7FuCgAAAPBchCk3io+PJ0wBAAAAHoow5UZM8wMAAAA8F9383KiwsFDh4eE6efKkvLzIrQAAAIAn4Td8NwoICFBgYKAyMjKMLgUAAABADSNMuRlNKAAAAADPRJhyM9ZNAQAAAJ7JYnQBno6RKQAAANQ1OUVlWr0rXfuzClVYalOAr0XxYQEa3jlSwVYfo8urNwhTbhYfH6+PP/7Y6DIAAAAA7UnL10uJh7X5YLYkqczmcO3ztWTp2f8cVM+4UE3s0VodooKMKrPeYJqfmzEyBQAAgLpgWVKy7no1SZ/tO6Yym6NSkJKk0v9u+3TvMd31apKWJSVX6z4xMTH6z3/+UwMV132EKTdr2bKlcnNzVVRUZHQpAAAAcLO33npL119/vZo0aaKwsDA98MADys/Pr/L5NR1EKq63LClZ89btU0m5XWc/GKk05TulLBig3E//6drmdEo/v/kX/e3xhdUOVDVl1apV6tatm5o0aaKePXsaWsv5EKbczGw2q3Xr1jp48KDRpQAAAMCNnn76aT300EN66qmnVFBQoKSkJKWkpKhPnz46ffq0YXUdOV6keev2q6Tccd79Jm9fFf+wSbb8Y5W2l9ucmrduv75Lr3oYrGnNmjXTlClT9PDDDxtWw8UQpmoBHf0AAAA8W2FhoWbNmqUXXnhBd9xxh7y9vRUTE6NVq1YpJSVFy5YtkySNHz9eM2bMcJ2XmJioyMhISdK4ceOUmpqqgQMHymq16sknn1RycrJMJpNeeeUVtWjRQuHh4Xr66add51flepPG36UDC4aoIGn1eWv38vWTtd3tyv9y5Tn7Sm12vbTpoObOnavo6Gg1b95cd999twoKClzHLF26VNHR0QoODta8efMqne9wOLRgwQK1atVKwcHBGjFihPLy8qr8ufbu3VsjRoxQixYtqnxObSJM1YL4+Hjt27fP6DIAAADgJl999ZVKS0t15513VtputVrVr18/ffbZZ5e8xtKlS9WyZUt9+OGHKioq0tSpU137Pv/8cx06dEiffvqpFixYUKWpgEuXLlVkVJTChs9Uy7+sVmDXYRc8NrDbSJ068KXKc9MrbXc6pQ/eXak33nxTn3/+uX766ScVFRXpD3/4gyRp7969euCBB7R06VJlZmYqNzdX6em/XGPhwoVau3atNm/erMzMTDVt2lSTJk1y7W/fvr1WrFhxyfdSVxGmakFcXBwjUwAAAB4sJydHISEhsljObZYdHh6unJycK7r+rFmz5Ofnp+uvv17/93//p5Urzx1FOp/iMnuVjjNbm8r///VT/pbl5+w7+cPnumnQ3br66qtltVr1+OOP6+2335bNZtPq1as1YMAA3XbbbfLx8dGcOXPk5fVLxPjXv/6lefPmKTIyUj4+Pnr00Ue1evVq2Ww2SdJ3332n0aNHV6nGuogwVQuY5gcAAODZQkJClJOT4woJZzt69KhCQkKu6PpRUVGu19HR0crMzKzSeeV2h8odzksfKCmg6zCV/PyNTh/7qdL20ydzVdKoWaX722w2HTt2TJmZmZVq8/PzU3BwsOv7lJQUDRkyREFBQQoKCtK1114rs9msY8cqr8+SpN///veyWq2yWq2aP39+lWo2GmGqFrRp00YHDx6Uw3H+RX8AAACo326++Wb5+PhozZo1lbYXFxdr/fr1uv322yWdCRunTp1y7c/Kyqp0vMlkOu/109LSXK9TU1Nda4iaNGmi3Nxc7dq1S2vWrNEbb7yh/Px8DR48WB07dtSpkpIqvwdz4wAFdBmk/C3LKm23WJvp+NFfpu6lpqbKYrHoqquuUnh4eKXaTp06pdzcXNf3UVFRWr9+vfLz811fpaWlioiIOOf+L7/8soqKilRUVKRp06ZVuW4jEaZqgb+/v5o1a1bpBw0AAACeIzAwULNmzdIf//hHffLJJyovL1dycrKGDx+uyMhIjRs3TpLUsWNHrVu3Tnl5ecrKytJzzz1X6TpXXXWVfvrpl5Eh53/7mP/pT3/SkiVL9OCDD+qFF17Q999/r3bt2un111/XK6+8onvuuUevvPKKPv30U1ksFt199916/fXXFRwWIVt+5cB2MQE3DlFZxn6V5/zye2uTtj2077OV+vnnn11BZ+TIkbJYLBo2bJg++ugjbd26VadPn9bMmTMrDSD8/ve/1/Tp05WSkiJJys7O1gcffFDleux2u0pLS2Wz2eRwOFRaWqry8vIqn+9uhKlawsN7AQAAPNvUqVM1f/58/fWvf1VAQIBuuukmRUVFaePGjfLx8ZF0psNehw4dFBMTo759+2r48OGy2+3aunWrli9frtatW+vBBx+Ut7e3QkNDFR8fL0k6cOCA7r//fv3rX/9Snz599Mgjj2jFihVKTU3VsGHDlJqaqszMTD300EOyWq2688471blzZ935f39Q4VfvKPXZkSr4es3Fypckefk0UcBNd8pRetK1LaTTr3Vrvzt12223KTY2Vr6+vnrhhRckSdddd51eeukljR49WuHh4WratKmrm6B0JgQOGjRIffv2lb+/v7p27aqvv/7atf+6667T8uXnrtOqsHTpUjVu3FgPPPCAtmzZosaNG2vChAmX9x/GjUxOp7NqkyhxRSZNmqS4uDhNnjzZ6FIAAABQS8rLy5Wenq6UlBQlJyef829GRoaCg4MVHR2tmJiYc/51Op267rrrVF5eft7mFpeSU1SmW57YpDJb9Zeb+Fi89NVDvRRs9an2NTzV5f8XQbUwMgUAAOB5SktLlZqaqpSUlPMGpqysLIWHhys6OtoVkG655RaNGTNG0dHRioqKkq+v7wWvn5ycfEX1hVh91KNNqD7bd0zVGUIxmaRfxYUSpC6AMFVL4uPjL2t+KAAAAIxXXFxcKRz9b2DKy8tTZGSkazQpOjpavXv3dgWniIgIeXt7G/oeJvVsrS2HclRSXrU26WfztZg1sWdrN1TlGZjmV0tSUlLUrVs3ZWRkGF0KAAAA/qugoOCc0aSzXxcVFVUaVfrf1+Hh4TKbzUa/jUtalpSseev2qaS86tP9Gnt7aXr/azW2a4z7CqvnCFO1xOFwyN/fX1lZWfL39ze6HAAAAI/ndDqVm5t73ul3Fa/tdvt51ytVvG7evPkF25XXN2cC1X6V2uwXnfJnMp0ZkZreP54gdQmEqVrUsWNHvfbaa+rSpYvRpQAAANR7DodDx48fP29jh4rA1KhRo3NGk87+t2nTph4Tlqriu/R8LUo8rM8PZMskqfSsxhS+Fi85dWaN1MSerdU+MsiwOusLwlQtuuuuuzRgwACNHTvW6FIAAADqPLvdrszMzAuuV0pLS5O/v/95p99V/BsQEGD026iTcovKtPqbdO0/elKFpeUK8PVWfLi/hnWKpNnEZaABRS2Kj4/XgQMHjC4DAACgTigvL1daWtoF1ytlZGQoJCSkUjjq3Lmzhg4dqujoaLVs2VJ+fn5Gv416Kdjqo/tva2V0GfUeYaoWxcXFac2aSz8sDQAAwBNUtA2/0Hql48ePKywsrNJoUvfu3TVmzBjFxMQoKirK9bBboC4iTNUiRqYAAIAnKSoquuDzlVJSUnTixAlFRkZWGlnq27eva0peXWgbDlwJ1kzVouLiYoWEhKioqKhetNAEAAANW35+/nmDUsW/p06dUsuWLc/b2KGibbiXl5fRbwNwG0amapGfn59CQ0OVmpqq2NhYo8sBAAANmNPpVE5OzkUfSOtwOBQTE1OpwcPNN9/sCkyhoaENqhMe8L8IU7UsLi5O+/fvJ0wBAAC3cjgcOnbs2EUfSOvj41NpNOnqq6/Wr371K9e2htY2HLhchKlaVrFuql+/fkaXAgAA6jG73a6MjIwLrldKTU1VYGBgpWl37dq1U0JCgmuUibbhwJUhTNWyuLg4/fDDD0aXAQAA6rjTp0+72oafLzBlZmYqNDS00vOVbrjhBg0fPtzVNrxJkyZGvw3AoxGmall8fLzee+89o8sAAAAGKykpqdQ2/H8DU3Z2tsLDwyutV7rttts0btw4V9vwRo0aGf02gAaNbn61LC0tTTfeeKOOHj1qdCkAANSKnKIyrd6Vrv1ZhSostSnA16L4sAAN7xypYKvnPkPo5MmT54Sks1/n5+crKiqq0jS8s19HRETIYuHv3kBdRpiqZQ6HQwEBAcrIyFBgYKDR5QAA4DZ70vL1UuJhbT6YLUkqszlc+3wtXnJK6hkXqok9WqtDVJBBVVaP0+m8YNvwitclJSXnbRde8W9YWBhtw4F6jjBlgM6dO+uf//ynbrzxRqNLAQDALZYlJWveuv0qtdl1sd80TCbJ12LW9P7xGts1ptbquxSn06ns7OwLrldKTk6WpAsGpZiYGIWEhNAJD/BwjB0boKI9OmEKAOCJzgSpfSopd1zyWKdTKim3a966fZJ03kCVmJiosWPHKj09vcZqdDgcysrKOu/0u6+++kqnTp1SQEBApel3rVu31u233+7aFhQURFgCGjjClAEq2qMDACBJPXv21J49e5SVlSUfn/q9huj3f35Y/1r4D5nM3pKXWY1CotS0173yibj2oueVlDs0b91+tY8MUvvIX6b8FRYWau/evRc912QyqV27dtqzZ49r2ty0adN08OBBTZ48+bzT8NLS0hQUFFRpNKl9+/YaOHCgGjVqpDZt2uipp5667Pefl5ene++9V59++qlCQkL0+OOPa/To0Zd9HQD1A2HKAHFxcVq1apXRZQAA6oDk5GRt2bJFgYGB+ve//63hw4fX6PVtNlutNjHYkZwnv2tvVcjAv8pptyn/iyXKXjNfEX9YcslRnFKbXYsSD+vlsV0kSZ988onGjh2r8vJy+fv7Vzq2rKzM1TZcko4cOaIePXrIy8vLFZZ8fX2VlZXlCkw33XSTRo4c6Wob3rhx4/PW8e6771Y71E6aNEmNGjXSsWPHtHv3biUkJKhDhw667rrrqnU9AHUbqx4NwMgUAKDCkiVL1LVrV40fP16LFy+WdCYoBAUFVXouYXZ2tho3bqzjx49Lkj766CN17NhRQUFB6tatm7777jvXsTExMXriiSfUvn17+fn5yWazacGCBWrVqpX8/f3Vtm1bvf/++67j7Xa7/vKXvygkJESxsbF68cUXZTKZZLPZJEkFBQW69957FR4eroiICM2YMUN2u/2c95JTVKbk3GLX9yazRX7tbpe9+IQcJYWynczV8dWzlfbcXcp4eYJO7v7EdazTVq7cz17Raw/8WleFhalNmzYaPHiwcnNzdfLkSRUUFGj06NG65ZZbFBERoYCAAPXp00dz586VJHXr1k0HDx7UjBkztGnTJk2dOlXDhw/X1q1btXz5ct100016/vnnNWLECN1///2uNU+S9O2336pTp07y9/fXyJEjVVpaWul9XeyzPltxcbHee+89zZkzR1arVd27d9egQYO0dOnSi/8QAKi3CFMGuOaaa3TkyJHz/o8IANCwLFmyRGPGjNGYMWO0YcMGHTt2TD4+Prrzzju1cuVK13GrVq1Sjx491Lx5c33zzTf67W9/q3/961/Kzc3V/fffr0GDBqmsrMx1/MqVK/Xxxx8rPz9fFotFrVq10pYtW1RQUKBZs2Zp7Nixrsd0vPrqq1q/fr12796tb775RmvXrq1U4z333COLxaLDhw/r22+/1aeffqrXXnvtnPeyelflNU1OW7mKv98os3+IzE0ClfPvp2T2D1HkH5YodMjflb95iUqSd0uSCr56R2WZBxQz4UU5W3XXoUOHXO+nYkSrX79+WrBggbZt26bi4mL9/PPP+vzzzyVJ//znPxUZGamUlBRdffXVMpvNrjoOHjyoUaNG6bnnnlN2drb69++vgQMH6vTp0zp9+rQGDx6scePGKS8vT8OHD6/0PMhLfdYTJ07UxIkTXfcxm81q06aN6/wOHTroxx9/rNLPAoD6hzBlgCZNmuiqq66q9FcxAEDDs3XrVqWkpGjEiBHq3LmzWrVqpRUrVkiSRo8eXSlMrVixwrX25tVXX9X999+vm266SWazWffcc498fHyUlJTkOn7y5MmKiopyTWUbPny4WrRoIS8vL40cOVLXXHONtm/fLulMUPvTn/6kyMhINW3aVA8//LDrOseOHdP69ev13HPPyc/PT82bN9ef//xnvf322+e8n/1ZhbI7nCret1Wpz45U+qLxKss6rNChM2QrzFZZ+l417TleJksjNbrqalk79FXxD2fCUPHeRAXdcpdsPgEafN+f9bvf/U4Wi8VVv6+vr8aNG6dbb71VLVu2PGfqoslk0pw5czR79uxKoVKS3nnnHSUkJKhPnz7y9vbWX//6V5WUlOirr75SUlKSysvLNWXKFHl7e2vYsGG64YYbXOde6rNetGiRFi1aJEkqKio657EngYGBOnny5MV/EADUW4Qpg1R09AMANFyLFy9W3759FRISIulMgKqY6terVy+VlJTo66+/VkpKinbv3q0hQ4ZIklJSUvT0008rKCjI9ZWWlqbMzEzXtaOioirda8mSJa6pahVTCHNyciRJmZmZlY4/+3VKSorKy8sVHh7uOvf+++93TTc8W2HpmWmBftd2V8s/v6OoycsVNnq+fMJay16UJy9fq7x8mriOtwQ2l70oV5JkL8qTOaD5mddejfTnP/9ZJpNJe/bs0W9/+9sqrfvq37+/WrZsqVdeeaXS9szMTEVHR7u+9/LyUlRUlDIyMpSZmamIiIhK67nOPrYqn3UFq9WqwsLCyp9JYeE5670AeA4aUBikYt1UQkKC0aUAAAxQUlKiVatWyW63KywsTNKZtVL5+fnas2ePOnTooBEjRmjlypW66qqrNGDAANcv5VFRUZo+fbqmT59+weufHQ5SUlI0YcIEbdy4UTfffLPMZrM6duyoikdNhoeHV2o7npaW5nodFRUlHx8f5eTkXDTQFBYWKj/76AX3m63N5CgtkqPslCtQ2QqzZbYGu/bbC49LodEK8PVWamqqWrRooWuuuUZjxozR+vXrL3jts82dO1d33XVXpQ56LVq00Pfff+/63ul0Ki0tzRWiMjIy5HQ6XZ9ZamqqWrVq5Xr/l/qsK7Rp00Y2m02HDh3SNddcI0nas2cPzScAD8bIlEEYmQKAhm3t2rUym83au3evdu/erd27d2vfvn269dZbtWTJEklnRqreeecdLV++vFI4mDBhgl5++WV9/fXXcjqdKi4u1scff3zB6WTFxcUymUwKDQ2VJL355puVmluMGDFCzz//vDIyMpSfn68nnnjCtS88PFx9+/bVX/7yFxUWFsrhcOjIkSNKTEzU3r179Y9//EO9evVSRESEUvdsk+n/t3fnUVXW+R/A3xfuZfECsiubLLGJCYlLuIZWIE/ZacxlQGyaHJXM/GmWR8PBxpGZRqcyS/2dnzXu27hWw0VCUDITjXEZLWUT2S4iIDsXuNvvj47PRFwNb8IVeb/O4Rx5nvvc5/PcP5A3n+8Cwzv0Su1cYOkRjLqs7dBr2tF+qwhNl9IhHxIJAOgX8hTqv90PaVsjPK3VWL16NeLj4+/7c42MjMTQoUPFDt+d50tJSUFGRgbUajXef/99WFpaYsyYMRg9ejSkUik2bNgAjUaDw4cPi8Mf7/ezlsvlmDp1KpKSktDc3IzTp0/j888/x+zZs+/7OYiod2CYMhGu6EdE1Ldt374dv//97zFo0CAMHDhQ/Fq4cCF2794NjUaDJ598EnK5HEqlEjExMeK1I0aMwJYtW7Bw4UI4ODjA398f27Ztu+u9QkJCsHTpUowePRoDBgzA5cuXMXbsWPH83LlzERUVhdDQUAwbNgyCIEAqlYqLOOzYsQPt7e0YPHgwbG1tERERgenTpyMmJgaFhYVYsmQJbt68iWOb3xX3eTLE+YVl0NTfQtknL6PqcDLsx8fB2ncYAMB+zExYDAzAjS0LsHbeCwgPD8fKlSuN+mzXrFmD27dvi98HBQVh165deOONN+Ds7Iwvv/wSX375JSwsLGBhYYHDhw9j27ZtcHBwwP79+zF16tQuf9YJCQlISEgQv9+0aRNUKhVcXV0RGxuLzZs3szNF9AiT6O/0+KlHKZVKDBs2DJWVlaYuhYiIqIPU1FQkJCSguLgYBQUFUCgUUCgUOH36NEaMGAFBECAIAkJCQjrtHTVvZw7Sr1bCmN8uJBIgOmSAuM8UEdHDjmHKRPR6Pfr374/i4mI4ODiYuhwiIurDVCoVTpw4gaioKBQXF+P555+HlZUVmpub0djYKIanZ555ptNqdT93qbQOv92SDZX6/rf/sJaZY/+8CIR62hv7KEREPYoLUJiIRCJBUFAQcnNzERERYepyiIioDyspKcGCBQtQVlYGnU4HZ2dnzJ8/H1OnTkVYWNg9h+79XJiXPRKFYCQrrkKl1nX5OmuZGRKFYAYpE+7LugAAG4pJREFUIupVGKZM6M4iFAxTRETUk9RqNU6fPi0O36usrMTkyZMhCAKioqLg5OT0q94/PsIHAJCsuIZWjfaeQ/4kEsBKao5EIVi8joiot2CYMiEuQkFERD2loqICqampUCgUOH78OAICAiAIAj777DOMGDFCXGziQYmP8EGopz02nSzAidwqSAC0av7bqbKSmkEPYGKQCxZE+rMjRUS9EudMmdCBAwewZ88eHDlyxNSlEBHRI0ar1eLs2bNi96moqAhRUVEQBAGTJ0/GgAEDeqyWmqY2HDxfhmsVjWhoVcPOSoZgN1tMC/eEk41lj9VBRPSgMUyZ0OXLlzFz5kz88MMPpi6FiIgeAVVVVUhLS0NqairS0tLg4eEhLh5xZz8lIiJ6cBimTEilUsHBwQFNTU38D46IiO6bTqfDhQsXoFAokJKSgqtXr2LSpEkQBAExMTHw9PQ0dYlERI80hikT8/PzQ1paGgICAkxdChER9QJ1dXVIT0+HQqFAamoqHBwcxO7TuHHjYGnJYXNERD2F7RATu7OiH8MUEREZotfrceXKFXHu04ULFzB+/HgIgoA//vGP8PPzM3WJRER9FsOUid1Z0W/KlCmmLoWIiB4STU1NyMjIEAOUTCbDc889h+XLlyMyMhLW1tamLpGIiMAwZXJBQUHIyckxdRlERGRCer0eeXl5YnjKzs5GREQEBEHAm2++icDAQEgkElOXSUREP8MwZWLBwcHYtWuXqcsgIqIeplKpcPLkSTFAtbe3QxAELFy4EIcPH4atra2pSyQiol/AMGVi3LiXiKjvKCoqEsPTqVOnMGzYMAiCgKNHj+Lxxx9n94mIqJdhmDIxc7k9JCHP4rUd2WjTm8POSorggXaYPpwbGRIR9Xbt7e04deqUGKBqa2sRExODV155Bbt374a9vb2pSyQiol+BS6ObyKXSOmw8WYCsvCq0tbUB5jLxnJXUDHoAkUEuWPCUP8K8+J8tEVFvUVZWhtTUVCgUCmRmZiIkJETc9yk8PBxmZmamLpGIiB4QhikT2JV9A8mKa2jVaHGvT18iAayk5kgUghEf4dNj9RERUddpNBqcOXNG7D6VlZUhOjoagiAgOjoaLi4upi6RiIi6CcNUD/sxSF2FSq3r8jXWMjMkCoN/MVCdPHkS8fHxKCsr+5VVEhHRvVRWVuLYsWNQKBRIT0+Hj4+PuHHuk08+CXNzc1OXSEREPaDPjjXYs2cPRowYARsbG7i5uSEmJgbffPNNt97zUmkdkhXXxCBV/a8PUfze82hT/ncBCnWtEsXvPd/hOpVah2TFNfynrK7batu+fTuGDx8OOzs7eHp6YtmyZdBoNN12PyKi3kSr1eLs2bNYtWoVRo4ciaCgIHz55ZeIjo7GlStXcP78eaxZswZjxoxhkCIi6kP6ZJj64IMPsHjxYrzzzjuorKxESUkJFixYgM8//7xb77vxZAFaNdoOx8ysbFH39S8vjd6q0WLTyYLuKg0tLS1Yv349qqurcfbsWWRkZODvf/97t92PiOhhV1NTg71792L27NkYOHAg5syZA5VKhXXr1qGqqgoHDx7Eq6++Cnd3d1OXSkREJtLnwlR9fT2SkpKwceNGTJ06FXK5HDKZDFOmTMG6desAAG1tbVi8eDHc3d3h7u6OxYsX/7hIBH4cSufp6Yn3338frq6ucHNzw9atWwEA2dnZGDhwILTa/wamI0eOIDQ0FNVNbcjKq+o0R0o+dBLaq4rQWnLZYL2axhrcOrgaJR/+Fv9Y9AI+/HiTeE6lUuGVV16Bg4MDQkJC8N1333W4VqlU4qWXXoKLiwt8fX2xYcOGu34ur732GsaPHw8LCwt4eHhg1qxZOH36dNc/WCKiXk6v1+PChQtITk7G2LFj4evri71792Ls2LHIycnBlStXsHbtWkRGRkImk/3yGxIR0SOvz4WpM2fOoLW1Fb/5zW/u+prk5GRkZ2fj4sWLuHTpEs6dO4c1a9aI52/evIn6+nqUl5fjs88+w+uvv47a2lpERERALpcjMzNTfO2ePXsQFxeHg/82PI9JIrNC/9EzUPf1ToPnq79YB3NbZ3gu3AH3l95B0h9XIiMjAwDwpz/9CYWFhSgsLERaWhq2b98uXqfT6TBlyhSEhYWhvLwcGRkZWL9+PdLS0gAA33zzzT2X5P36668xZMiQu54nInoU1NfX49ChQ5gzZw48PDwwc+ZMVFVVYdWqVbh16xa++OILJCQkwNvb29SlEhHRQ6jPhamamho4OztDKr37Flu7d+9GUlISXF1d4eLiglWrVmHnzv+GHZlMhqSkJMhkMgiCABsbG3Hj3djYWOzduxcA0NjYCIVCgdjYWFy72YA2jeFFJ2yfiIGmoQqqwpwOxzUNVWgr+wEOka9AIrUAnH0RHPkidu7ciZaWFmzduhUWFhZobm6Gl5cXFi1aJF773XffoaqqCklJSbCwsICfnx/mzp2Lffv2AQDGjRuHujrDc7C2bt2KnJwcvPXWW134RImIeg+9Xo/vv/8e69atw8SJE+Hp6YktW7YgLCwMWVlZyMvLw/r16xEVFQUrKytTl0tERA+5Prdpr5OTE6qrq6HRaO4aqJRKZYe/Qnp7e0OpVHZ4j59e269fPzQ1NQEA4uLiMGbMGGzevBmHDx9GeHg4vL290XDy1l1rkkhl6D9mJupO7YLzC2+Lx7VNt2FmZQMzy37isXq1BEePHsW+ffvQ1taGrKws8d4/rbm4uBhKpbJD90mr1WL8+PH3/HyOHj2K5cuX4/jx43B2dr7na4mIeoPm5mZkZmaKS5dLJBIIgoClS5di4sSJkMvlpi6RiIh6qT4XpkaPHg0rKyscPXoU06ZNM/gad3d3FBcXi8PcSkpKujzBOCQkBN7e3khNTRWH+AGAndW9P2qb0GfRcPYQWvLOiMfMbRyha22Crq1FDFQVhdfQVF8vvkar1eKjjz7C4MGDcf36dWg0Gmg0Gnh5ecHX1xf5+fldqhsAjh07hrlz5yIlJQVDhw7t8nVERA+b/Px8pKamIiUlBd9++y1GjhwJQRCQmpqKwYMHQyKRmLpEIiJ6BPS5MNW/f3+sXr0ar7/+OqRSKaKioiCTyXD8+HGcOHECa9euRWxsLNasWYORI0dCIpFg9erViI+P7/I94uLisGHDBpw5cwa7d+8GAAQPtIOl9OZdh/pJzMzRf1wcatP/TzwmtXOBpUcw6rK2w2HSHEjqKyC5lYtZs2bh8OHDUKlUMDc3h4+PDy5cuIBDhw5BpVLBxsYGPj4+qKqqwoQJEzBz5kzxlwe5XI5Ro0Z1un9mZiZmzZqFI0eOGDxPRPQwa21tRVZWlth9am5uRkxMDObPn48DBw7Azs7O1CUSEdEjqM+FKQB48803MWDAAKxZswazZs2Cra0thg8fjsTERADAypUr0dDQgNDQUADA9OnTsXLlyi6/f2xsLFasWIGYmBhxqNy04Z748HjePa+ThzyFhjMHoGttFI85v7AMt9M2ouyTl2FuZYO/vPsu3vqfhTh37hxefPFFaLVavPfee3B3d0dSUhI++ugj5Ofno7CwENnZ2fj444/x9ttvo729HRKJBFKpFCEhIbC3t8epU6ewbds2BAYGYtWqVaivr4cgCOK9x48fj9TU1C4/NxFRTyouLhbDU1ZWFkJDQyEIAg4cOICwsDB2n4iIqNtJ9PqfL9ZN3WXezhykX63stDx6V0gkQHTIAPxv/AjxWEtLCxobGzFgwIAuv09tbS3y8/ORl5fX6cvGxgaBgYEdvgICAvDYY49xIjYRmZxarcbp06eRkpIChUKBW7duISYmBoIgICoqCo6OjqYukYiI+hiGqR50qbQOv92SDZVa+8sv/hlrmTn2z4tAqOfdlzP/NfR6PSoqKgyGrBs3bsDNzQ1BQUGdwpaXlxfMzc27pSYiIqVSiWPHjkGhUOD48eMIDAyEIAgQBAHDhw/nzx8iIjIphqketiv7BpIVV6FSG547ZYi1zAyJwmDER/h0X2H3oFarUVxcjLy8POTm5nYIWtXV1Xjsscc6hazAwEC4uLhwmA0R3RetVouzZ8+Kw/du3LiBqKgoCIKA6Ojo++rEExERdTeGKRP4MVBdQ6tGe88hfxIJYCU1R6IQbLIg9Uuam5tRUFDQqZuVm5sLnU5nMGQFBATA1tbW1KUT0UOiqqoKaWlpUCgUSEtLg5eXl9h9ioiIuOe+gERERKbEMGUi/ymrw6aTBTiRWwUJgNafrPJnJTWDHsDEIBcsiPTvtqF93a2mpsbgsMH8/HzY29sbDFp+fn6wsLAwdelE1I10Oh3Onz8vdp+uXbuGSZMmQRAETJ48GZ6enqYukYiIqEsYpkyspqkNB8+X4VpFIxpa1bCzkiHYzRbTwj3hZGNp6vK6hU6nQ3l5ucGgVVpaCk9PT4NBy9PTE2ZmZqYun4iMUFtbi/T0dCgUCqSmpsLJyUnsPo0bN45/RCEiol6JYYoeKu3t7SgqKjIYtGpra+Hv728waDk5OXF+FtFDRK/X4/Lly2L36eLFi5gwYQIEQUBMTAx8fX1NXSIREdGvxjBFvUZjY+Nd52eZmZnddX6WXC43delEfUJjYyMyMjLEAGVpaYnnnnsOgiDgqaeegrW1talLJCIieqAYpqjX0+v1qK6uNtjNKigogJOTk8Gg5evrC5lMZuryiXotvV6P3NxcMTydPXsWo0ePFofvBQQEsGNMRESPNIYpeqRptVqUlZUZDFrl5eUYNGiQwaDl7u7O+VlEBrS0tODkyZNigFKr1WL3adKkSbCxsTF1iURERD2GYYr6rLa2Nly/ft1g0GpoaEBAQIDBoOXo6Gjq0ol61PXr18Xw9M033yA8PFzsPg0ZMoTdJyIi6rMYpogMaGhoQH5+vsGNii0sLAyGLH9/f/Tr18/UpRP9am1tbTh16pQYoOrq6sTw9Mwzz8Devndu10BERPSgMUwR3Qe9Xo/KykqD3azr16/D1dXVYNDy8fHhxqP0UCstLUVqaioUCgVOnDiBIUOGiAHqiSee4LBXIiIiAximiB4QrVaL4uJig0Hr5s2b8PHxMRi03NzcOEyKepxarcaZM2fE7pNSqcTkyZMhCAKioqLg7Oxs6hKJiIgeegxTRD1ApVKhsLDQYNBSqVR3nZ/F4VT0IFVWVuLYsWNQKBRIT0+Hn5+f2H0aOXIkzM3NTV0iERFRr8IwRWRitbW14vysn3/169fvrvOzrKysTF06PeS0Wi1ycnLE7lNBQQGeffZZCIKAyZMnY+DAgaYukYiIqFdjmCJ6SOn1elRUVBgMWTdu3MDAgQPFcBUUFCT+e9CgQeww9GE1NTX46quvoFAocOzYMbi5uUEQBMTExGDMmDHcW42IiOgBYpgi6oU0Gg1u3LhhMGhVVVXBz8/PYEfL1dWV87MeMXq9HhcvXhS7T1euXEFkZKQ4fM/Ly8vUJRIRET2yGKaIHjEtLS0oKCgwGLTUarXBkBUQEAA7OztTl05dVF9fj+PHj0OhUCA1NRW2trZieJowYQIsLS1NXSIREVGfwDBF1IfU1NQYnJ+Vn58POzs7g0HLz8+Pv5ybmF6vxw8//CB2n/79739j7Nix4vA9f39/U5dIRETUJzFMERF0Oh2USqUYrn66UXFJSQk8PT0NBi0vLy/uP9RNmpubkZmZKQYoMzMzsfs0ceJEbhBNRET0EGCYIqJ7am9vR1FRkcFhg7dv34a/v7/BoOXs7Nyr52dVN7Xh4L/LcO1mAxpaNbCzkiJ4oB2mD/eEk033dOry8/PF8PTtt99i1KhRYoAKDg7u1Z8nERHRo4hhioiM1tTUZHDYYG5uLiQSyV3nZ9nY2Ji69Lu6VFqHjScLkJVXBQBo0+jEc1ZSM+gBRAa5YMFT/gjz+nX7gLW2tiIrK0sMUC0tLWJ4evrppzmPjYiI6CHHMEVED5xer0d1dbXBblZBQQEcHR0NBi1fX19YWFiYrO5d2TeQrLiGVo0W9/rJKJEAVlJzJArBiI/w6XT+9u3bcHR0NHhtcXGxGJ6ysrIQFhYmBqjQ0FB2n4iIiHoRhiki6lE6nQ6lpaUGg1ZZWRkGDRpkMGh5eHh06/ysH4PUVajUug7Hb+5eDvnjE2EbFt3pGmuZGRKFwR0C1fbt2zFnzhxcvHgRjz/+ONrb23H69GkxQFVVVSEmJgaCICAqKgoODg7itTdu3ICvry/UajWkUmm3PSsRERE9GAxTRNQjfHx8oFQqoVQq4ezsLB5/4okncOnSJRQVFcHNzQ3Xr183GLQaGho6zc+6s1nxnS6QRCJBv379IJFI0L9/f8ycORPr1q37xU2ML5XW4bdbsqFSazudu1eYqju1G/Wn92Ld5q14K+EVvP/++1i5ciVaW1sRFRUFGxsbZGRkICgoSOw+DR8+/K6h8NeEqYqKCsyfPx85OTmoqKhAUVERfHx87us9iIiI6P7wT59E1GN8fX2xd+9evPHGGwCAy5cvQ6VSiectLS0xePBgDB48uNO1DQ0NHeZnffXVV/jkk0+Qm5sLCwsLBAYGAgASEhIwevRoyGQyzJs3D4GBgUhISLhnXRtPFqBV0zlIdYWZlS2S//wnXDiVjgMHDkCtVgMAzpw5g40bN2Lz5s1wdXU16r3vqw4zM0yePBkrVqzAmDFjuv1+REREBHBNYyLqMbNnz8aOHTvE77dv346XX365w2tSUlIwbNgw2NnZwcvLC++++y4AwM7ODgUFBUhMTMSSJUuwe/durF69Gv369UNWVhb+9re/AQAaGxuxe/duvPPOO6iursbbb7+NZ555BpGRkXBxcYGtrS2efvpplJSUAPhx1b5jGVlQbl2Ckg9noGLbErSWXe3yM1n5haNFI8GBI19Aq9WKS5Y3NjZiypQpsLS0xMsvvwwXFxd4e3tjzZo10Ol+HEqo1Wrx1ltvwdnZGX5+fkhJSenw3vX19ZgzZw7c3Nzg4eGBlStXQqs1HPoGDBiABQsWYOTIkV2unYiIiH4dhiki6jERERFoaGjA1atXodVqsX//fsTHx3d4jVwux44dO1BXV4eUlBRs3rwZR48eBQDMnDkTo0ePxqJFi1BTU4M5c+bg008/xZAhQzB+/HgAwLJly3DkyBEcOHAALi4uSExMxLPPPoucnBxMmjQJERER+O677+Dj44Pg4GBMnpeI8n2rYDtiCrz+Zy/sRr2IqgPvQqtq6NIzSSQSuETORn97B5SXl+Pzzz8HAEybNg1arRZvvPEG6uvrcf36dWRlZWHHjh3YunUrAGDLli3417/+hQsXLiAnJwcHDx7s8N6/+93vIJVKUVBQgAsXLuCrr77Cp59+CgAoKSmBvb29GAqJiIio5zFMEVGPutOdSk9PR3BwMDw8PDqcj4yMxNChQ2FmZobQ0FDExsYiKytLPL9x40ZkZmYiMjISU6ZMwfPPP9/h+vDwcDg4OGDKlCn4wx/+gGXLliEvLw8LFizA/v37kZ6eDqVSCXNzc2zYsAESvRZSR3fYPD4JEjNzyEOegtTJE6r8c11+JqnfKJj3648jR44gMjISALBu3TrY29tj//79+Otf/wpbW1v4+Phg6dKl2LlzJwDgn//8JxYvXgwvLy84OjpixYoV4ntWVlYiNTUV69evh1wuh6urK5YsWYJ9+/YBAAYNGoS6ujoMGjTovj5/IiIienA4Z4qIetTs2bMxYcIEFBUVdRriBwBnz57F8uXLceXKFbS3t6OtrQ3Tp08Xz9vb22P69On44IMPcOjQoU7Xnz9/Hv7+/h2OKZVKhIeHi9/b2NjAyckJcrkceq0aUruOc5qk/V2hbaq5r+d64jfzkZycjNmzZ4vHqqur0d7eDm9vb/GYt7c3ysvLxbq8vLw6nLujuLgYarUabm5u4jGdTtfh9URERGRa7EwRUY/y9vaGr68vFAoFpk6d2ul8XFwcXnjhBZSWlqK+vh4JCQn46aKjFy9exD/+8Q/ExsZi0aJFXbqnu7s7iouLxe+bm5tRU1MDDw8POLkMgKbhVofXaxuqYG7jdF/PNXjEOPj7+2PTpk3iMWdnZ8hksg73LikpEbtxbm5uKC0t7XDuDi8vL1haWqK6uhp1dXWoq6tDQ0MDvv/++/uqi4iIiLoPwxQR9bjPPvsMmZmZkMvlnc41NjbC0dERVlZWOHfuHPbs2SOea21tRXx8PP7yl79g69atKC8v7xBe7iYuLg5bt27FxYsX0dbWhnfeeQdPPvkkfHx88Gx0DDS3lWj+/iT0Oi2ar36N9upSWPt3fSEHK6kZgt1skZycjLVr14rHzc3NMWPGDCQmJqKxsRHFxcX44IMPxHliM2bMwIYNG1BWVoba2lq899574rVubm6IiorC0qVL0dDQAJ1Oh8LCwg5DHn+utbUVbW1tAIC2tja0trZ2+RmIiIjo/jFMEVGPe+yxxzBixAiD5zZt2oSkpCTY2tpi9erVmDFjhnhuxYoV8PT0xGuvvQZLS0vs2rULK1euRH5+/j3v9/TTT+PPf/4zXnrpJbi5uaGwsFCce/TKpKHwmPkuGs4dQelHsWjIPgTXaUkw79e/y8+jBzAt3BNjx47FqFGjOpz7+OOPIZfL4efnh3HjxiEuLg6vvvoqAGDu3LmIjo5GWFgYwsPDO3XqduzYgfb2doSEhMDBwQHTpk1DRUUFgB+7WDY2Nh26WdbW1rCxsQEABAcHw9rausvPQERERPePm/YSUZ83b2cO0q9WwpifhhIJEB0yAP8bbzgcEhER0aOLnSki6vNej/SHldTcqGutpOZYEOn/yy8kIiKiRw7DFBH1eWFe9kgUgmEtu78fidYyMyQKwQj1tO+myoiIiOhhxqXRiYgAxEf4AACSFdfQqtHec8ifRPJjRypRCBavIyIior6Hc6aIiH7iP2V12HSyACdyqyAB0KrRieespGbQA5gY5IIFkf7sSBEREfVxDFNERAbUNLXh4PkyXKtoREOrGnZWMgS72WJauCecbCxNXR4RERE9BBimiIiIiIiIjMAFKIiIiIiIiIzAMEVERERERGQEhikiIiIiIiIjMEwREREREREZgWGKiIiIiIjICAxTRERERERERmCYIiIiIiIiMgLDFBERERERkREYpoiIiIiIiIzAMEVERERERGQEhikiIiIiIiIjMEwREREREREZgWGKiIiIiIjICAxTRERERERERmCYIiIiIiIiMgLDFBERERERkREYpoiIiIiIiIzAMEVERERERGQEhikiIiIiIiIjMEwREREREREZgWGKiIiIiIjICAxTRERERERERmCYIiIiIiIiMgLDFBERERERkREYpoiIiIiIiIzAMEVERERERGQEhikiIiIiIiIjMEwREREREREZgWGKiIiIiIjICAxTRERERERERmCYIiIiIiIiMgLDFBERERERkREYpoiIiIiIiIzAMEVERERERGSE/welHeFzJbyaHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "rag = RandomArchitectureGenerator(\n",
    "    prediction_classes=10,\n",
    "    min_depth=5,\n",
    "    max_depth=7,\n",
    "    image_size=int(images.shape[2]),\n",
    "    input_channels=int(images.shape[1]),\n",
    "    min_nodes=5\n",
    ")\n",
    "\n",
    "rag.get_architecture()\n",
    "cont = rag.controller()\n",
    "rag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Controller(\n",
       "  (module_dict): ModuleDict(\n",
       "    (5:Input_Node): Identity()\n",
       "    (4:Conv_Node): Sequential(\n",
       "      (0): Conv2d(1, 512, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3:Conv_Node): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2:Conv_Node): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1:MaxPool_Node): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (0:Average_Pool_Node): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    (-1:Output_Node): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=18432, out_features=9574, bias=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Dropout(p=0.12841732156108204, inplace=False)\n",
       "      (4): Linear(in_features=9574, out_features=10, bias=True)\n",
       "      (5): Softmax(dim=None)\n",
       "    )\n",
       "  )\n",
       "  (network_map): ModuleDict(\n",
       "    (-1:Output_Node): OutputNode(node_id=-1, out_features=9574, classes=10, width=None, [successors=[0]] )\n",
       "    (0:Average_Pool_Node): AvgPoolNode(node_id=0, )\n",
       "    (1:MaxPool_Node): MaxPoolNode(node_id=1, )\n",
       "    (2:Conv_Node): ConvNode(node_id=2, )\n",
       "    (3:Conv_Node): ConvNode(node_id=3, )\n",
       "    (4:Conv_Node): ConvNode(node_id=4, )\n",
       "    (5:Input_Node): InputNode(node_id=5, channels=1, height=28, width=28, )\n",
       "  )\n",
       "  (input_node): InputNode(node_id=5, channels=1, height=28, width=28, )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3fb15110a6c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[1;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'forward'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[1;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[0m\u001b[0;32m    954\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m                             check_tolerance, strict, _force_outplace, _module_class)\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m   1107\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"forward\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\genotype.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, node, tensor)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'zeros'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[0m\u001b[0;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_pad\u001b[1;34m(input, pad, mode, value)\u001b[0m\n\u001b[0;32m   3548\u001b[0m                 _pad, (input,), input, pad, mode=mode, value=value)\n\u001b[0;32m   3549\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Padding length must be divisible by 2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3550\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Padding length too large'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3551\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_pad_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "if torch.cuda.is_available():\n",
    "     images= images.to(device).cuda(device)\n",
    "# cont.update_device(device)\n",
    "# cont.to(device)\n",
    "\n",
    "grid = torchvision.utils.make_grid(images).to(device).cuda()\n",
    "\n",
    "\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(cont, images)\n",
    "del images\n",
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "lr = 0.8\n",
    "# optimizer = optim.Adam(cont.parameters(), lr=lr,)   \n",
    "optimizer = optim.Adam(cont.module_dict.parameters(), lr=lr,)  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# can add milestones in later if needed\n",
    "# milestones = [k for k in range(0, num_epochs*len(trainloader), 50)]\n",
    "\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dbc9c9a788f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         scheduler.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mbatch_et\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_tt = np.empty(shape=(10,))\n",
    "k=0\n",
    "num_epochs = 2\n",
    "start_t = default_timer()\n",
    "for epoch in range(num_epochs-1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        batch_st = default_timer() \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = [d.to(device).cuda(device) for d in data]\n",
    "        inputs.requires_grad = True\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "        outputs = cont(inputs)\n",
    "        loss = criterion(outputs, labels).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for p in cont.parameters():\n",
    "                \n",
    "#                 p.sub_(lr* p.grad)\n",
    "#             print(torch.all(p.grad.eq(0)))\n",
    "#             p = []\n",
    "        \n",
    "#         scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        batch_et = default_timer()\n",
    "        \n",
    "        batch_tt[k] = batch_et - batch_st\n",
    "        \n",
    "        k+=1\n",
    "        \n",
    "        if i % 10 == 9:    # every 10 batches...\n",
    "            \n",
    "            \n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('Training loss',\n",
    "                            running_loss / 10,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            writer.add_scalar('Learning rate',+\n",
    "                            optimizer.param_groups[0]['lr'],\n",
    "                            epoch * len(trainloader) + i)\n",
    "            writer.add_scalar('Average batch time',\n",
    "                            np.mean(batch_tt).item(),\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            batch_tt = np.empty(shape=(10,))\n",
    "            k=0\n",
    "            \n",
    "#         if i > 50:\n",
    "#             break\n",
    "        \n",
    "\n",
    "\n",
    "end_t = default_timer()\n",
    "\n",
    "total_t = end_t - start_t\n",
    "\n",
    "writer.add_scalar('Total training time',\n",
    "                   total_t,\n",
    "                epoch * len(trainloader) + i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-1.5990e-01, -9.7942e-02,  5.0226e-03,  ...,  1.9742e-01,\n",
       "             1.4729e-01,  1.0208e-01],\n",
       "           [-7.6299e-02, -6.8681e-02, -4.5328e-02,  ...,  2.4870e-02,\n",
       "            -2.7810e-02,  7.8350e-02],\n",
       "           [-5.1901e-02, -6.1059e-02, -1.5014e-02,  ...,  1.1504e-01,\n",
       "             1.2390e-01,  2.0242e-01],\n",
       "           ...,\n",
       "           [ 1.5141e-01,  4.3206e-02, -7.1445e-02,  ...,  1.0480e-01,\n",
       "            -9.0759e-06,  6.1600e-02],\n",
       "           [ 1.0759e-01, -6.3953e-02,  1.6421e-01,  ...,  1.7835e-01,\n",
       "            -7.7521e-02,  8.9601e-02],\n",
       "           [ 1.7176e-01,  5.1343e-02, -1.3152e-02,  ..., -4.2158e-03,\n",
       "             4.9071e-02, -4.8466e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.1937e-02,  1.8164e-01,  1.8973e-01,  ..., -5.8223e-03,\n",
       "             3.5658e-02,  9.4269e-02],\n",
       "           [-1.7112e-01,  9.7162e-02, -3.1565e-03,  ..., -7.0301e-02,\n",
       "             1.8508e-01,  8.9966e-02],\n",
       "           [-1.6398e-01,  5.3017e-02,  7.3726e-02,  ..., -9.5444e-02,\n",
       "            -4.4003e-02,  1.4091e-01],\n",
       "           ...,\n",
       "           [-1.3385e-01,  1.3939e-03, -1.8135e-01,  ...,  4.4920e-03,\n",
       "            -7.3203e-02,  1.4611e-01],\n",
       "           [-1.5426e-01, -6.2293e-02, -1.7896e-02,  ...,  1.1012e-01,\n",
       "            -5.9048e-03,  1.5658e-01],\n",
       "           [ 1.2283e-01, -1.9205e-01,  7.6853e-02,  ...,  1.8903e-01,\n",
       "            -8.2257e-02,  9.5414e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.3248e-02, -5.5211e-02, -7.2681e-02,  ...,  5.4796e-03,\n",
       "             1.4298e-01,  5.3818e-02],\n",
       "           [ 1.0207e-01,  2.3275e-03, -8.1739e-02,  ...,  9.8285e-02,\n",
       "            -1.9700e-02,  1.7947e-01],\n",
       "           [ 1.7920e-01, -3.5690e-02,  4.0981e-03,  ..., -1.9080e-01,\n",
       "            -6.9812e-02,  1.1733e-01],\n",
       "           ...,\n",
       "           [ 6.8322e-02,  5.4200e-02, -3.8376e-02,  ..., -3.5981e-02,\n",
       "            -1.5726e-01, -1.6865e-02],\n",
       "           [-5.5672e-02, -1.9953e-01, -7.4768e-02,  ..., -1.8954e-01,\n",
       "            -1.5066e-01, -1.3166e-01],\n",
       "           [-3.0505e-02, -1.6385e-01, -5.3644e-02,  ..., -8.1707e-03,\n",
       "            -9.1821e-02,  6.2543e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.9640e-02, -7.3919e-02, -1.4099e-01,  ..., -1.7596e-01,\n",
       "             1.6735e-01, -2.0376e-02],\n",
       "           [ 9.7194e-02, -1.9912e-01, -1.0344e-01,  ..., -7.7119e-02,\n",
       "            -4.7041e-02,  1.1976e-01],\n",
       "           [ 1.1600e-02,  6.1269e-02,  4.0335e-02,  ..., -1.3143e-01,\n",
       "             1.8040e-01,  1.4772e-01],\n",
       "           ...,\n",
       "           [-1.3141e-02,  4.2827e-02, -5.5238e-02,  ...,  1.7334e-01,\n",
       "             6.0111e-02,  1.3455e-01],\n",
       "           [-6.8769e-02, -3.0789e-02, -1.7529e-02,  ...,  1.7617e-01,\n",
       "            -4.6167e-02, -4.6144e-02],\n",
       "           [-4.0186e-02, -1.9687e-01, -1.0848e-01,  ...,  2.3603e-02,\n",
       "             1.3195e-01,  1.6205e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.7258e-02, -1.8490e-01, -1.9470e-01,  ...,  8.8506e-02,\n",
       "             5.1941e-02,  7.1144e-03],\n",
       "           [ 1.7936e-02,  1.2385e-01, -1.1980e-03,  ..., -4.7335e-02,\n",
       "             6.4082e-02, -6.0777e-02],\n",
       "           [ 5.6281e-02,  7.5180e-02,  1.5922e-01,  ...,  2.5065e-02,\n",
       "             2.9736e-02, -1.8525e-01],\n",
       "           ...,\n",
       "           [ 1.2279e-01, -1.1383e-02,  7.7128e-02,  ..., -1.1860e-01,\n",
       "            -2.5905e-02,  6.2405e-02],\n",
       "           [-1.5633e-01, -1.0795e-01, -2.0112e-01,  ..., -1.6681e-01,\n",
       "             5.1555e-02,  1.2370e-02],\n",
       "           [ 4.8439e-02, -1.6821e-01,  2.7520e-02,  ..., -1.2064e-01,\n",
       "            -6.9681e-02,  6.6301e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.2226e-02, -8.0124e-03, -1.6611e-01,  ...,  3.4243e-02,\n",
       "             1.4296e-02,  4.9845e-02],\n",
       "           [-7.5890e-02, -1.7271e-01, -9.2039e-02,  ..., -5.7199e-02,\n",
       "             2.1592e-02,  1.9262e-02],\n",
       "           [-7.2020e-02, -1.8591e-01, -5.7096e-02,  ...,  1.4564e-01,\n",
       "             1.7117e-01, -7.6180e-02],\n",
       "           ...,\n",
       "           [-7.3659e-02, -4.0230e-02, -3.9004e-03,  ...,  1.3210e-01,\n",
       "            -5.5328e-02,  4.6880e-02],\n",
       "           [-2.8578e-02,  5.0958e-02,  1.1931e-01,  ..., -5.8856e-02,\n",
       "            -1.5853e-01, -1.2103e-01],\n",
       "           [-4.9190e-02, -6.5898e-02,  8.0315e-03,  ...,  1.3173e-01,\n",
       "            -6.3942e-02, -1.4959e-01]]]], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 6.8167e-02,  1.7427e-01,  7.1828e-02,  5.9750e-02,  1.6582e-01,\n",
       "          1.4754e-01,  7.2470e-02,  1.3732e-01,  1.3407e-01,  2.5424e-02,\n",
       "          1.6653e-01, -1.4432e-01,  1.3041e-01,  3.2491e-02,  1.2896e-01,\n",
       "         -1.8139e-01, -2.4734e-02,  4.3505e-02, -6.2008e-03, -6.5936e-02,\n",
       "          1.7903e-01, -4.3727e-02,  1.4897e-01,  5.1953e-03,  3.4557e-02,\n",
       "         -4.5972e-02, -1.6058e-01, -1.5312e-01, -1.8340e-01, -2.0071e-01,\n",
       "          1.8027e-01,  1.2841e-01, -6.6038e-02, -1.8722e-02, -1.0047e-01,\n",
       "         -7.6401e-02,  1.9920e-01,  7.2139e-02, -2.6995e-02,  5.9052e-02,\n",
       "         -7.2766e-02, -1.5916e-03,  5.8029e-02,  4.8098e-03,  1.2133e-01,\n",
       "         -6.7689e-02, -3.5042e-03, -4.9329e-02,  9.8978e-03, -4.3473e-02,\n",
       "          1.8010e-01,  3.3872e-02, -1.0510e-01, -6.6082e-02,  4.4661e-02,\n",
       "          1.3621e-01, -1.8224e-02,  1.3655e-01, -1.2544e-01,  1.5500e-01,\n",
       "          1.4651e-01,  1.6677e-01,  1.4051e-01,  5.2027e-02,  1.8990e-01,\n",
       "         -1.5002e-01, -1.7871e-01,  1.1446e-01, -2.9816e-02, -7.8911e-02,\n",
       "         -1.9568e-01, -1.4031e-01, -5.2782e-02,  1.0778e-01, -1.0700e-01,\n",
       "         -6.6215e-02,  3.5220e-02, -1.7169e-01,  4.2563e-02,  1.8897e-01,\n",
       "          1.1847e-01, -2.0316e-02,  1.3712e-01, -3.3497e-02, -1.0172e-01,\n",
       "         -1.8316e-01, -2.4232e-02,  1.2613e-01,  3.8420e-02, -1.2612e-01,\n",
       "          6.6982e-02,  5.8687e-02,  7.0531e-02,  2.1777e-03, -3.0621e-02,\n",
       "         -7.8647e-02,  1.7633e-01,  2.0124e-01,  8.9417e-02, -6.5040e-02,\n",
       "         -6.8200e-02, -4.9139e-02,  7.5341e-02,  1.8835e-01, -2.8449e-02,\n",
       "          5.9081e-02,  4.8040e-02,  5.2645e-03, -1.5314e-02, -1.0487e-01,\n",
       "         -1.7193e-01, -1.7425e-02,  2.9920e-02, -6.4032e-02, -1.0783e-01,\n",
       "         -2.7768e-02, -1.9537e-01, -1.2437e-01, -3.4430e-02,  1.1706e-01,\n",
       "          1.7948e-01,  6.6160e-02,  9.2733e-02,  4.8882e-02,  1.9044e-01,\n",
       "          9.1907e-02,  1.8012e-02,  3.2363e-02,  1.7917e-02, -6.4927e-02,\n",
       "         -4.4376e-02, -1.1045e-01,  3.2315e-02,  1.3014e-01, -6.1121e-02,\n",
       "          1.1676e-02, -3.2528e-02,  5.4819e-02, -2.5784e-02, -4.3140e-02,\n",
       "         -2.2195e-02, -4.3537e-02,  1.2871e-01, -7.4298e-02, -5.4494e-02,\n",
       "          1.2225e-01,  1.2714e-01, -1.6212e-01, -1.2290e-01, -3.3866e-03,\n",
       "         -1.0470e-04, -1.5437e-01,  1.5726e-02,  8.2818e-02, -7.1467e-02,\n",
       "         -1.2291e-01,  1.8606e-01,  3.7953e-02,  9.0964e-02, -1.4184e-01,\n",
       "          1.2847e-01,  5.1361e-02, -1.2274e-02,  8.9286e-02,  1.8987e-01,\n",
       "          1.6426e-01,  6.5310e-02,  1.8609e-01, -1.5264e-02, -1.9693e-01,\n",
       "          1.5901e-01, -1.0330e-01, -5.4901e-02,  6.1161e-02, -6.3650e-02,\n",
       "         -1.5566e-01, -9.0725e-02, -3.8710e-02,  2.9677e-02,  5.4303e-02,\n",
       "         -4.4934e-02,  3.1172e-02, -7.4079e-02, -5.8764e-03,  6.1510e-02,\n",
       "         -1.2898e-01,  1.8772e-01, -1.7915e-01, -3.2454e-02, -1.3055e-01,\n",
       "          1.0717e-01,  9.4811e-02,  2.1185e-02, -1.7109e-01,  3.3438e-02,\n",
       "         -9.8502e-02,  8.7848e-02, -8.2520e-02,  2.6471e-02,  3.9794e-03,\n",
       "          1.0252e-01, -1.2017e-02, -1.3428e-01, -8.5310e-02, -1.5915e-02,\n",
       "          1.9002e-01,  8.3059e-02,  2.7935e-02, -7.5448e-02, -1.2517e-01,\n",
       "         -1.5073e-01, -1.8854e-01,  1.9113e-01,  9.4833e-02,  1.6288e-01,\n",
       "         -4.2656e-02,  1.6889e-01,  8.0071e-02, -7.5490e-02, -2.6175e-02,\n",
       "         -6.2019e-02,  1.4742e-01,  7.5616e-02,  8.2509e-02,  2.7313e-02,\n",
       "          1.2571e-01, -9.1052e-02, -1.9082e-01,  5.2890e-02, -1.3257e-01,\n",
       "         -2.0476e-02, -1.5127e-01, -1.6548e-01, -4.9224e-02, -1.3146e-01,\n",
       "          4.3257e-02,  7.0461e-02,  1.6033e-02,  1.6367e-01, -1.7346e-02,\n",
       "         -1.5203e-02, -3.6301e-02, -1.0944e-01, -1.5484e-01,  9.2078e-02,\n",
       "          5.3148e-02,  1.7428e-01,  6.2901e-02,  1.4461e-01,  2.0032e-01,\n",
       "          1.0168e-01, -1.3772e-01, -5.2062e-02,  1.3379e-01,  1.0547e-01,\n",
       "          6.1239e-02,  8.2060e-02, -1.5447e-02,  3.0699e-02, -8.6161e-02,\n",
       "          1.1106e-01, -1.5142e-01, -1.0463e-01,  2.5737e-02, -7.3332e-02,\n",
       "         -8.0829e-02, -9.1622e-02,  5.9498e-02,  1.5668e-01,  1.2970e-01,\n",
       "          3.7511e-02,  1.7395e-01,  1.7871e-02,  5.8868e-02, -1.2082e-01,\n",
       "         -5.3043e-03,  4.2380e-02,  3.1874e-02, -1.0856e-04, -1.1715e-01,\n",
       "          4.5006e-02,  5.2657e-02,  1.4530e-01, -1.4787e-01, -2.4275e-02,\n",
       "         -1.0786e-01,  3.9140e-02, -7.5809e-02,  8.5338e-02,  6.2458e-02,\n",
       "         -1.4588e-01,  6.7843e-02, -5.0131e-02,  1.9522e-01,  1.5338e-01,\n",
       "         -4.5785e-02,  7.5339e-02,  8.0621e-02,  5.5636e-02, -7.2135e-02,\n",
       "         -4.7704e-02,  3.6254e-03, -1.0946e-02, -7.9055e-02,  7.5346e-02,\n",
       "          5.7315e-02,  9.2809e-02, -1.0175e-01, -5.7346e-02, -6.0016e-02,\n",
       "         -6.1106e-02,  1.3329e-01,  1.2572e-01, -7.0544e-03, -1.4502e-01,\n",
       "         -1.1292e-01, -2.0134e-02,  1.5554e-01, -4.1603e-02,  1.4262e-01,\n",
       "          1.9015e-01, -1.2466e-01,  1.2922e-01, -1.4496e-01, -5.4652e-02,\n",
       "          1.6897e-02, -7.0841e-02,  7.0609e-02,  7.5779e-02, -1.1227e-01,\n",
       "         -1.4551e-02,  4.3763e-02,  8.1951e-02,  7.4855e-02, -1.5653e-01,\n",
       "         -1.5028e-01,  4.6875e-02, -4.8786e-02,  1.2711e-01,  1.9745e-01,\n",
       "          7.9750e-02, -1.3858e-03, -6.1062e-02,  2.6581e-02, -1.2918e-02,\n",
       "          3.5895e-02, -9.3168e-02, -4.1284e-02,  6.6618e-02, -5.3816e-02,\n",
       "          1.5841e-02, -8.3886e-02,  8.4826e-03,  2.8857e-02, -7.6782e-02,\n",
       "         -6.4913e-02,  2.6589e-02,  1.4262e-01,  1.3049e-02, -1.2823e-02,\n",
       "         -1.2079e-01,  6.2057e-02,  7.9391e-02, -5.8023e-02,  9.4921e-02,\n",
       "          7.7148e-02,  8.3707e-02, -1.5385e-01, -1.2525e-01, -1.9638e-02,\n",
       "         -3.9498e-02, -1.1942e-02, -1.3671e-01,  8.8016e-04,  1.0720e-01,\n",
       "          2.1889e-02, -7.4919e-02, -1.7721e-01,  3.8316e-02,  7.0471e-02,\n",
       "         -1.3011e-02, -3.2194e-02, -4.6542e-02,  1.6512e-01, -6.9677e-02,\n",
       "         -1.0807e-01, -1.0373e-01,  2.8600e-02, -2.2669e-02,  1.8077e-01,\n",
       "          6.9956e-02,  8.9127e-03, -1.8365e-01, -1.1247e-01,  1.9685e-01,\n",
       "          3.7107e-03,  6.5596e-02,  7.7863e-02, -4.5734e-02, -1.5122e-02,\n",
       "         -1.2089e-01,  1.5620e-01,  4.8382e-02, -1.9863e-01,  1.1566e-01,\n",
       "         -1.7558e-01, -8.0683e-02, -3.6024e-02,  9.1467e-02, -5.9203e-02,\n",
       "         -6.1896e-02,  7.5169e-02,  3.1257e-02,  4.3976e-02, -9.8494e-02,\n",
       "         -6.1396e-03, -1.4352e-02, -6.0709e-02, -4.8127e-02, -1.1525e-01,\n",
       "         -8.0372e-02,  2.8901e-02, -5.2233e-02,  6.7757e-03,  9.1734e-02,\n",
       "          1.3070e-01,  1.5953e-01,  8.8138e-03,  1.3401e-01, -7.6659e-02,\n",
       "          8.3603e-02, -9.5557e-02,  4.7013e-02,  5.9766e-03,  1.0011e-02,\n",
       "          7.6062e-02, -6.6325e-02,  3.0848e-02, -1.5658e-02,  1.9066e-01,\n",
       "          2.8279e-02,  1.7440e-01, -6.0070e-02,  1.4882e-02,  1.5123e-01,\n",
       "         -6.4650e-02, -9.7383e-02, -5.3190e-02,  4.5808e-02,  8.4361e-02,\n",
       "         -1.4845e-01,  1.9642e-01, -7.1961e-02,  1.9631e-01,  1.0865e-01,\n",
       "         -1.4355e-01, -9.7917e-02,  1.0385e-01,  4.3094e-02,  6.6414e-02,\n",
       "          1.5030e-01,  1.5010e-01, -1.5071e-02, -4.5050e-02,  1.6611e-01,\n",
       "          1.6992e-02, -1.9860e-01,  1.5021e-02,  2.5937e-02, -2.2218e-02,\n",
       "          2.4087e-02, -1.1881e-01, -1.7577e-01,  7.1243e-02, -1.6439e-01,\n",
       "         -7.3573e-02, -1.3193e-01, -1.6456e-01, -1.7228e-01,  3.6621e-02,\n",
       "          4.2445e-02,  1.0091e-01, -1.3382e-01, -3.0692e-02, -1.9432e-01,\n",
       "         -9.3457e-02, -5.7430e-03,  1.5417e-01, -1.3316e-02, -1.4445e-01,\n",
       "         -1.9126e-01, -1.6478e-01,  1.6050e-01, -4.9046e-02,  3.3289e-02,\n",
       "          1.3652e-01,  1.6172e-01, -9.5312e-02, -5.3180e-02,  1.6389e-02,\n",
       "         -1.8916e-02, -9.7877e-02, -5.0261e-02,  2.6980e-02, -1.2025e-01,\n",
       "         -1.5392e-01,  5.7081e-02, -3.1825e-02,  1.4998e-02,  3.3995e-03,\n",
       "          6.0985e-03, -7.0484e-02], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0601, 1.0600, 0.9401, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601, 0.9400,\n",
       "         0.9400, 0.9400, 1.0600, 0.9399, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400,\n",
       "         0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0601,\n",
       "         1.0592, 1.0601, 1.0600, 1.0599, 1.0601, 1.0600, 1.0600, 1.0600, 1.0600,\n",
       "         0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "         0.9399, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9399,\n",
       "         0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 0.9399, 0.9400,\n",
       "         1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0600,\n",
       "         0.9399, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601,\n",
       "         1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "         1.0598, 0.9400, 1.0600, 0.9400, 1.0601, 1.0600, 0.9400, 0.9400, 1.0599,\n",
       "         1.0600, 1.0600, 0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600,\n",
       "         0.9400, 1.0601, 1.0601, 0.9400, 1.0600, 1.0601, 0.9400, 1.0600, 1.0600,\n",
       "         1.0600, 0.9399, 1.0601, 0.9401, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400,\n",
       "         1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "         0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 1.0601,\n",
       "         1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "         1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 0.9400, 0.9401,\n",
       "         1.0600, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400, 1.0600, 1.0601, 0.9400,\n",
       "         1.0600, 1.0600, 0.9399, 1.0600, 1.0600, 1.0600, 1.0601, 0.9400, 1.0600,\n",
       "         1.0598, 0.9400, 1.0600, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "         1.0600, 1.0599, 0.9400, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600, 1.0600,\n",
       "         1.0601, 0.9403, 0.9400, 0.9399, 1.0601, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "         1.0601, 1.0601, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 0.9399,\n",
       "         0.9400, 0.9400, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9401, 1.0600,\n",
       "         0.9401, 1.0600, 0.9400, 0.9400, 1.0601, 0.9400, 1.0600, 1.0600, 1.0601,\n",
       "         1.0599, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 1.0600, 1.0600,\n",
       "         1.0600, 1.0600, 1.0601, 0.9400, 1.0600, 0.9400, 1.0599, 0.9399, 1.0601,\n",
       "         0.9400, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399, 1.0600, 0.9401,\n",
       "         1.0601, 1.0600, 1.0600, 0.9400, 0.9399, 1.0600, 0.9399, 0.9400, 0.9400,\n",
       "         0.9400, 0.9402, 1.0600, 1.0600, 1.0600, 0.9399, 0.9400, 0.9400, 1.0601,\n",
       "         1.0601, 1.0601, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 0.9400,\n",
       "         1.0600, 0.9402, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "         0.9399, 1.0600, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400,\n",
       "         1.0600, 0.9402, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "         1.0600, 0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400,\n",
       "         1.0601, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0601, 0.9399,\n",
       "         0.9400, 1.0600, 0.9401, 1.0600, 0.9400, 0.9399, 1.0600, 1.0600, 1.0600,\n",
       "         0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0600, 0.9399, 1.0600,\n",
       "         1.0600, 0.9400, 1.0598, 1.0601, 1.0600, 0.9400, 0.9400, 0.9400, 0.9401,\n",
       "         0.9400, 1.0600, 0.9399, 1.0601, 0.9401, 1.0600, 0.9399, 1.0601, 1.0599,\n",
       "         0.9399, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "         0.9401, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600, 0.9400, 0.9400, 1.0601,\n",
       "         1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 1.0581, 0.9399, 1.0600,\n",
       "         1.0600, 1.0601, 1.0601, 0.9400, 1.0600, 0.9399, 1.0600, 1.0601, 0.9401,\n",
       "         1.0601, 0.9400, 1.0601, 0.9400, 1.0601, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "         1.0601, 0.9400, 0.9400, 1.0601, 1.0600, 1.0600, 0.9400, 1.0598, 1.0600,\n",
       "         0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 0.9407, 1.0600, 1.0600,\n",
       "         0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600,\n",
       "         0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600, 1.0601,\n",
       "         1.0600, 1.0601, 1.0600, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "         0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "         1.0601, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "         1.0600, 1.0601, 0.9400, 0.9402, 0.9399, 1.0600, 1.0601, 1.0601, 0.9400,\n",
       "         1.0600, 0.9400, 0.9399, 1.0600, 1.0601, 1.0600, 1.0601, 1.0600, 0.9400,\n",
       "         0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 0.9401,\n",
       "         1.0600, 1.0598, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0597, -0.0600,  0.0600,\n",
       "          0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "         -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0599,  0.0599,  0.0600,\n",
       "          0.0512,  0.0600, -0.0600, -0.0600,  0.0600, -0.0598, -0.0600, -0.0600,\n",
       "         -0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "         -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "         -0.0600, -0.0600, -0.0600, -0.0600, -0.0596,  0.0599,  0.0598,  0.0600,\n",
       "         -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "          0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          0.0600, -0.0600, -0.0600,  0.0600,  0.0599, -0.0600,  0.0600, -0.0600,\n",
       "         -0.0600, -0.0594,  0.0600,  0.0600, -0.0600, -0.0598, -0.0600, -0.0600,\n",
       "         -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "         -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "          0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          0.0600, -0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "         -0.0600,  0.0600,  0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0597,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600,\n",
       "          0.0600,  0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600, -0.0600,\n",
       "          0.0600,  0.0599,  0.0600,  0.0593, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          0.0600, -0.0600,  0.0600,  0.0600,  0.0599, -0.0600,  0.0600,  0.0600,\n",
       "          0.0600,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0577, -0.0600,\n",
       "          0.0600, -0.0600,  0.0595, -0.0600, -0.0600, -0.0600,  0.0597, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0598,\n",
       "         -0.0600,  0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "         -0.0600,  0.0600, -0.0600, -0.0600,  0.0596, -0.0600, -0.0600,  0.0600,\n",
       "          0.0600, -0.0600,  0.0600, -0.0600, -0.0599,  0.0600, -0.0600,  0.0600,\n",
       "          0.0599, -0.0584,  0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          0.0600, -0.0599, -0.0600, -0.0600,  0.0600, -0.0600,  0.0489, -0.0600,\n",
       "         -0.0599,  0.0600, -0.0599,  0.0600,  0.0586, -0.0600,  0.0600,  0.0600,\n",
       "         -0.0598,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0592,  0.0600,\n",
       "          0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          0.0600, -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          0.0548, -0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0598,  0.0600,\n",
       "         -0.0600, -0.0598, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,  0.0600,\n",
       "          0.0596, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "         -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599, -0.0600,  0.0600,\n",
       "         -0.0600, -0.0599, -0.0600, -0.0600, -0.0599,  0.0599, -0.0600, -0.0600,\n",
       "          0.0600,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "         -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "          0.0600, -0.0598, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          0.0578,  0.0600,  0.0600,  0.0576, -0.0598, -0.0600, -0.0599,  0.0598,\n",
       "          0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "         -0.0600,  0.0599,  0.0600,  0.0600, -0.0599,  0.0600,  0.0599, -0.0600,\n",
       "          0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0589,  0.0600,\n",
       "          0.0600,  0.0600,  0.0599,  0.0600, -0.0600, -0.0598, -0.0600, -0.0598,\n",
       "          0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600, -0.0600, -0.0586,\n",
       "         -0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,\n",
       "         -0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0537,  0.0600,  0.0600,\n",
       "         -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0566,\n",
       "         -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "          0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,\n",
       "          0.0600,  0.0600,  0.0600,  0.0600, -0.0598, -0.0600, -0.0600, -0.0600,\n",
       "         -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0588,  0.0600,\n",
       "          0.0600, -0.0600, -0.0600,  0.0600,  0.0573,  0.0599, -0.0600, -0.0600,\n",
       "          0.0600, -0.0600, -0.0600, -0.0599,  0.0600, -0.0600, -0.0600,  0.0600,\n",
       "         -0.0600, -0.0600, -0.0600, -0.0600,  0.0571,  0.0598, -0.0600, -0.0600,\n",
       "         -0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.2453, -0.0800, -0.0261,  0.2573,  0.0137],\n",
       "           [ 0.1347, -0.0993, -0.0091,  0.1237,  0.2133],\n",
       "           [-0.1203,  0.1583, -0.1118,  0.0746, -0.0516],\n",
       "           [ 0.0211,  0.1537,  0.0209, -0.0052, -0.1673],\n",
       "           [ 0.0071, -0.1311, -0.0563,  0.0044,  0.0009]]],\n",
       " \n",
       " \n",
       "         [[[-0.0394, -0.1376, -0.1337, -0.1827,  0.1238],\n",
       "           [ 0.1211, -0.0602, -0.0912, -0.1345, -0.0577],\n",
       "           [-0.2154, -0.1498, -0.0292,  0.0635, -0.0607],\n",
       "           [-0.0051,  0.2468, -0.2046, -0.0599, -0.1780],\n",
       "           [-0.0299, -0.1748, -0.1545, -0.1388, -0.1679]]],\n",
       " \n",
       " \n",
       "         [[[-0.2593, -0.0949,  0.1343, -0.0551,  0.2540],\n",
       "           [-0.0428, -0.1399, -0.0779,  0.0574,  0.1892],\n",
       "           [-0.2128, -0.1716,  0.1081,  0.0639, -0.0592],\n",
       "           [-0.1870,  0.1170, -0.1113, -0.1670,  0.0479],\n",
       "           [ 0.1192, -0.1164,  0.0632,  0.0048, -0.2199]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0081, -0.0432, -0.1522, -0.0360,  0.1212],\n",
       "           [ 0.0993, -0.2594,  0.0096, -0.1371, -0.1064],\n",
       "           [-0.0940,  0.0671, -0.1217,  0.2246, -0.1447],\n",
       "           [-0.0669,  0.0071,  0.2307,  0.0134, -0.2541],\n",
       "           [-0.0932, -0.0058, -0.2276, -0.2369, -0.0368]]],\n",
       " \n",
       " \n",
       "         [[[-0.0216, -0.1973,  0.1075,  0.1047, -0.0592],\n",
       "           [-0.2475, -0.2583,  0.0632, -0.0388,  0.0058],\n",
       "           [-0.0071,  0.0473,  0.0826,  0.1176,  0.2552],\n",
       "           [ 0.1211, -0.0400,  0.0058, -0.1140,  0.0338],\n",
       "           [-0.0885,  0.1182,  0.1937,  0.1002,  0.0021]]],\n",
       " \n",
       " \n",
       "         [[[-0.0262, -0.0207, -0.0044, -0.1043,  0.0903],\n",
       "           [ 0.2437, -0.0761,  0.0686,  0.1320, -0.2127],\n",
       "           [-0.1985, -0.1377, -0.0134, -0.2302, -0.0669],\n",
       "           [-0.1081, -0.2339,  0.0013,  0.1274, -0.2081],\n",
       "           [-0.2247, -0.2600, -0.0780,  0.0998,  0.0049]]]], device='cuda:1',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0288,  0.1469,  0.2572,  0.1455,  0.0588,  0.0765, -0.1986,  0.0944,\n",
       "         -0.2509,  0.0802, -0.1385, -0.0133, -0.0170,  0.1253, -0.1885, -0.0091,\n",
       "          0.1322, -0.0832,  0.0583, -0.1532,  0.1548,  0.2562,  0.0436,  0.2036,\n",
       "          0.0478, -0.0392, -0.0107,  0.0334, -0.2536,  0.0020, -0.0894, -0.1814,\n",
       "          0.1275,  0.0119,  0.0621, -0.2426,  0.0614,  0.0997,  0.1022,  0.1255,\n",
       "          0.2229, -0.0302, -0.1128, -0.0646, -0.0236,  0.0625,  0.0871, -0.0654,\n",
       "         -0.1177,  0.0190, -0.2554,  0.0629, -0.0415, -0.1036,  0.0532,  0.0410,\n",
       "          0.2405,  0.1343, -0.0100, -0.0317, -0.0856,  0.2000, -0.1151, -0.1362],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "         1.0600, 0.9399, 1.0600, 0.9399, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600,\n",
       "         1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "         1.0600, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "         0.9399, 1.0600, 1.0600, 0.9400, 1.0601, 0.9399, 1.0600, 1.0600, 0.9400,\n",
       "         1.0601, 1.0601, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "         0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "         1.0600], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "         -0.0600, -0.0600,  0.0600,  0.0598,  0.0600, -0.0594, -0.0600, -0.0600,\n",
       "         -0.0600,  0.0600, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "         -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599,  0.0600,\n",
       "          0.0600, -0.0599,  0.0600, -0.0598,  0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.3269,  0.3376,  0.1132],\n",
       "           [-0.3058,  0.0294,  0.2141],\n",
       "           [-0.0527,  0.0887,  0.0372]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0016, -0.2299, -0.0984],\n",
       "           [-0.2386, -0.0527,  0.0149],\n",
       "           [ 0.1953,  0.3674, -0.0410]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1030, -0.2454, -0.1495],\n",
       "           [-0.1238,  0.1354, -0.1034],\n",
       "           [ 0.0923,  0.0624,  0.0144]]],\n",
       " \n",
       " \n",
       "         [[[-0.0386,  0.1073, -0.3635],\n",
       "           [-0.1111, -0.2862, -0.0517],\n",
       "           [ 0.1275, -0.2230, -0.1134]]],\n",
       " \n",
       " \n",
       "         [[[-0.3510, -0.0179,  0.1793],\n",
       "           [ 0.1666, -0.3695, -0.3223],\n",
       "           [-0.1493, -0.3289,  0.0401]]],\n",
       " \n",
       " \n",
       "         [[[-0.0774, -0.0535,  0.0455],\n",
       "           [-0.0977,  0.3613,  0.3804],\n",
       "           [-0.0218,  0.3432, -0.2184]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1901,  0.1241,  0.0148],\n",
       "           [ 0.0026, -0.0838,  0.1118],\n",
       "           [-0.0647,  0.0506,  0.0888]]],\n",
       " \n",
       " \n",
       "         [[[-0.0708,  0.1378, -0.3528],\n",
       "           [-0.0389, -0.3458,  0.2679],\n",
       "           [ 0.1595, -0.0018, -0.0951]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0185, -0.0721,  0.3827],\n",
       "           [ 0.0474,  0.2076,  0.1898],\n",
       "           [-0.1008, -0.1253,  0.0094]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1627, -0.3132, -0.1671],\n",
       "           [-0.0197,  0.0824,  0.1439],\n",
       "           [ 0.2378,  0.0428, -0.1248]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1012,  0.2255, -0.3068],\n",
       "           [ 0.2680,  0.2954,  0.3061],\n",
       "           [ 0.3459, -0.2698,  0.1819]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0948,  0.1303, -0.1320],\n",
       "           [ 0.0118,  0.3515,  0.2337],\n",
       "           [ 0.1739, -0.0960,  0.0334]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0820,  0.2203,  0.2551],\n",
       "           [ 0.2838, -0.2233,  0.3808],\n",
       "           [ 0.1507, -0.1088, -0.2116]]],\n",
       " \n",
       " \n",
       "         [[[-0.0157, -0.2666,  0.3496],\n",
       "           [-0.1649,  0.1017,  0.1674],\n",
       "           [ 0.2523, -0.1366,  0.2932]]],\n",
       " \n",
       " \n",
       "         [[[-0.1053, -0.2206, -0.3085],\n",
       "           [ 0.0172, -0.2193, -0.3585],\n",
       "           [ 0.1307,  0.2647,  0.2088]]],\n",
       " \n",
       " \n",
       "         [[[-0.3489, -0.0409,  0.1418],\n",
       "           [-0.1525, -0.1919, -0.3430],\n",
       "           [ 0.1563,  0.0015, -0.0016]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3790,  0.3453, -0.0246],\n",
       "           [-0.2116, -0.0378,  0.0756],\n",
       "           [-0.1251,  0.1768,  0.3686]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0915,  0.0414,  0.1043],\n",
       "           [-0.0314,  0.1969,  0.0920],\n",
       "           [-0.0232,  0.2952,  0.3034]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1688, -0.0212, -0.1975],\n",
       "           [ 0.1439,  0.2162,  0.1378],\n",
       "           [ 0.2552,  0.1640, -0.0532]]],\n",
       " \n",
       " \n",
       "         [[[-0.2374, -0.2078,  0.3396],\n",
       "           [-0.0753,  0.1338,  0.2909],\n",
       "           [-0.0136, -0.1792, -0.0691]]],\n",
       " \n",
       " \n",
       "         [[[-0.1107,  0.0075,  0.0358],\n",
       "           [ 0.1824, -0.1787,  0.1207],\n",
       "           [-0.2644,  0.3380,  0.1370]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0057,  0.1525,  0.3118],\n",
       "           [ 0.0310, -0.2211, -0.0631],\n",
       "           [ 0.1472, -0.2173,  0.3301]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3352, -0.2602, -0.0159],\n",
       "           [ 0.1570, -0.0295, -0.0747],\n",
       "           [ 0.0281, -0.0734, -0.0079]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1196, -0.2341, -0.3577],\n",
       "           [ 0.1272, -0.1568,  0.1983],\n",
       "           [ 0.0186,  0.0980, -0.2567]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0377, -0.0359,  0.1783],\n",
       "           [-0.1740, -0.1516,  0.0580],\n",
       "           [ 0.0856, -0.3458, -0.1893]]],\n",
       " \n",
       " \n",
       "         [[[-0.2690, -0.3563,  0.2335],\n",
       "           [-0.0411, -0.0981,  0.3489],\n",
       "           [-0.1771, -0.2193, -0.1687]]],\n",
       " \n",
       " \n",
       "         [[[-0.1314, -0.2470,  0.3583],\n",
       "           [-0.2674, -0.3599,  0.0621],\n",
       "           [ 0.1936, -0.1130, -0.1922]]],\n",
       " \n",
       " \n",
       "         [[[-0.2492,  0.3375,  0.0783],\n",
       "           [-0.0212,  0.0599,  0.3692],\n",
       "           [-0.1984, -0.1535, -0.0773]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2603,  0.0260, -0.1428],\n",
       "           [-0.0401, -0.2312, -0.1798],\n",
       "           [-0.0849,  0.0914, -0.0168]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1678, -0.2232,  0.2834],\n",
       "           [ 0.1509, -0.2445,  0.2188],\n",
       "           [ 0.3497, -0.1100,  0.2170]]],\n",
       " \n",
       " \n",
       "         [[[-0.2511,  0.2410,  0.2098],\n",
       "           [-0.0581,  0.1774, -0.0636],\n",
       "           [-0.0036, -0.1822,  0.2093]]],\n",
       " \n",
       " \n",
       "         [[[-0.1864,  0.1593, -0.0715],\n",
       "           [-0.2306,  0.2433,  0.0857],\n",
       "           [ 0.0294,  0.1967,  0.3672]]],\n",
       " \n",
       " \n",
       "         [[[-0.2440,  0.0382,  0.3127],\n",
       "           [-0.3238, -0.2075, -0.2322],\n",
       "           [ 0.1198,  0.2592, -0.1291]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2633,  0.1645,  0.1530],\n",
       "           [-0.1981,  0.2618, -0.1290],\n",
       "           [-0.0431, -0.0884,  0.0061]]],\n",
       " \n",
       " \n",
       "         [[[-0.1068,  0.1621,  0.2843],\n",
       "           [-0.1677,  0.2400, -0.1533],\n",
       "           [-0.2368,  0.0697, -0.0595]]],\n",
       " \n",
       " \n",
       "         [[[-0.3442,  0.1361,  0.0835],\n",
       "           [ 0.0122,  0.1348, -0.1407],\n",
       "           [ 0.1459, -0.1719, -0.0624]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0914,  0.0408, -0.3109],\n",
       "           [ 0.1178, -0.2322,  0.1720],\n",
       "           [-0.1704, -0.1037,  0.2085]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1608, -0.2221,  0.1762],\n",
       "           [-0.3180, -0.1872, -0.0319],\n",
       "           [-0.0112,  0.2361,  0.2956]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1258,  0.3427,  0.2691],\n",
       "           [-0.1393,  0.0355,  0.1253],\n",
       "           [-0.1241,  0.2254,  0.3576]]],\n",
       " \n",
       " \n",
       "         [[[-0.3155,  0.0849,  0.2717],\n",
       "           [-0.2048, -0.0372,  0.3863],\n",
       "           [ 0.1504,  0.0348, -0.2330]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1782,  0.3248,  0.1735],\n",
       "           [-0.2453,  0.3392,  0.1689],\n",
       "           [ 0.2192, -0.3849, -0.2056]]],\n",
       " \n",
       " \n",
       "         [[[-0.2633,  0.1378,  0.1518],\n",
       "           [ 0.0998,  0.1505,  0.1821],\n",
       "           [-0.0589, -0.0480,  0.2372]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0473, -0.0042,  0.0334],\n",
       "           [ 0.2647, -0.1813, -0.2456],\n",
       "           [ 0.2861,  0.2428,  0.1718]]],\n",
       " \n",
       " \n",
       "         [[[-0.0392, -0.2271,  0.3517],\n",
       "           [-0.1371, -0.0698,  0.2699],\n",
       "           [ 0.0666,  0.1801,  0.3521]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3562, -0.1411,  0.1616],\n",
       "           [ 0.2610,  0.1506, -0.0657],\n",
       "           [-0.0699, -0.0612, -0.1657]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3698,  0.2020, -0.2125],\n",
       "           [-0.0877, -0.0151, -0.1401],\n",
       "           [ 0.2638,  0.2625,  0.1872]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1861,  0.2028,  0.0016],\n",
       "           [ 0.2549, -0.3431,  0.3722],\n",
       "           [ 0.2300,  0.0349,  0.3412]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0641,  0.1496,  0.0051],\n",
       "           [-0.0117,  0.1895,  0.1370],\n",
       "           [-0.2003, -0.2441, -0.3928]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1091,  0.0538,  0.2580],\n",
       "           [-0.2588,  0.1165, -0.0851],\n",
       "           [ 0.3182,  0.2742,  0.2786]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0951,  0.1799,  0.0644],\n",
       "           [-0.2126, -0.3342, -0.1788],\n",
       "           [-0.1753,  0.0506, -0.2686]]],\n",
       " \n",
       " \n",
       "         [[[-0.1528, -0.1101, -0.0323],\n",
       "           [-0.1342,  0.0568,  0.1518],\n",
       "           [ 0.1398, -0.1688,  0.1560]]],\n",
       " \n",
       " \n",
       "         [[[-0.2394, -0.1753, -0.2501],\n",
       "           [ 0.1648,  0.0962,  0.0427],\n",
       "           [ 0.3448,  0.2341, -0.1209]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1957, -0.3921,  0.1047],\n",
       "           [ 0.1317, -0.1083, -0.1607],\n",
       "           [ 0.0159, -0.2667, -0.0118]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1196,  0.0910, -0.2165],\n",
       "           [-0.3372,  0.0103,  0.2028],\n",
       "           [-0.2916, -0.0696,  0.2602]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3215, -0.2493,  0.0172],\n",
       "           [-0.1908,  0.1707,  0.3794],\n",
       "           [ 0.1062, -0.3278, -0.1574]]],\n",
       " \n",
       " \n",
       "         [[[-0.2033,  0.2321,  0.0229],\n",
       "           [ 0.1731, -0.0194,  0.1993],\n",
       "           [ 0.1371, -0.2059, -0.0495]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0664, -0.1708, -0.2554],\n",
       "           [-0.3875,  0.0671,  0.0416],\n",
       "           [ 0.1544, -0.2661, -0.0172]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2396,  0.2414,  0.1776],\n",
       "           [ 0.0442,  0.0775, -0.3594],\n",
       "           [ 0.2832, -0.0484,  0.1364]]],\n",
       " \n",
       " \n",
       "         [[[-0.0950, -0.1686,  0.2725],\n",
       "           [ 0.1011,  0.1122,  0.2413],\n",
       "           [-0.2664,  0.1229, -0.0232]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2130,  0.1265, -0.0875],\n",
       "           [-0.3864, -0.1423,  0.0252],\n",
       "           [ 0.0934, -0.1658,  0.2515]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2508,  0.1692,  0.1474],\n",
       "           [-0.0524,  0.3914, -0.2312],\n",
       "           [ 0.1528,  0.3175,  0.3161]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3885,  0.0282, -0.2465],\n",
       "           [ 0.2420,  0.1174,  0.2517],\n",
       "           [ 0.2067,  0.0136, -0.3403]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0145,  0.3831, -0.0084],\n",
       "           [ 0.0364, -0.0421, -0.1523],\n",
       "           [ 0.1596, -0.3494,  0.1648]]],\n",
       " \n",
       " \n",
       "         [[[-0.3706,  0.0076, -0.2769],\n",
       "           [-0.2486, -0.3272,  0.0434],\n",
       "           [ 0.2529, -0.2475, -0.0096]]]], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0435, -0.0704,  0.2645,  0.2072,  0.0744, -0.0911, -0.2215,  0.3429,\n",
       "         -0.0841,  0.2657, -0.3546, -0.1920, -0.0277,  0.0157,  0.2278,  0.1193,\n",
       "         -0.1689,  0.3619, -0.1523, -0.1147,  0.0276,  0.2094,  0.3264,  0.1618,\n",
       "          0.3466, -0.0203, -0.2095, -0.2572,  0.2978,  0.0554, -0.2631,  0.1339,\n",
       "         -0.0883, -0.0553, -0.2902, -0.0872, -0.2794, -0.0442,  0.2209, -0.1531,\n",
       "          0.0538,  0.2231, -0.0400,  0.1907, -0.2147, -0.3298, -0.1419,  0.1246,\n",
       "          0.1688, -0.1833, -0.2531,  0.3512,  0.3374, -0.3904,  0.2344, -0.0654,\n",
       "          0.1455,  0.2170, -0.3737,  0.1172,  0.1883,  0.1038, -0.2175,  0.1139],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9399, 1.0600, 0.9400, 1.0601, 1.0601, 1.0601, 1.0600, 0.9399, 0.9399,\n",
       "         1.0601, 0.9399, 1.0601, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 1.0601,\n",
       "         0.9399, 1.0601, 0.9399, 1.0601, 1.0601, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "         0.9400, 1.0600, 1.0601, 1.0601, 1.0600, 1.0601, 1.0601, 1.0600, 0.9400,\n",
       "         1.0601, 1.0601, 1.0600, 1.0600, 1.0601, 1.0601, 0.9399, 1.0601, 0.9399,\n",
       "         0.9399, 1.0601, 1.0601, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399,\n",
       "         1.0601, 0.9399, 1.0601, 1.0601, 0.9400, 0.9400, 1.0601, 1.0601, 0.9400,\n",
       "         0.9399], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0600,  0.0600, -0.0601,\n",
       "         -0.0601, -0.0600,  0.0601, -0.0601, -0.0600, -0.0601,  0.0600, -0.0601,\n",
       "         -0.0601, -0.0601,  0.0601,  0.0601,  0.0599,  0.0601,  0.0601,  0.0601,\n",
       "          0.0600,  0.0601, -0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0601,\n",
       "          0.0601,  0.0601, -0.0601,  0.0599, -0.0601, -0.0601, -0.0601, -0.0601,\n",
       "         -0.0601, -0.0601,  0.0601, -0.0601, -0.0601, -0.0601, -0.0600,  0.0601,\n",
       "         -0.0601, -0.0601,  0.0600, -0.0601,  0.0601,  0.0600,  0.0601, -0.0600,\n",
       "          0.0601, -0.0600,  0.0601,  0.0601, -0.0601, -0.0601,  0.0600, -0.0601],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0685, -0.0735, -0.0471],\n",
       "           [ 0.0703, -0.0732,  0.0719],\n",
       "           [-0.0601, -0.0651,  0.0486]],\n",
       " \n",
       "          [[ 0.0664,  0.0697,  0.0646],\n",
       "           [ 0.0463,  0.0500,  0.0716],\n",
       "           [ 0.0511,  0.0535,  0.0607]],\n",
       " \n",
       "          [[-0.0713, -0.0466, -0.0524],\n",
       "           [-0.0504, -0.0593, -0.0588],\n",
       "           [-0.0663, -0.0484, -0.0651]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0597, -0.0541, -0.0699],\n",
       "           [-0.0566, -0.0501, -0.0665],\n",
       "           [-0.0694, -0.0609,  0.0635]],\n",
       " \n",
       "          [[-0.0725, -0.0571, -0.0681],\n",
       "           [-0.0563, -0.0719, -0.0703],\n",
       "           [-0.0588, -0.0653, -0.0662]],\n",
       " \n",
       "          [[-0.0608,  0.0588,  0.0556],\n",
       "           [-0.0499,  0.0734,  0.0577],\n",
       "           [-0.0577,  0.0670,  0.0619]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0516, -0.0507, -0.0680],\n",
       "           [ 0.0698,  0.0655, -0.0490],\n",
       "           [-0.0674, -0.0602, -0.0553]],\n",
       " \n",
       "          [[ 0.0567, -0.0654, -0.0642],\n",
       "           [ 0.0689, -0.0563, -0.0605],\n",
       "           [-0.0681, -0.0606, -0.0541]],\n",
       " \n",
       "          [[-0.0618,  0.0678,  0.0563],\n",
       "           [-0.0545,  0.0525,  0.0619],\n",
       "           [ 0.0484,  0.0463,  0.0555]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0511, -0.0553, -0.0494],\n",
       "           [-0.0530,  0.0669,  0.0615],\n",
       "           [-0.0603,  0.0537, -0.0477]],\n",
       " \n",
       "          [[ 0.0701,  0.0729, -0.0677],\n",
       "           [ 0.0578,  0.0559, -0.0735],\n",
       "           [ 0.0497,  0.0619, -0.0639]],\n",
       " \n",
       "          [[ 0.0617, -0.0628, -0.0507],\n",
       "           [ 0.0466, -0.0573, -0.0515],\n",
       "           [ 0.0659,  0.0485, -0.0553]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0532, -0.0501, -0.0548],\n",
       "           [ 0.0633, -0.0671, -0.0606],\n",
       "           [ 0.0660, -0.0462, -0.0465]],\n",
       " \n",
       "          [[-0.0738, -0.0622, -0.0554],\n",
       "           [ 0.0731, -0.0629, -0.0561],\n",
       "           [ 0.0484,  0.0550,  0.0506]],\n",
       " \n",
       "          [[ 0.0721, -0.0504, -0.0471],\n",
       "           [ 0.0686, -0.0638, -0.0629],\n",
       "           [ 0.0659, -0.0722, -0.0562]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0560,  0.0478,  0.0597],\n",
       "           [ 0.0496,  0.0494,  0.0729],\n",
       "           [ 0.0468,  0.0558,  0.0507]],\n",
       " \n",
       "          [[-0.0685, -0.0638, -0.0694],\n",
       "           [ 0.0650,  0.0551,  0.0574],\n",
       "           [ 0.0616,  0.0534,  0.0535]],\n",
       " \n",
       "          [[ 0.0643,  0.0694,  0.0641],\n",
       "           [ 0.0497,  0.0612,  0.0463],\n",
       "           [ 0.0588,  0.0505,  0.0726]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0495,  0.0664,  0.0704],\n",
       "           [-0.0681,  0.0658,  0.0521],\n",
       "           [-0.0729, -0.0647,  0.0683]],\n",
       " \n",
       "          [[-0.0479,  0.0556,  0.0638],\n",
       "           [-0.0481,  0.0612,  0.0548],\n",
       "           [-0.0724,  0.0649,  0.0464]],\n",
       " \n",
       "          [[-0.0560,  0.0711,  0.0506],\n",
       "           [-0.0592,  0.0563,  0.0680],\n",
       "           [-0.0536, -0.0732,  0.0470]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0495,  0.0564,  0.0610],\n",
       "           [ 0.0689, -0.0734, -0.0560],\n",
       "           [ 0.0568, -0.0695, -0.0664]],\n",
       " \n",
       "          [[ 0.0697,  0.0612,  0.0618],\n",
       "           [ 0.0725, -0.0682,  0.0589],\n",
       "           [-0.0713, -0.0538, -0.0605]],\n",
       " \n",
       "          [[ 0.0637,  0.0528,  0.0557],\n",
       "           [ 0.0488,  0.0652,  0.0649],\n",
       "           [ 0.0656,  0.0514,  0.0550]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0475,  0.0577, -0.0557],\n",
       "           [-0.0675, -0.0558, -0.0555],\n",
       "           [-0.0681, -0.0723,  0.0580]],\n",
       " \n",
       "          [[-0.0643, -0.0613,  0.0511],\n",
       "           [-0.0515, -0.0724, -0.0666],\n",
       "           [-0.0504, -0.0547, -0.0733]],\n",
       " \n",
       "          [[ 0.0493,  0.0646,  0.0529],\n",
       "           [ 0.0624,  0.0588,  0.0586],\n",
       "           [ 0.0668, -0.0469, -0.0631]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0615,  0.0600,  0.0504],\n",
       "           [ 0.0479,  0.0606,  0.0473],\n",
       "           [ 0.0529,  0.0630,  0.0605]],\n",
       " \n",
       "          [[-0.0645, -0.0554, -0.0527],\n",
       "           [ 0.0619,  0.0526,  0.0691],\n",
       "           [ 0.0591,  0.0514,  0.0676]],\n",
       " \n",
       "          [[ 0.0496,  0.0515,  0.0528],\n",
       "           [ 0.0702,  0.0676,  0.0737],\n",
       "           [ 0.0601, -0.0470, -0.0606]]],\n",
       " \n",
       " \n",
       "         [[[-0.0711,  0.0702,  0.0731],\n",
       "           [-0.0532, -0.0705, -0.0591],\n",
       "           [-0.0615, -0.0487, -0.0654]],\n",
       " \n",
       "          [[-0.0466,  0.0595,  0.0665],\n",
       "           [ 0.0532, -0.0620, -0.0471],\n",
       "           [ 0.0728, -0.0501, -0.0499]],\n",
       " \n",
       "          [[-0.0685,  0.0534,  0.0610],\n",
       "           [ 0.0628,  0.0704,  0.0568],\n",
       "           [ 0.0474,  0.0714,  0.0694]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0701, -0.0592,  0.0622],\n",
       "           [-0.0520, -0.0712,  0.0604],\n",
       "           [-0.0503, -0.0543,  0.0720]],\n",
       " \n",
       "          [[-0.0696, -0.0674,  0.0505],\n",
       "           [-0.0543,  0.0657,  0.0630],\n",
       "           [-0.0728, -0.0607,  0.0672]],\n",
       " \n",
       "          [[-0.0686, -0.0596, -0.0692],\n",
       "           [-0.0462, -0.0732, -0.0559],\n",
       "           [-0.0694, -0.0712, -0.0686]]]], device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0485, -0.0588, -0.0485, -0.0485,  0.0507, -0.0551,  0.0462, -0.0599,\n",
       "          0.0591, -0.0725,  0.0719,  0.0534, -0.0627,  0.0674, -0.0556, -0.0608,\n",
       "         -0.0696,  0.0606, -0.0500,  0.0496,  0.0522,  0.0577,  0.0512, -0.0582,\n",
       "         -0.0613,  0.0612,  0.0601,  0.0671, -0.0514, -0.0647,  0.0737, -0.0544],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9399, 1.0600, 0.9399, 0.9399, 1.0601, 0.9399, 0.9399, 0.9399, 0.9399,\n",
       "         0.9399, 1.0600, 0.9399, 1.0601, 0.9400, 1.0601, 1.0601, 0.9400, 1.0601,\n",
       "         1.0600, 0.9399, 0.9399, 0.9399, 0.9400, 0.9399, 0.9401, 0.9399, 0.9400,\n",
       "         0.9400, 0.9400, 0.9399, 0.9400, 0.9399], device='cuda:1',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0601, -0.0601, -0.0601, -0.0601, -0.0600, -0.0601,  0.0601, -0.0601,\n",
       "          0.0600,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,  0.0601, -0.0600,\n",
       "         -0.0601, -0.0601, -0.0601,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,\n",
       "          0.0600, -0.0601, -0.0601, -0.0600,  0.0601, -0.0601,  0.0601, -0.0600],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0546,  0.0687,  0.0543,  ...,  0.0662,  0.0577,  0.0519],\n",
       "         [-0.0539, -0.0641, -0.0520,  ..., -0.0554, -0.0499, -0.0689],\n",
       "         [-0.0678, -0.0542, -0.0593,  ..., -0.0581, -0.0615, -0.0501],\n",
       "         ...,\n",
       "         [ 0.0483,  0.0717,  0.0532,  ...,  0.0562,  0.0645,  0.0606],\n",
       "         [-0.0515, -0.0538, -0.0653,  ..., -0.0483, -0.0619, -0.0636],\n",
       "         [ 0.0627,  0.0662,  0.0645,  ...,  0.0602,  0.0595,  0.0714]],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0576,  0.0579,  0.0701,  ..., -0.0676,  0.0651, -0.0672],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0708, -0.0533, -0.0507,  ..., -0.0629,  0.0693, -0.0670],\n",
       "         [-0.0683, -0.0579, -0.0638,  ...,  0.0639, -0.0534, -0.0578],\n",
       "         [ 0.0494, -0.0683,  0.0645,  ...,  0.0494, -0.0626, -0.0676],\n",
       "         ...,\n",
       "         [-0.0626, -0.0664, -0.0557,  ..., -0.0593, -0.0490, -0.0680],\n",
       "         [-0.0689, -0.0652, -0.0678,  ..., -0.0610, -0.0570, -0.0667],\n",
       "         [-0.0643, -0.0709, -0.0576,  ...,  0.0612, -0.0529, -0.0550]],\n",
       "        device='cuda:1', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0687,  0.0668,  0.0645, -0.0582, -0.0487, -0.0568,  0.0591, -0.0634,\n",
       "         -0.0626, -0.0523], device='cuda:1', requires_grad=True)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cont.module_dict.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cont.module_dict.parameters(), lr=lr,)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Controller' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-28f57162d87a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    772\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'Controller' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "cont.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[[[-1.5990e-01, -9.7942e-02,  5.0226e-03,  ...,  1.9742e-01,\n",
       "              1.4729e-01,  1.0208e-01],\n",
       "            [-7.6299e-02, -6.8681e-02, -4.5328e-02,  ...,  2.4870e-02,\n",
       "             -2.7810e-02,  7.8350e-02],\n",
       "            [-5.1901e-02, -6.1059e-02, -1.5014e-02,  ...,  1.1504e-01,\n",
       "              1.2390e-01,  2.0242e-01],\n",
       "            ...,\n",
       "            [ 1.5141e-01,  4.3206e-02, -7.1445e-02,  ...,  1.0480e-01,\n",
       "             -9.0759e-06,  6.1600e-02],\n",
       "            [ 1.0759e-01, -6.3953e-02,  1.6421e-01,  ...,  1.7835e-01,\n",
       "             -7.7521e-02,  8.9601e-02],\n",
       "            [ 1.7176e-01,  5.1343e-02, -1.3152e-02,  ..., -4.2158e-03,\n",
       "              4.9071e-02, -4.8466e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.1937e-02,  1.8164e-01,  1.8973e-01,  ..., -5.8223e-03,\n",
       "              3.5658e-02,  9.4269e-02],\n",
       "            [-1.7112e-01,  9.7162e-02, -3.1565e-03,  ..., -7.0301e-02,\n",
       "              1.8508e-01,  8.9966e-02],\n",
       "            [-1.6398e-01,  5.3017e-02,  7.3726e-02,  ..., -9.5444e-02,\n",
       "             -4.4003e-02,  1.4091e-01],\n",
       "            ...,\n",
       "            [-1.3385e-01,  1.3939e-03, -1.8135e-01,  ...,  4.4920e-03,\n",
       "             -7.3203e-02,  1.4611e-01],\n",
       "            [-1.5426e-01, -6.2293e-02, -1.7896e-02,  ...,  1.1012e-01,\n",
       "             -5.9048e-03,  1.5658e-01],\n",
       "            [ 1.2283e-01, -1.9205e-01,  7.6853e-02,  ...,  1.8903e-01,\n",
       "             -8.2257e-02,  9.5414e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-5.3248e-02, -5.5211e-02, -7.2681e-02,  ...,  5.4796e-03,\n",
       "              1.4298e-01,  5.3818e-02],\n",
       "            [ 1.0207e-01,  2.3275e-03, -8.1739e-02,  ...,  9.8285e-02,\n",
       "             -1.9700e-02,  1.7947e-01],\n",
       "            [ 1.7920e-01, -3.5690e-02,  4.0981e-03,  ..., -1.9080e-01,\n",
       "             -6.9812e-02,  1.1733e-01],\n",
       "            ...,\n",
       "            [ 6.8322e-02,  5.4200e-02, -3.8376e-02,  ..., -3.5981e-02,\n",
       "             -1.5726e-01, -1.6865e-02],\n",
       "            [-5.5672e-02, -1.9953e-01, -7.4768e-02,  ..., -1.8954e-01,\n",
       "             -1.5066e-01, -1.3166e-01],\n",
       "            [-3.0505e-02, -1.6385e-01, -5.3644e-02,  ..., -8.1707e-03,\n",
       "             -9.1821e-02,  6.2543e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-2.9640e-02, -7.3919e-02, -1.4099e-01,  ..., -1.7596e-01,\n",
       "              1.6735e-01, -2.0376e-02],\n",
       "            [ 9.7194e-02, -1.9912e-01, -1.0344e-01,  ..., -7.7119e-02,\n",
       "             -4.7041e-02,  1.1976e-01],\n",
       "            [ 1.1600e-02,  6.1269e-02,  4.0335e-02,  ..., -1.3143e-01,\n",
       "              1.8040e-01,  1.4772e-01],\n",
       "            ...,\n",
       "            [-1.3141e-02,  4.2827e-02, -5.5238e-02,  ...,  1.7334e-01,\n",
       "              6.0111e-02,  1.3455e-01],\n",
       "            [-6.8769e-02, -3.0789e-02, -1.7529e-02,  ...,  1.7617e-01,\n",
       "             -4.6167e-02, -4.6144e-02],\n",
       "            [-4.0186e-02, -1.9687e-01, -1.0848e-01,  ...,  2.3603e-02,\n",
       "              1.3195e-01,  1.6205e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 5.7258e-02, -1.8490e-01, -1.9470e-01,  ...,  8.8506e-02,\n",
       "              5.1941e-02,  7.1144e-03],\n",
       "            [ 1.7936e-02,  1.2385e-01, -1.1980e-03,  ..., -4.7335e-02,\n",
       "              6.4082e-02, -6.0777e-02],\n",
       "            [ 5.6281e-02,  7.5180e-02,  1.5922e-01,  ...,  2.5065e-02,\n",
       "              2.9736e-02, -1.8525e-01],\n",
       "            ...,\n",
       "            [ 1.2279e-01, -1.1383e-02,  7.7128e-02,  ..., -1.1860e-01,\n",
       "             -2.5905e-02,  6.2405e-02],\n",
       "            [-1.5633e-01, -1.0795e-01, -2.0112e-01,  ..., -1.6681e-01,\n",
       "              5.1555e-02,  1.2370e-02],\n",
       "            [ 4.8439e-02, -1.6821e-01,  2.7520e-02,  ..., -1.2064e-01,\n",
       "             -6.9681e-02,  6.6301e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-8.2226e-02, -8.0124e-03, -1.6611e-01,  ...,  3.4243e-02,\n",
       "              1.4296e-02,  4.9845e-02],\n",
       "            [-7.5890e-02, -1.7271e-01, -9.2039e-02,  ..., -5.7199e-02,\n",
       "              2.1592e-02,  1.9262e-02],\n",
       "            [-7.2020e-02, -1.8591e-01, -5.7096e-02,  ...,  1.4564e-01,\n",
       "              1.7117e-01, -7.6180e-02],\n",
       "            ...,\n",
       "            [-7.3659e-02, -4.0230e-02, -3.9004e-03,  ...,  1.3210e-01,\n",
       "             -5.5328e-02,  4.6880e-02],\n",
       "            [-2.8578e-02,  5.0958e-02,  1.1931e-01,  ..., -5.8856e-02,\n",
       "             -1.5853e-01, -1.2103e-01],\n",
       "            [-4.9190e-02, -6.5898e-02,  8.0315e-03,  ...,  1.3173e-01,\n",
       "             -6.3942e-02, -1.4959e-01]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.8167e-02,  1.7427e-01,  7.1828e-02,  5.9750e-02,  1.6582e-01,\n",
       "           1.4754e-01,  7.2470e-02,  1.3732e-01,  1.3407e-01,  2.5424e-02,\n",
       "           1.6653e-01, -1.4432e-01,  1.3041e-01,  3.2491e-02,  1.2896e-01,\n",
       "          -1.8139e-01, -2.4734e-02,  4.3505e-02, -6.2008e-03, -6.5936e-02,\n",
       "           1.7903e-01, -4.3727e-02,  1.4897e-01,  5.1953e-03,  3.4557e-02,\n",
       "          -4.5972e-02, -1.6058e-01, -1.5312e-01, -1.8340e-01, -2.0071e-01,\n",
       "           1.8027e-01,  1.2841e-01, -6.6038e-02, -1.8722e-02, -1.0047e-01,\n",
       "          -7.6401e-02,  1.9920e-01,  7.2139e-02, -2.6995e-02,  5.9052e-02,\n",
       "          -7.2766e-02, -1.5916e-03,  5.8029e-02,  4.8098e-03,  1.2133e-01,\n",
       "          -6.7689e-02, -3.5042e-03, -4.9329e-02,  9.8978e-03, -4.3473e-02,\n",
       "           1.8010e-01,  3.3872e-02, -1.0510e-01, -6.6082e-02,  4.4661e-02,\n",
       "           1.3621e-01, -1.8224e-02,  1.3655e-01, -1.2544e-01,  1.5500e-01,\n",
       "           1.4651e-01,  1.6677e-01,  1.4051e-01,  5.2027e-02,  1.8990e-01,\n",
       "          -1.5002e-01, -1.7871e-01,  1.1446e-01, -2.9816e-02, -7.8911e-02,\n",
       "          -1.9568e-01, -1.4031e-01, -5.2782e-02,  1.0778e-01, -1.0700e-01,\n",
       "          -6.6215e-02,  3.5220e-02, -1.7169e-01,  4.2563e-02,  1.8897e-01,\n",
       "           1.1847e-01, -2.0316e-02,  1.3712e-01, -3.3497e-02, -1.0172e-01,\n",
       "          -1.8316e-01, -2.4232e-02,  1.2613e-01,  3.8420e-02, -1.2612e-01,\n",
       "           6.6982e-02,  5.8687e-02,  7.0531e-02,  2.1777e-03, -3.0621e-02,\n",
       "          -7.8647e-02,  1.7633e-01,  2.0124e-01,  8.9417e-02, -6.5040e-02,\n",
       "          -6.8200e-02, -4.9139e-02,  7.5341e-02,  1.8835e-01, -2.8449e-02,\n",
       "           5.9081e-02,  4.8040e-02,  5.2645e-03, -1.5314e-02, -1.0487e-01,\n",
       "          -1.7193e-01, -1.7425e-02,  2.9920e-02, -6.4032e-02, -1.0783e-01,\n",
       "          -2.7768e-02, -1.9537e-01, -1.2437e-01, -3.4430e-02,  1.1706e-01,\n",
       "           1.7948e-01,  6.6160e-02,  9.2733e-02,  4.8882e-02,  1.9044e-01,\n",
       "           9.1907e-02,  1.8012e-02,  3.2363e-02,  1.7917e-02, -6.4927e-02,\n",
       "          -4.4376e-02, -1.1045e-01,  3.2315e-02,  1.3014e-01, -6.1121e-02,\n",
       "           1.1676e-02, -3.2528e-02,  5.4819e-02, -2.5784e-02, -4.3140e-02,\n",
       "          -2.2195e-02, -4.3537e-02,  1.2871e-01, -7.4298e-02, -5.4494e-02,\n",
       "           1.2225e-01,  1.2714e-01, -1.6212e-01, -1.2290e-01, -3.3866e-03,\n",
       "          -1.0470e-04, -1.5437e-01,  1.5726e-02,  8.2818e-02, -7.1467e-02,\n",
       "          -1.2291e-01,  1.8606e-01,  3.7953e-02,  9.0964e-02, -1.4184e-01,\n",
       "           1.2847e-01,  5.1361e-02, -1.2274e-02,  8.9286e-02,  1.8987e-01,\n",
       "           1.6426e-01,  6.5310e-02,  1.8609e-01, -1.5264e-02, -1.9693e-01,\n",
       "           1.5901e-01, -1.0330e-01, -5.4901e-02,  6.1161e-02, -6.3650e-02,\n",
       "          -1.5566e-01, -9.0725e-02, -3.8710e-02,  2.9677e-02,  5.4303e-02,\n",
       "          -4.4934e-02,  3.1172e-02, -7.4079e-02, -5.8764e-03,  6.1510e-02,\n",
       "          -1.2898e-01,  1.8772e-01, -1.7915e-01, -3.2454e-02, -1.3055e-01,\n",
       "           1.0717e-01,  9.4811e-02,  2.1185e-02, -1.7109e-01,  3.3438e-02,\n",
       "          -9.8502e-02,  8.7848e-02, -8.2520e-02,  2.6471e-02,  3.9794e-03,\n",
       "           1.0252e-01, -1.2017e-02, -1.3428e-01, -8.5310e-02, -1.5915e-02,\n",
       "           1.9002e-01,  8.3059e-02,  2.7935e-02, -7.5448e-02, -1.2517e-01,\n",
       "          -1.5073e-01, -1.8854e-01,  1.9113e-01,  9.4833e-02,  1.6288e-01,\n",
       "          -4.2656e-02,  1.6889e-01,  8.0071e-02, -7.5490e-02, -2.6175e-02,\n",
       "          -6.2019e-02,  1.4742e-01,  7.5616e-02,  8.2509e-02,  2.7313e-02,\n",
       "           1.2571e-01, -9.1052e-02, -1.9082e-01,  5.2890e-02, -1.3257e-01,\n",
       "          -2.0476e-02, -1.5127e-01, -1.6548e-01, -4.9224e-02, -1.3146e-01,\n",
       "           4.3257e-02,  7.0461e-02,  1.6033e-02,  1.6367e-01, -1.7346e-02,\n",
       "          -1.5203e-02, -3.6301e-02, -1.0944e-01, -1.5484e-01,  9.2078e-02,\n",
       "           5.3148e-02,  1.7428e-01,  6.2901e-02,  1.4461e-01,  2.0032e-01,\n",
       "           1.0168e-01, -1.3772e-01, -5.2062e-02,  1.3379e-01,  1.0547e-01,\n",
       "           6.1239e-02,  8.2060e-02, -1.5447e-02,  3.0699e-02, -8.6161e-02,\n",
       "           1.1106e-01, -1.5142e-01, -1.0463e-01,  2.5737e-02, -7.3332e-02,\n",
       "          -8.0829e-02, -9.1622e-02,  5.9498e-02,  1.5668e-01,  1.2970e-01,\n",
       "           3.7511e-02,  1.7395e-01,  1.7871e-02,  5.8868e-02, -1.2082e-01,\n",
       "          -5.3043e-03,  4.2380e-02,  3.1874e-02, -1.0856e-04, -1.1715e-01,\n",
       "           4.5006e-02,  5.2657e-02,  1.4530e-01, -1.4787e-01, -2.4275e-02,\n",
       "          -1.0786e-01,  3.9140e-02, -7.5809e-02,  8.5338e-02,  6.2458e-02,\n",
       "          -1.4588e-01,  6.7843e-02, -5.0131e-02,  1.9522e-01,  1.5338e-01,\n",
       "          -4.5785e-02,  7.5339e-02,  8.0621e-02,  5.5636e-02, -7.2135e-02,\n",
       "          -4.7704e-02,  3.6254e-03, -1.0946e-02, -7.9055e-02,  7.5346e-02,\n",
       "           5.7315e-02,  9.2809e-02, -1.0175e-01, -5.7346e-02, -6.0016e-02,\n",
       "          -6.1106e-02,  1.3329e-01,  1.2572e-01, -7.0544e-03, -1.4502e-01,\n",
       "          -1.1292e-01, -2.0134e-02,  1.5554e-01, -4.1603e-02,  1.4262e-01,\n",
       "           1.9015e-01, -1.2466e-01,  1.2922e-01, -1.4496e-01, -5.4652e-02,\n",
       "           1.6897e-02, -7.0841e-02,  7.0609e-02,  7.5779e-02, -1.1227e-01,\n",
       "          -1.4551e-02,  4.3763e-02,  8.1951e-02,  7.4855e-02, -1.5653e-01,\n",
       "          -1.5028e-01,  4.6875e-02, -4.8786e-02,  1.2711e-01,  1.9745e-01,\n",
       "           7.9750e-02, -1.3858e-03, -6.1062e-02,  2.6581e-02, -1.2918e-02,\n",
       "           3.5895e-02, -9.3168e-02, -4.1284e-02,  6.6618e-02, -5.3816e-02,\n",
       "           1.5841e-02, -8.3886e-02,  8.4826e-03,  2.8857e-02, -7.6782e-02,\n",
       "          -6.4913e-02,  2.6589e-02,  1.4262e-01,  1.3049e-02, -1.2823e-02,\n",
       "          -1.2079e-01,  6.2057e-02,  7.9391e-02, -5.8023e-02,  9.4921e-02,\n",
       "           7.7148e-02,  8.3707e-02, -1.5385e-01, -1.2525e-01, -1.9638e-02,\n",
       "          -3.9498e-02, -1.1942e-02, -1.3671e-01,  8.8016e-04,  1.0720e-01,\n",
       "           2.1889e-02, -7.4919e-02, -1.7721e-01,  3.8316e-02,  7.0471e-02,\n",
       "          -1.3011e-02, -3.2194e-02, -4.6542e-02,  1.6512e-01, -6.9677e-02,\n",
       "          -1.0807e-01, -1.0373e-01,  2.8600e-02, -2.2669e-02,  1.8077e-01,\n",
       "           6.9956e-02,  8.9127e-03, -1.8365e-01, -1.1247e-01,  1.9685e-01,\n",
       "           3.7107e-03,  6.5596e-02,  7.7863e-02, -4.5734e-02, -1.5122e-02,\n",
       "          -1.2089e-01,  1.5620e-01,  4.8382e-02, -1.9863e-01,  1.1566e-01,\n",
       "          -1.7558e-01, -8.0683e-02, -3.6024e-02,  9.1467e-02, -5.9203e-02,\n",
       "          -6.1896e-02,  7.5169e-02,  3.1257e-02,  4.3976e-02, -9.8494e-02,\n",
       "          -6.1396e-03, -1.4352e-02, -6.0709e-02, -4.8127e-02, -1.1525e-01,\n",
       "          -8.0372e-02,  2.8901e-02, -5.2233e-02,  6.7757e-03,  9.1734e-02,\n",
       "           1.3070e-01,  1.5953e-01,  8.8138e-03,  1.3401e-01, -7.6659e-02,\n",
       "           8.3603e-02, -9.5557e-02,  4.7013e-02,  5.9766e-03,  1.0011e-02,\n",
       "           7.6062e-02, -6.6325e-02,  3.0848e-02, -1.5658e-02,  1.9066e-01,\n",
       "           2.8279e-02,  1.7440e-01, -6.0070e-02,  1.4882e-02,  1.5123e-01,\n",
       "          -6.4650e-02, -9.7383e-02, -5.3190e-02,  4.5808e-02,  8.4361e-02,\n",
       "          -1.4845e-01,  1.9642e-01, -7.1961e-02,  1.9631e-01,  1.0865e-01,\n",
       "          -1.4355e-01, -9.7917e-02,  1.0385e-01,  4.3094e-02,  6.6414e-02,\n",
       "           1.5030e-01,  1.5010e-01, -1.5071e-02, -4.5050e-02,  1.6611e-01,\n",
       "           1.6992e-02, -1.9860e-01,  1.5021e-02,  2.5937e-02, -2.2218e-02,\n",
       "           2.4087e-02, -1.1881e-01, -1.7577e-01,  7.1243e-02, -1.6439e-01,\n",
       "          -7.3573e-02, -1.3193e-01, -1.6456e-01, -1.7228e-01,  3.6621e-02,\n",
       "           4.2445e-02,  1.0091e-01, -1.3382e-01, -3.0692e-02, -1.9432e-01,\n",
       "          -9.3457e-02, -5.7430e-03,  1.5417e-01, -1.3316e-02, -1.4445e-01,\n",
       "          -1.9126e-01, -1.6478e-01,  1.6050e-01, -4.9046e-02,  3.3289e-02,\n",
       "           1.3652e-01,  1.6172e-01, -9.5312e-02, -5.3180e-02,  1.6389e-02,\n",
       "          -1.8916e-02, -9.7877e-02, -5.0261e-02,  2.6980e-02, -1.2025e-01,\n",
       "          -1.5392e-01,  5.7081e-02, -3.1825e-02,  1.4998e-02,  3.3995e-03,\n",
       "           6.0985e-03, -7.0484e-02], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([1.0601, 1.0600, 0.9401, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601, 0.9400,\n",
       "          0.9400, 0.9400, 1.0600, 0.9399, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400,\n",
       "          0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0601,\n",
       "          1.0592, 1.0601, 1.0600, 1.0599, 1.0601, 1.0600, 1.0600, 1.0600, 1.0600,\n",
       "          0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "          0.9399, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9399,\n",
       "          0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 0.9399, 0.9400,\n",
       "          1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0600,\n",
       "          0.9399, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601,\n",
       "          1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "          1.0598, 0.9400, 1.0600, 0.9400, 1.0601, 1.0600, 0.9400, 0.9400, 1.0599,\n",
       "          1.0600, 1.0600, 0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600,\n",
       "          0.9400, 1.0601, 1.0601, 0.9400, 1.0600, 1.0601, 0.9400, 1.0600, 1.0600,\n",
       "          1.0600, 0.9399, 1.0601, 0.9401, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400,\n",
       "          1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "          0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 1.0601,\n",
       "          1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 0.9400, 0.9401,\n",
       "          1.0600, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400, 1.0600, 1.0601, 0.9400,\n",
       "          1.0600, 1.0600, 0.9399, 1.0600, 1.0600, 1.0600, 1.0601, 0.9400, 1.0600,\n",
       "          1.0598, 0.9400, 1.0600, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "          1.0600, 1.0599, 0.9400, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600, 1.0600,\n",
       "          1.0601, 0.9403, 0.9400, 0.9399, 1.0601, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "          1.0601, 1.0601, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 0.9399,\n",
       "          0.9400, 0.9400, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9401, 1.0600,\n",
       "          0.9401, 1.0600, 0.9400, 0.9400, 1.0601, 0.9400, 1.0600, 1.0600, 1.0601,\n",
       "          1.0599, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 1.0600, 1.0600,\n",
       "          1.0600, 1.0600, 1.0601, 0.9400, 1.0600, 0.9400, 1.0599, 0.9399, 1.0601,\n",
       "          0.9400, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399, 1.0600, 0.9401,\n",
       "          1.0601, 1.0600, 1.0600, 0.9400, 0.9399, 1.0600, 0.9399, 0.9400, 0.9400,\n",
       "          0.9400, 0.9402, 1.0600, 1.0600, 1.0600, 0.9399, 0.9400, 0.9400, 1.0601,\n",
       "          1.0601, 1.0601, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 0.9400,\n",
       "          1.0600, 0.9402, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "          0.9399, 1.0600, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400,\n",
       "          1.0600, 0.9402, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          1.0600, 0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400,\n",
       "          1.0601, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0601, 0.9399,\n",
       "          0.9400, 1.0600, 0.9401, 1.0600, 0.9400, 0.9399, 1.0600, 1.0600, 1.0600,\n",
       "          0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0600, 0.9399, 1.0600,\n",
       "          1.0600, 0.9400, 1.0598, 1.0601, 1.0600, 0.9400, 0.9400, 0.9400, 0.9401,\n",
       "          0.9400, 1.0600, 0.9399, 1.0601, 0.9401, 1.0600, 0.9399, 1.0601, 1.0599,\n",
       "          0.9399, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "          0.9401, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600, 0.9400, 0.9400, 1.0601,\n",
       "          1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 1.0581, 0.9399, 1.0600,\n",
       "          1.0600, 1.0601, 1.0601, 0.9400, 1.0600, 0.9399, 1.0600, 1.0601, 0.9401,\n",
       "          1.0601, 0.9400, 1.0601, 0.9400, 1.0601, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "          1.0601, 0.9400, 0.9400, 1.0601, 1.0600, 1.0600, 0.9400, 1.0598, 1.0600,\n",
       "          0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 0.9407, 1.0600, 1.0600,\n",
       "          0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600,\n",
       "          0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600, 1.0601,\n",
       "          1.0600, 1.0601, 1.0600, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "          0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "          1.0601, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "          1.0600, 1.0601, 0.9400, 0.9402, 0.9399, 1.0600, 1.0601, 1.0601, 0.9400,\n",
       "          1.0600, 0.9400, 0.9399, 1.0600, 1.0601, 1.0600, 1.0601, 1.0600, 0.9400,\n",
       "          0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 0.9401,\n",
       "          1.0600, 1.0598, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0597, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0599,  0.0599,  0.0600,\n",
       "           0.0512,  0.0600, -0.0600, -0.0600,  0.0600, -0.0598, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0596,  0.0599,  0.0598,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600,  0.0599, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600, -0.0594,  0.0600,  0.0600, -0.0600, -0.0598, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0597,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600,  0.0599,  0.0600,  0.0593, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600,  0.0600,  0.0599, -0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0577, -0.0600,\n",
       "           0.0600, -0.0600,  0.0595, -0.0600, -0.0600, -0.0600,  0.0597, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0598,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600,  0.0596, -0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600, -0.0600, -0.0599,  0.0600, -0.0600,  0.0600,\n",
       "           0.0599, -0.0584,  0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0599, -0.0600, -0.0600,  0.0600, -0.0600,  0.0489, -0.0600,\n",
       "          -0.0599,  0.0600, -0.0599,  0.0600,  0.0586, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0598,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0592,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0548, -0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0598,  0.0600,\n",
       "          -0.0600, -0.0598, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,  0.0600,\n",
       "           0.0596, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0599, -0.0600, -0.0600, -0.0599,  0.0599, -0.0600, -0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0598, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "           0.0578,  0.0600,  0.0600,  0.0576, -0.0598, -0.0600, -0.0599,  0.0598,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0599,  0.0600,  0.0600, -0.0599,  0.0600,  0.0599, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0589,  0.0600,\n",
       "           0.0600,  0.0600,  0.0599,  0.0600, -0.0600, -0.0598, -0.0600, -0.0598,\n",
       "           0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600, -0.0600, -0.0586,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0537,  0.0600,  0.0600,\n",
       "          -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0566,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0598, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0588,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600,  0.0573,  0.0599, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0599,  0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600,  0.0571,  0.0598, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2453, -0.0800, -0.0261,  0.2573,  0.0137],\n",
       "            [ 0.1347, -0.0993, -0.0091,  0.1237,  0.2133],\n",
       "            [-0.1203,  0.1583, -0.1118,  0.0746, -0.0516],\n",
       "            [ 0.0211,  0.1537,  0.0209, -0.0052, -0.1673],\n",
       "            [ 0.0071, -0.1311, -0.0563,  0.0044,  0.0009]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0394, -0.1376, -0.1337, -0.1827,  0.1238],\n",
       "            [ 0.1211, -0.0602, -0.0912, -0.1345, -0.0577],\n",
       "            [-0.2154, -0.1498, -0.0292,  0.0635, -0.0607],\n",
       "            [-0.0051,  0.2468, -0.2046, -0.0599, -0.1780],\n",
       "            [-0.0299, -0.1748, -0.1545, -0.1388, -0.1679]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2593, -0.0949,  0.1343, -0.0551,  0.2540],\n",
       "            [-0.0428, -0.1399, -0.0779,  0.0574,  0.1892],\n",
       "            [-0.2128, -0.1716,  0.1081,  0.0639, -0.0592],\n",
       "            [-0.1870,  0.1170, -0.1113, -0.1670,  0.0479],\n",
       "            [ 0.1192, -0.1164,  0.0632,  0.0048, -0.2199]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.0081, -0.0432, -0.1522, -0.0360,  0.1212],\n",
       "            [ 0.0993, -0.2594,  0.0096, -0.1371, -0.1064],\n",
       "            [-0.0940,  0.0671, -0.1217,  0.2246, -0.1447],\n",
       "            [-0.0669,  0.0071,  0.2307,  0.0134, -0.2541],\n",
       "            [-0.0932, -0.0058, -0.2276, -0.2369, -0.0368]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0216, -0.1973,  0.1075,  0.1047, -0.0592],\n",
       "            [-0.2475, -0.2583,  0.0632, -0.0388,  0.0058],\n",
       "            [-0.0071,  0.0473,  0.0826,  0.1176,  0.2552],\n",
       "            [ 0.1211, -0.0400,  0.0058, -0.1140,  0.0338],\n",
       "            [-0.0885,  0.1182,  0.1937,  0.1002,  0.0021]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0262, -0.0207, -0.0044, -0.1043,  0.0903],\n",
       "            [ 0.2437, -0.0761,  0.0686,  0.1320, -0.2127],\n",
       "            [-0.1985, -0.1377, -0.0134, -0.2302, -0.0669],\n",
       "            [-0.1081, -0.2339,  0.0013,  0.1274, -0.2081],\n",
       "            [-0.2247, -0.2600, -0.0780,  0.0998,  0.0049]]]], device='cuda:1',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0288,  0.1469,  0.2572,  0.1455,  0.0588,  0.0765, -0.1986,  0.0944,\n",
       "          -0.2509,  0.0802, -0.1385, -0.0133, -0.0170,  0.1253, -0.1885, -0.0091,\n",
       "           0.1322, -0.0832,  0.0583, -0.1532,  0.1548,  0.2562,  0.0436,  0.2036,\n",
       "           0.0478, -0.0392, -0.0107,  0.0334, -0.2536,  0.0020, -0.0894, -0.1814,\n",
       "           0.1275,  0.0119,  0.0621, -0.2426,  0.0614,  0.0997,  0.1022,  0.1255,\n",
       "           0.2229, -0.0302, -0.1128, -0.0646, -0.0236,  0.0625,  0.0871, -0.0654,\n",
       "          -0.1177,  0.0190, -0.2554,  0.0629, -0.0415, -0.1036,  0.0532,  0.0410,\n",
       "           0.2405,  0.1343, -0.0100, -0.0317, -0.0856,  0.2000, -0.1151, -0.1362],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "          1.0600, 0.9399, 1.0600, 0.9399, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600,\n",
       "          1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "          1.0600, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          0.9399, 1.0600, 1.0600, 0.9400, 1.0601, 0.9399, 1.0600, 1.0600, 0.9400,\n",
       "          1.0601, 1.0601, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "          0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "          1.0600], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0598,  0.0600, -0.0594, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599,  0.0600,\n",
       "           0.0600, -0.0599,  0.0600, -0.0598,  0.0600, -0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.3269,  0.3376,  0.1132],\n",
       "            [-0.3058,  0.0294,  0.2141],\n",
       "            [-0.0527,  0.0887,  0.0372]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0016, -0.2299, -0.0984],\n",
       "            [-0.2386, -0.0527,  0.0149],\n",
       "            [ 0.1953,  0.3674, -0.0410]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1030, -0.2454, -0.1495],\n",
       "            [-0.1238,  0.1354, -0.1034],\n",
       "            [ 0.0923,  0.0624,  0.0144]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0386,  0.1073, -0.3635],\n",
       "            [-0.1111, -0.2862, -0.0517],\n",
       "            [ 0.1275, -0.2230, -0.1134]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3510, -0.0179,  0.1793],\n",
       "            [ 0.1666, -0.3695, -0.3223],\n",
       "            [-0.1493, -0.3289,  0.0401]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0774, -0.0535,  0.0455],\n",
       "            [-0.0977,  0.3613,  0.3804],\n",
       "            [-0.0218,  0.3432, -0.2184]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1901,  0.1241,  0.0148],\n",
       "            [ 0.0026, -0.0838,  0.1118],\n",
       "            [-0.0647,  0.0506,  0.0888]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0708,  0.1378, -0.3528],\n",
       "            [-0.0389, -0.3458,  0.2679],\n",
       "            [ 0.1595, -0.0018, -0.0951]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0185, -0.0721,  0.3827],\n",
       "            [ 0.0474,  0.2076,  0.1898],\n",
       "            [-0.1008, -0.1253,  0.0094]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1627, -0.3132, -0.1671],\n",
       "            [-0.0197,  0.0824,  0.1439],\n",
       "            [ 0.2378,  0.0428, -0.1248]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1012,  0.2255, -0.3068],\n",
       "            [ 0.2680,  0.2954,  0.3061],\n",
       "            [ 0.3459, -0.2698,  0.1819]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0948,  0.1303, -0.1320],\n",
       "            [ 0.0118,  0.3515,  0.2337],\n",
       "            [ 0.1739, -0.0960,  0.0334]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0820,  0.2203,  0.2551],\n",
       "            [ 0.2838, -0.2233,  0.3808],\n",
       "            [ 0.1507, -0.1088, -0.2116]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0157, -0.2666,  0.3496],\n",
       "            [-0.1649,  0.1017,  0.1674],\n",
       "            [ 0.2523, -0.1366,  0.2932]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1053, -0.2206, -0.3085],\n",
       "            [ 0.0172, -0.2193, -0.3585],\n",
       "            [ 0.1307,  0.2647,  0.2088]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3489, -0.0409,  0.1418],\n",
       "            [-0.1525, -0.1919, -0.3430],\n",
       "            [ 0.1563,  0.0015, -0.0016]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3790,  0.3453, -0.0246],\n",
       "            [-0.2116, -0.0378,  0.0756],\n",
       "            [-0.1251,  0.1768,  0.3686]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0915,  0.0414,  0.1043],\n",
       "            [-0.0314,  0.1969,  0.0920],\n",
       "            [-0.0232,  0.2952,  0.3034]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1688, -0.0212, -0.1975],\n",
       "            [ 0.1439,  0.2162,  0.1378],\n",
       "            [ 0.2552,  0.1640, -0.0532]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2374, -0.2078,  0.3396],\n",
       "            [-0.0753,  0.1338,  0.2909],\n",
       "            [-0.0136, -0.1792, -0.0691]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1107,  0.0075,  0.0358],\n",
       "            [ 0.1824, -0.1787,  0.1207],\n",
       "            [-0.2644,  0.3380,  0.1370]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0057,  0.1525,  0.3118],\n",
       "            [ 0.0310, -0.2211, -0.0631],\n",
       "            [ 0.1472, -0.2173,  0.3301]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3352, -0.2602, -0.0159],\n",
       "            [ 0.1570, -0.0295, -0.0747],\n",
       "            [ 0.0281, -0.0734, -0.0079]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1196, -0.2341, -0.3577],\n",
       "            [ 0.1272, -0.1568,  0.1983],\n",
       "            [ 0.0186,  0.0980, -0.2567]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0377, -0.0359,  0.1783],\n",
       "            [-0.1740, -0.1516,  0.0580],\n",
       "            [ 0.0856, -0.3458, -0.1893]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2690, -0.3563,  0.2335],\n",
       "            [-0.0411, -0.0981,  0.3489],\n",
       "            [-0.1771, -0.2193, -0.1687]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1314, -0.2470,  0.3583],\n",
       "            [-0.2674, -0.3599,  0.0621],\n",
       "            [ 0.1936, -0.1130, -0.1922]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2492,  0.3375,  0.0783],\n",
       "            [-0.0212,  0.0599,  0.3692],\n",
       "            [-0.1984, -0.1535, -0.0773]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2603,  0.0260, -0.1428],\n",
       "            [-0.0401, -0.2312, -0.1798],\n",
       "            [-0.0849,  0.0914, -0.0168]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1678, -0.2232,  0.2834],\n",
       "            [ 0.1509, -0.2445,  0.2188],\n",
       "            [ 0.3497, -0.1100,  0.2170]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2511,  0.2410,  0.2098],\n",
       "            [-0.0581,  0.1774, -0.0636],\n",
       "            [-0.0036, -0.1822,  0.2093]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1864,  0.1593, -0.0715],\n",
       "            [-0.2306,  0.2433,  0.0857],\n",
       "            [ 0.0294,  0.1967,  0.3672]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2440,  0.0382,  0.3127],\n",
       "            [-0.3238, -0.2075, -0.2322],\n",
       "            [ 0.1198,  0.2592, -0.1291]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2633,  0.1645,  0.1530],\n",
       "            [-0.1981,  0.2618, -0.1290],\n",
       "            [-0.0431, -0.0884,  0.0061]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1068,  0.1621,  0.2843],\n",
       "            [-0.1677,  0.2400, -0.1533],\n",
       "            [-0.2368,  0.0697, -0.0595]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3442,  0.1361,  0.0835],\n",
       "            [ 0.0122,  0.1348, -0.1407],\n",
       "            [ 0.1459, -0.1719, -0.0624]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0914,  0.0408, -0.3109],\n",
       "            [ 0.1178, -0.2322,  0.1720],\n",
       "            [-0.1704, -0.1037,  0.2085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1608, -0.2221,  0.1762],\n",
       "            [-0.3180, -0.1872, -0.0319],\n",
       "            [-0.0112,  0.2361,  0.2956]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1258,  0.3427,  0.2691],\n",
       "            [-0.1393,  0.0355,  0.1253],\n",
       "            [-0.1241,  0.2254,  0.3576]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3155,  0.0849,  0.2717],\n",
       "            [-0.2048, -0.0372,  0.3863],\n",
       "            [ 0.1504,  0.0348, -0.2330]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1782,  0.3248,  0.1735],\n",
       "            [-0.2453,  0.3392,  0.1689],\n",
       "            [ 0.2192, -0.3849, -0.2056]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2633,  0.1378,  0.1518],\n",
       "            [ 0.0998,  0.1505,  0.1821],\n",
       "            [-0.0589, -0.0480,  0.2372]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0473, -0.0042,  0.0334],\n",
       "            [ 0.2647, -0.1813, -0.2456],\n",
       "            [ 0.2861,  0.2428,  0.1718]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0392, -0.2271,  0.3517],\n",
       "            [-0.1371, -0.0698,  0.2699],\n",
       "            [ 0.0666,  0.1801,  0.3521]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3562, -0.1411,  0.1616],\n",
       "            [ 0.2610,  0.1506, -0.0657],\n",
       "            [-0.0699, -0.0612, -0.1657]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3698,  0.2020, -0.2125],\n",
       "            [-0.0877, -0.0151, -0.1401],\n",
       "            [ 0.2638,  0.2625,  0.1872]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1861,  0.2028,  0.0016],\n",
       "            [ 0.2549, -0.3431,  0.3722],\n",
       "            [ 0.2300,  0.0349,  0.3412]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0641,  0.1496,  0.0051],\n",
       "            [-0.0117,  0.1895,  0.1370],\n",
       "            [-0.2003, -0.2441, -0.3928]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1091,  0.0538,  0.2580],\n",
       "            [-0.2588,  0.1165, -0.0851],\n",
       "            [ 0.3182,  0.2742,  0.2786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0951,  0.1799,  0.0644],\n",
       "            [-0.2126, -0.3342, -0.1788],\n",
       "            [-0.1753,  0.0506, -0.2686]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1528, -0.1101, -0.0323],\n",
       "            [-0.1342,  0.0568,  0.1518],\n",
       "            [ 0.1398, -0.1688,  0.1560]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2394, -0.1753, -0.2501],\n",
       "            [ 0.1648,  0.0962,  0.0427],\n",
       "            [ 0.3448,  0.2341, -0.1209]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1957, -0.3921,  0.1047],\n",
       "            [ 0.1317, -0.1083, -0.1607],\n",
       "            [ 0.0159, -0.2667, -0.0118]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1196,  0.0910, -0.2165],\n",
       "            [-0.3372,  0.0103,  0.2028],\n",
       "            [-0.2916, -0.0696,  0.2602]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3215, -0.2493,  0.0172],\n",
       "            [-0.1908,  0.1707,  0.3794],\n",
       "            [ 0.1062, -0.3278, -0.1574]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2033,  0.2321,  0.0229],\n",
       "            [ 0.1731, -0.0194,  0.1993],\n",
       "            [ 0.1371, -0.2059, -0.0495]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0664, -0.1708, -0.2554],\n",
       "            [-0.3875,  0.0671,  0.0416],\n",
       "            [ 0.1544, -0.2661, -0.0172]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2396,  0.2414,  0.1776],\n",
       "            [ 0.0442,  0.0775, -0.3594],\n",
       "            [ 0.2832, -0.0484,  0.1364]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0950, -0.1686,  0.2725],\n",
       "            [ 0.1011,  0.1122,  0.2413],\n",
       "            [-0.2664,  0.1229, -0.0232]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2130,  0.1265, -0.0875],\n",
       "            [-0.3864, -0.1423,  0.0252],\n",
       "            [ 0.0934, -0.1658,  0.2515]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2508,  0.1692,  0.1474],\n",
       "            [-0.0524,  0.3914, -0.2312],\n",
       "            [ 0.1528,  0.3175,  0.3161]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3885,  0.0282, -0.2465],\n",
       "            [ 0.2420,  0.1174,  0.2517],\n",
       "            [ 0.2067,  0.0136, -0.3403]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0145,  0.3831, -0.0084],\n",
       "            [ 0.0364, -0.0421, -0.1523],\n",
       "            [ 0.1596, -0.3494,  0.1648]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3706,  0.0076, -0.2769],\n",
       "            [-0.2486, -0.3272,  0.0434],\n",
       "            [ 0.2529, -0.2475, -0.0096]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0435, -0.0704,  0.2645,  0.2072,  0.0744, -0.0911, -0.2215,  0.3429,\n",
       "          -0.0841,  0.2657, -0.3546, -0.1920, -0.0277,  0.0157,  0.2278,  0.1193,\n",
       "          -0.1689,  0.3619, -0.1523, -0.1147,  0.0276,  0.2094,  0.3264,  0.1618,\n",
       "           0.3466, -0.0203, -0.2095, -0.2572,  0.2978,  0.0554, -0.2631,  0.1339,\n",
       "          -0.0883, -0.0553, -0.2902, -0.0872, -0.2794, -0.0442,  0.2209, -0.1531,\n",
       "           0.0538,  0.2231, -0.0400,  0.1907, -0.2147, -0.3298, -0.1419,  0.1246,\n",
       "           0.1688, -0.1833, -0.2531,  0.3512,  0.3374, -0.3904,  0.2344, -0.0654,\n",
       "           0.1455,  0.2170, -0.3737,  0.1172,  0.1883,  0.1038, -0.2175,  0.1139],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.9399, 1.0600, 0.9400, 1.0601, 1.0601, 1.0601, 1.0600, 0.9399, 0.9399,\n",
       "          1.0601, 0.9399, 1.0601, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 1.0601,\n",
       "          0.9399, 1.0601, 0.9399, 1.0601, 1.0601, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "          0.9400, 1.0600, 1.0601, 1.0601, 1.0600, 1.0601, 1.0601, 1.0600, 0.9400,\n",
       "          1.0601, 1.0601, 1.0600, 1.0600, 1.0601, 1.0601, 0.9399, 1.0601, 0.9399,\n",
       "          0.9399, 1.0601, 1.0601, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399,\n",
       "          1.0601, 0.9399, 1.0601, 1.0601, 0.9400, 0.9400, 1.0601, 1.0601, 0.9400,\n",
       "          0.9399], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0600,  0.0600, -0.0601,\n",
       "          -0.0601, -0.0600,  0.0601, -0.0601, -0.0600, -0.0601,  0.0600, -0.0601,\n",
       "          -0.0601, -0.0601,  0.0601,  0.0601,  0.0599,  0.0601,  0.0601,  0.0601,\n",
       "           0.0600,  0.0601, -0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0601,\n",
       "           0.0601,  0.0601, -0.0601,  0.0599, -0.0601, -0.0601, -0.0601, -0.0601,\n",
       "          -0.0601, -0.0601,  0.0601, -0.0601, -0.0601, -0.0601, -0.0600,  0.0601,\n",
       "          -0.0601, -0.0601,  0.0600, -0.0601,  0.0601,  0.0600,  0.0601, -0.0600,\n",
       "           0.0601, -0.0600,  0.0601,  0.0601, -0.0601, -0.0601,  0.0600, -0.0601],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0685, -0.0735, -0.0471],\n",
       "            [ 0.0703, -0.0732,  0.0719],\n",
       "            [-0.0601, -0.0651,  0.0486]],\n",
       "  \n",
       "           [[ 0.0664,  0.0697,  0.0646],\n",
       "            [ 0.0463,  0.0500,  0.0716],\n",
       "            [ 0.0511,  0.0535,  0.0607]],\n",
       "  \n",
       "           [[-0.0713, -0.0466, -0.0524],\n",
       "            [-0.0504, -0.0593, -0.0588],\n",
       "            [-0.0663, -0.0484, -0.0651]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0597, -0.0541, -0.0699],\n",
       "            [-0.0566, -0.0501, -0.0665],\n",
       "            [-0.0694, -0.0609,  0.0635]],\n",
       "  \n",
       "           [[-0.0725, -0.0571, -0.0681],\n",
       "            [-0.0563, -0.0719, -0.0703],\n",
       "            [-0.0588, -0.0653, -0.0662]],\n",
       "  \n",
       "           [[-0.0608,  0.0588,  0.0556],\n",
       "            [-0.0499,  0.0734,  0.0577],\n",
       "            [-0.0577,  0.0670,  0.0619]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0516, -0.0507, -0.0680],\n",
       "            [ 0.0698,  0.0655, -0.0490],\n",
       "            [-0.0674, -0.0602, -0.0553]],\n",
       "  \n",
       "           [[ 0.0567, -0.0654, -0.0642],\n",
       "            [ 0.0689, -0.0563, -0.0605],\n",
       "            [-0.0681, -0.0606, -0.0541]],\n",
       "  \n",
       "           [[-0.0618,  0.0678,  0.0563],\n",
       "            [-0.0545,  0.0525,  0.0619],\n",
       "            [ 0.0484,  0.0463,  0.0555]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0511, -0.0553, -0.0494],\n",
       "            [-0.0530,  0.0669,  0.0615],\n",
       "            [-0.0603,  0.0537, -0.0477]],\n",
       "  \n",
       "           [[ 0.0701,  0.0729, -0.0677],\n",
       "            [ 0.0578,  0.0559, -0.0735],\n",
       "            [ 0.0497,  0.0619, -0.0639]],\n",
       "  \n",
       "           [[ 0.0617, -0.0628, -0.0507],\n",
       "            [ 0.0466, -0.0573, -0.0515],\n",
       "            [ 0.0659,  0.0485, -0.0553]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0532, -0.0501, -0.0548],\n",
       "            [ 0.0633, -0.0671, -0.0606],\n",
       "            [ 0.0660, -0.0462, -0.0465]],\n",
       "  \n",
       "           [[-0.0738, -0.0622, -0.0554],\n",
       "            [ 0.0731, -0.0629, -0.0561],\n",
       "            [ 0.0484,  0.0550,  0.0506]],\n",
       "  \n",
       "           [[ 0.0721, -0.0504, -0.0471],\n",
       "            [ 0.0686, -0.0638, -0.0629],\n",
       "            [ 0.0659, -0.0722, -0.0562]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0560,  0.0478,  0.0597],\n",
       "            [ 0.0496,  0.0494,  0.0729],\n",
       "            [ 0.0468,  0.0558,  0.0507]],\n",
       "  \n",
       "           [[-0.0685, -0.0638, -0.0694],\n",
       "            [ 0.0650,  0.0551,  0.0574],\n",
       "            [ 0.0616,  0.0534,  0.0535]],\n",
       "  \n",
       "           [[ 0.0643,  0.0694,  0.0641],\n",
       "            [ 0.0497,  0.0612,  0.0463],\n",
       "            [ 0.0588,  0.0505,  0.0726]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0495,  0.0664,  0.0704],\n",
       "            [-0.0681,  0.0658,  0.0521],\n",
       "            [-0.0729, -0.0647,  0.0683]],\n",
       "  \n",
       "           [[-0.0479,  0.0556,  0.0638],\n",
       "            [-0.0481,  0.0612,  0.0548],\n",
       "            [-0.0724,  0.0649,  0.0464]],\n",
       "  \n",
       "           [[-0.0560,  0.0711,  0.0506],\n",
       "            [-0.0592,  0.0563,  0.0680],\n",
       "            [-0.0536, -0.0732,  0.0470]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0495,  0.0564,  0.0610],\n",
       "            [ 0.0689, -0.0734, -0.0560],\n",
       "            [ 0.0568, -0.0695, -0.0664]],\n",
       "  \n",
       "           [[ 0.0697,  0.0612,  0.0618],\n",
       "            [ 0.0725, -0.0682,  0.0589],\n",
       "            [-0.0713, -0.0538, -0.0605]],\n",
       "  \n",
       "           [[ 0.0637,  0.0528,  0.0557],\n",
       "            [ 0.0488,  0.0652,  0.0649],\n",
       "            [ 0.0656,  0.0514,  0.0550]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0475,  0.0577, -0.0557],\n",
       "            [-0.0675, -0.0558, -0.0555],\n",
       "            [-0.0681, -0.0723,  0.0580]],\n",
       "  \n",
       "           [[-0.0643, -0.0613,  0.0511],\n",
       "            [-0.0515, -0.0724, -0.0666],\n",
       "            [-0.0504, -0.0547, -0.0733]],\n",
       "  \n",
       "           [[ 0.0493,  0.0646,  0.0529],\n",
       "            [ 0.0624,  0.0588,  0.0586],\n",
       "            [ 0.0668, -0.0469, -0.0631]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0615,  0.0600,  0.0504],\n",
       "            [ 0.0479,  0.0606,  0.0473],\n",
       "            [ 0.0529,  0.0630,  0.0605]],\n",
       "  \n",
       "           [[-0.0645, -0.0554, -0.0527],\n",
       "            [ 0.0619,  0.0526,  0.0691],\n",
       "            [ 0.0591,  0.0514,  0.0676]],\n",
       "  \n",
       "           [[ 0.0496,  0.0515,  0.0528],\n",
       "            [ 0.0702,  0.0676,  0.0737],\n",
       "            [ 0.0601, -0.0470, -0.0606]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0711,  0.0702,  0.0731],\n",
       "            [-0.0532, -0.0705, -0.0591],\n",
       "            [-0.0615, -0.0487, -0.0654]],\n",
       "  \n",
       "           [[-0.0466,  0.0595,  0.0665],\n",
       "            [ 0.0532, -0.0620, -0.0471],\n",
       "            [ 0.0728, -0.0501, -0.0499]],\n",
       "  \n",
       "           [[-0.0685,  0.0534,  0.0610],\n",
       "            [ 0.0628,  0.0704,  0.0568],\n",
       "            [ 0.0474,  0.0714,  0.0694]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0701, -0.0592,  0.0622],\n",
       "            [-0.0520, -0.0712,  0.0604],\n",
       "            [-0.0503, -0.0543,  0.0720]],\n",
       "  \n",
       "           [[-0.0696, -0.0674,  0.0505],\n",
       "            [-0.0543,  0.0657,  0.0630],\n",
       "            [-0.0728, -0.0607,  0.0672]],\n",
       "  \n",
       "           [[-0.0686, -0.0596, -0.0692],\n",
       "            [-0.0462, -0.0732, -0.0559],\n",
       "            [-0.0694, -0.0712, -0.0686]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0485, -0.0588, -0.0485, -0.0485,  0.0507, -0.0551,  0.0462, -0.0599,\n",
       "           0.0591, -0.0725,  0.0719,  0.0534, -0.0627,  0.0674, -0.0556, -0.0608,\n",
       "          -0.0696,  0.0606, -0.0500,  0.0496,  0.0522,  0.0577,  0.0512, -0.0582,\n",
       "          -0.0613,  0.0612,  0.0601,  0.0671, -0.0514, -0.0647,  0.0737, -0.0544],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.9399, 1.0600, 0.9399, 0.9399, 1.0601, 0.9399, 0.9399, 0.9399, 0.9399,\n",
       "          0.9399, 1.0600, 0.9399, 1.0601, 0.9400, 1.0601, 1.0601, 0.9400, 1.0601,\n",
       "          1.0600, 0.9399, 0.9399, 0.9399, 0.9400, 0.9399, 0.9401, 0.9399, 0.9400,\n",
       "          0.9400, 0.9400, 0.9399, 0.9400, 0.9399], device='cuda:1',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0601, -0.0601, -0.0601, -0.0601, -0.0600, -0.0601,  0.0601, -0.0601,\n",
       "           0.0600,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,  0.0601, -0.0600,\n",
       "          -0.0601, -0.0601, -0.0601,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,\n",
       "           0.0600, -0.0601, -0.0601, -0.0600,  0.0601, -0.0601,  0.0601, -0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0546,  0.0687,  0.0543,  ...,  0.0662,  0.0577,  0.0519],\n",
       "          [-0.0539, -0.0641, -0.0520,  ..., -0.0554, -0.0499, -0.0689],\n",
       "          [-0.0678, -0.0542, -0.0593,  ..., -0.0581, -0.0615, -0.0501],\n",
       "          ...,\n",
       "          [ 0.0483,  0.0717,  0.0532,  ...,  0.0562,  0.0645,  0.0606],\n",
       "          [-0.0515, -0.0538, -0.0653,  ..., -0.0483, -0.0619, -0.0636],\n",
       "          [ 0.0627,  0.0662,  0.0645,  ...,  0.0602,  0.0595,  0.0714]],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0576,  0.0579,  0.0701,  ..., -0.0676,  0.0651, -0.0672],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0708, -0.0533, -0.0507,  ..., -0.0629,  0.0693, -0.0670],\n",
       "          [-0.0683, -0.0579, -0.0638,  ...,  0.0639, -0.0534, -0.0578],\n",
       "          [ 0.0494, -0.0683,  0.0645,  ...,  0.0494, -0.0626, -0.0676],\n",
       "          ...,\n",
       "          [-0.0626, -0.0664, -0.0557,  ..., -0.0593, -0.0490, -0.0680],\n",
       "          [-0.0689, -0.0652, -0.0678,  ..., -0.0610, -0.0570, -0.0667],\n",
       "          [-0.0643, -0.0709, -0.0576,  ...,  0.0612, -0.0529, -0.0550]],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0687,  0.0668,  0.0645, -0.0582, -0.0487, -0.0568,  0.0591, -0.0634,\n",
       "          -0.0626, -0.0523], device='cuda:1', requires_grad=True)],\n",
       " 'lr': 0.8,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[[[-1.5990e-01, -9.7942e-02,  5.0226e-03,  ...,  1.9742e-01,\n",
       "              1.4729e-01,  1.0208e-01],\n",
       "            [-7.6299e-02, -6.8681e-02, -4.5328e-02,  ...,  2.4870e-02,\n",
       "             -2.7810e-02,  7.8350e-02],\n",
       "            [-5.1901e-02, -6.1059e-02, -1.5014e-02,  ...,  1.1504e-01,\n",
       "              1.2390e-01,  2.0242e-01],\n",
       "            ...,\n",
       "            [ 1.5141e-01,  4.3206e-02, -7.1445e-02,  ...,  1.0480e-01,\n",
       "             -9.0759e-06,  6.1600e-02],\n",
       "            [ 1.0759e-01, -6.3953e-02,  1.6421e-01,  ...,  1.7835e-01,\n",
       "             -7.7521e-02,  8.9601e-02],\n",
       "            [ 1.7176e-01,  5.1343e-02, -1.3152e-02,  ..., -4.2158e-03,\n",
       "              4.9071e-02, -4.8466e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.1937e-02,  1.8164e-01,  1.8973e-01,  ..., -5.8223e-03,\n",
       "              3.5658e-02,  9.4269e-02],\n",
       "            [-1.7112e-01,  9.7162e-02, -3.1565e-03,  ..., -7.0301e-02,\n",
       "              1.8508e-01,  8.9966e-02],\n",
       "            [-1.6398e-01,  5.3017e-02,  7.3726e-02,  ..., -9.5444e-02,\n",
       "             -4.4003e-02,  1.4091e-01],\n",
       "            ...,\n",
       "            [-1.3385e-01,  1.3939e-03, -1.8135e-01,  ...,  4.4920e-03,\n",
       "             -7.3203e-02,  1.4611e-01],\n",
       "            [-1.5426e-01, -6.2293e-02, -1.7896e-02,  ...,  1.1012e-01,\n",
       "             -5.9048e-03,  1.5658e-01],\n",
       "            [ 1.2283e-01, -1.9205e-01,  7.6853e-02,  ...,  1.8903e-01,\n",
       "             -8.2257e-02,  9.5414e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-5.3248e-02, -5.5211e-02, -7.2681e-02,  ...,  5.4796e-03,\n",
       "              1.4298e-01,  5.3818e-02],\n",
       "            [ 1.0207e-01,  2.3275e-03, -8.1739e-02,  ...,  9.8285e-02,\n",
       "             -1.9700e-02,  1.7947e-01],\n",
       "            [ 1.7920e-01, -3.5690e-02,  4.0981e-03,  ..., -1.9080e-01,\n",
       "             -6.9812e-02,  1.1733e-01],\n",
       "            ...,\n",
       "            [ 6.8322e-02,  5.4200e-02, -3.8376e-02,  ..., -3.5981e-02,\n",
       "             -1.5726e-01, -1.6865e-02],\n",
       "            [-5.5672e-02, -1.9953e-01, -7.4768e-02,  ..., -1.8954e-01,\n",
       "             -1.5066e-01, -1.3166e-01],\n",
       "            [-3.0505e-02, -1.6385e-01, -5.3644e-02,  ..., -8.1707e-03,\n",
       "             -9.1821e-02,  6.2543e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-2.9640e-02, -7.3919e-02, -1.4099e-01,  ..., -1.7596e-01,\n",
       "              1.6735e-01, -2.0376e-02],\n",
       "            [ 9.7194e-02, -1.9912e-01, -1.0344e-01,  ..., -7.7119e-02,\n",
       "             -4.7041e-02,  1.1976e-01],\n",
       "            [ 1.1600e-02,  6.1269e-02,  4.0335e-02,  ..., -1.3143e-01,\n",
       "              1.8040e-01,  1.4772e-01],\n",
       "            ...,\n",
       "            [-1.3141e-02,  4.2827e-02, -5.5238e-02,  ...,  1.7334e-01,\n",
       "              6.0111e-02,  1.3455e-01],\n",
       "            [-6.8769e-02, -3.0789e-02, -1.7529e-02,  ...,  1.7617e-01,\n",
       "             -4.6167e-02, -4.6144e-02],\n",
       "            [-4.0186e-02, -1.9687e-01, -1.0848e-01,  ...,  2.3603e-02,\n",
       "              1.3195e-01,  1.6205e-01]]],\n",
       "  \n",
       "  \n",
       "          [[[ 5.7258e-02, -1.8490e-01, -1.9470e-01,  ...,  8.8506e-02,\n",
       "              5.1941e-02,  7.1144e-03],\n",
       "            [ 1.7936e-02,  1.2385e-01, -1.1980e-03,  ..., -4.7335e-02,\n",
       "              6.4082e-02, -6.0777e-02],\n",
       "            [ 5.6281e-02,  7.5180e-02,  1.5922e-01,  ...,  2.5065e-02,\n",
       "              2.9736e-02, -1.8525e-01],\n",
       "            ...,\n",
       "            [ 1.2279e-01, -1.1383e-02,  7.7128e-02,  ..., -1.1860e-01,\n",
       "             -2.5905e-02,  6.2405e-02],\n",
       "            [-1.5633e-01, -1.0795e-01, -2.0112e-01,  ..., -1.6681e-01,\n",
       "              5.1555e-02,  1.2370e-02],\n",
       "            [ 4.8439e-02, -1.6821e-01,  2.7520e-02,  ..., -1.2064e-01,\n",
       "             -6.9681e-02,  6.6301e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-8.2226e-02, -8.0124e-03, -1.6611e-01,  ...,  3.4243e-02,\n",
       "              1.4296e-02,  4.9845e-02],\n",
       "            [-7.5890e-02, -1.7271e-01, -9.2039e-02,  ..., -5.7199e-02,\n",
       "              2.1592e-02,  1.9262e-02],\n",
       "            [-7.2020e-02, -1.8591e-01, -5.7096e-02,  ...,  1.4564e-01,\n",
       "              1.7117e-01, -7.6180e-02],\n",
       "            ...,\n",
       "            [-7.3659e-02, -4.0230e-02, -3.9004e-03,  ...,  1.3210e-01,\n",
       "             -5.5328e-02,  4.6880e-02],\n",
       "            [-2.8578e-02,  5.0958e-02,  1.1931e-01,  ..., -5.8856e-02,\n",
       "             -1.5853e-01, -1.2103e-01],\n",
       "            [-4.9190e-02, -6.5898e-02,  8.0315e-03,  ...,  1.3173e-01,\n",
       "             -6.3942e-02, -1.4959e-01]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.8167e-02,  1.7427e-01,  7.1828e-02,  5.9750e-02,  1.6582e-01,\n",
       "           1.4754e-01,  7.2470e-02,  1.3732e-01,  1.3407e-01,  2.5424e-02,\n",
       "           1.6653e-01, -1.4432e-01,  1.3041e-01,  3.2491e-02,  1.2896e-01,\n",
       "          -1.8139e-01, -2.4734e-02,  4.3505e-02, -6.2008e-03, -6.5936e-02,\n",
       "           1.7903e-01, -4.3727e-02,  1.4897e-01,  5.1953e-03,  3.4557e-02,\n",
       "          -4.5972e-02, -1.6058e-01, -1.5312e-01, -1.8340e-01, -2.0071e-01,\n",
       "           1.8027e-01,  1.2841e-01, -6.6038e-02, -1.8722e-02, -1.0047e-01,\n",
       "          -7.6401e-02,  1.9920e-01,  7.2139e-02, -2.6995e-02,  5.9052e-02,\n",
       "          -7.2766e-02, -1.5916e-03,  5.8029e-02,  4.8098e-03,  1.2133e-01,\n",
       "          -6.7689e-02, -3.5042e-03, -4.9329e-02,  9.8978e-03, -4.3473e-02,\n",
       "           1.8010e-01,  3.3872e-02, -1.0510e-01, -6.6082e-02,  4.4661e-02,\n",
       "           1.3621e-01, -1.8224e-02,  1.3655e-01, -1.2544e-01,  1.5500e-01,\n",
       "           1.4651e-01,  1.6677e-01,  1.4051e-01,  5.2027e-02,  1.8990e-01,\n",
       "          -1.5002e-01, -1.7871e-01,  1.1446e-01, -2.9816e-02, -7.8911e-02,\n",
       "          -1.9568e-01, -1.4031e-01, -5.2782e-02,  1.0778e-01, -1.0700e-01,\n",
       "          -6.6215e-02,  3.5220e-02, -1.7169e-01,  4.2563e-02,  1.8897e-01,\n",
       "           1.1847e-01, -2.0316e-02,  1.3712e-01, -3.3497e-02, -1.0172e-01,\n",
       "          -1.8316e-01, -2.4232e-02,  1.2613e-01,  3.8420e-02, -1.2612e-01,\n",
       "           6.6982e-02,  5.8687e-02,  7.0531e-02,  2.1777e-03, -3.0621e-02,\n",
       "          -7.8647e-02,  1.7633e-01,  2.0124e-01,  8.9417e-02, -6.5040e-02,\n",
       "          -6.8200e-02, -4.9139e-02,  7.5341e-02,  1.8835e-01, -2.8449e-02,\n",
       "           5.9081e-02,  4.8040e-02,  5.2645e-03, -1.5314e-02, -1.0487e-01,\n",
       "          -1.7193e-01, -1.7425e-02,  2.9920e-02, -6.4032e-02, -1.0783e-01,\n",
       "          -2.7768e-02, -1.9537e-01, -1.2437e-01, -3.4430e-02,  1.1706e-01,\n",
       "           1.7948e-01,  6.6160e-02,  9.2733e-02,  4.8882e-02,  1.9044e-01,\n",
       "           9.1907e-02,  1.8012e-02,  3.2363e-02,  1.7917e-02, -6.4927e-02,\n",
       "          -4.4376e-02, -1.1045e-01,  3.2315e-02,  1.3014e-01, -6.1121e-02,\n",
       "           1.1676e-02, -3.2528e-02,  5.4819e-02, -2.5784e-02, -4.3140e-02,\n",
       "          -2.2195e-02, -4.3537e-02,  1.2871e-01, -7.4298e-02, -5.4494e-02,\n",
       "           1.2225e-01,  1.2714e-01, -1.6212e-01, -1.2290e-01, -3.3866e-03,\n",
       "          -1.0470e-04, -1.5437e-01,  1.5726e-02,  8.2818e-02, -7.1467e-02,\n",
       "          -1.2291e-01,  1.8606e-01,  3.7953e-02,  9.0964e-02, -1.4184e-01,\n",
       "           1.2847e-01,  5.1361e-02, -1.2274e-02,  8.9286e-02,  1.8987e-01,\n",
       "           1.6426e-01,  6.5310e-02,  1.8609e-01, -1.5264e-02, -1.9693e-01,\n",
       "           1.5901e-01, -1.0330e-01, -5.4901e-02,  6.1161e-02, -6.3650e-02,\n",
       "          -1.5566e-01, -9.0725e-02, -3.8710e-02,  2.9677e-02,  5.4303e-02,\n",
       "          -4.4934e-02,  3.1172e-02, -7.4079e-02, -5.8764e-03,  6.1510e-02,\n",
       "          -1.2898e-01,  1.8772e-01, -1.7915e-01, -3.2454e-02, -1.3055e-01,\n",
       "           1.0717e-01,  9.4811e-02,  2.1185e-02, -1.7109e-01,  3.3438e-02,\n",
       "          -9.8502e-02,  8.7848e-02, -8.2520e-02,  2.6471e-02,  3.9794e-03,\n",
       "           1.0252e-01, -1.2017e-02, -1.3428e-01, -8.5310e-02, -1.5915e-02,\n",
       "           1.9002e-01,  8.3059e-02,  2.7935e-02, -7.5448e-02, -1.2517e-01,\n",
       "          -1.5073e-01, -1.8854e-01,  1.9113e-01,  9.4833e-02,  1.6288e-01,\n",
       "          -4.2656e-02,  1.6889e-01,  8.0071e-02, -7.5490e-02, -2.6175e-02,\n",
       "          -6.2019e-02,  1.4742e-01,  7.5616e-02,  8.2509e-02,  2.7313e-02,\n",
       "           1.2571e-01, -9.1052e-02, -1.9082e-01,  5.2890e-02, -1.3257e-01,\n",
       "          -2.0476e-02, -1.5127e-01, -1.6548e-01, -4.9224e-02, -1.3146e-01,\n",
       "           4.3257e-02,  7.0461e-02,  1.6033e-02,  1.6367e-01, -1.7346e-02,\n",
       "          -1.5203e-02, -3.6301e-02, -1.0944e-01, -1.5484e-01,  9.2078e-02,\n",
       "           5.3148e-02,  1.7428e-01,  6.2901e-02,  1.4461e-01,  2.0032e-01,\n",
       "           1.0168e-01, -1.3772e-01, -5.2062e-02,  1.3379e-01,  1.0547e-01,\n",
       "           6.1239e-02,  8.2060e-02, -1.5447e-02,  3.0699e-02, -8.6161e-02,\n",
       "           1.1106e-01, -1.5142e-01, -1.0463e-01,  2.5737e-02, -7.3332e-02,\n",
       "          -8.0829e-02, -9.1622e-02,  5.9498e-02,  1.5668e-01,  1.2970e-01,\n",
       "           3.7511e-02,  1.7395e-01,  1.7871e-02,  5.8868e-02, -1.2082e-01,\n",
       "          -5.3043e-03,  4.2380e-02,  3.1874e-02, -1.0856e-04, -1.1715e-01,\n",
       "           4.5006e-02,  5.2657e-02,  1.4530e-01, -1.4787e-01, -2.4275e-02,\n",
       "          -1.0786e-01,  3.9140e-02, -7.5809e-02,  8.5338e-02,  6.2458e-02,\n",
       "          -1.4588e-01,  6.7843e-02, -5.0131e-02,  1.9522e-01,  1.5338e-01,\n",
       "          -4.5785e-02,  7.5339e-02,  8.0621e-02,  5.5636e-02, -7.2135e-02,\n",
       "          -4.7704e-02,  3.6254e-03, -1.0946e-02, -7.9055e-02,  7.5346e-02,\n",
       "           5.7315e-02,  9.2809e-02, -1.0175e-01, -5.7346e-02, -6.0016e-02,\n",
       "          -6.1106e-02,  1.3329e-01,  1.2572e-01, -7.0544e-03, -1.4502e-01,\n",
       "          -1.1292e-01, -2.0134e-02,  1.5554e-01, -4.1603e-02,  1.4262e-01,\n",
       "           1.9015e-01, -1.2466e-01,  1.2922e-01, -1.4496e-01, -5.4652e-02,\n",
       "           1.6897e-02, -7.0841e-02,  7.0609e-02,  7.5779e-02, -1.1227e-01,\n",
       "          -1.4551e-02,  4.3763e-02,  8.1951e-02,  7.4855e-02, -1.5653e-01,\n",
       "          -1.5028e-01,  4.6875e-02, -4.8786e-02,  1.2711e-01,  1.9745e-01,\n",
       "           7.9750e-02, -1.3858e-03, -6.1062e-02,  2.6581e-02, -1.2918e-02,\n",
       "           3.5895e-02, -9.3168e-02, -4.1284e-02,  6.6618e-02, -5.3816e-02,\n",
       "           1.5841e-02, -8.3886e-02,  8.4826e-03,  2.8857e-02, -7.6782e-02,\n",
       "          -6.4913e-02,  2.6589e-02,  1.4262e-01,  1.3049e-02, -1.2823e-02,\n",
       "          -1.2079e-01,  6.2057e-02,  7.9391e-02, -5.8023e-02,  9.4921e-02,\n",
       "           7.7148e-02,  8.3707e-02, -1.5385e-01, -1.2525e-01, -1.9638e-02,\n",
       "          -3.9498e-02, -1.1942e-02, -1.3671e-01,  8.8016e-04,  1.0720e-01,\n",
       "           2.1889e-02, -7.4919e-02, -1.7721e-01,  3.8316e-02,  7.0471e-02,\n",
       "          -1.3011e-02, -3.2194e-02, -4.6542e-02,  1.6512e-01, -6.9677e-02,\n",
       "          -1.0807e-01, -1.0373e-01,  2.8600e-02, -2.2669e-02,  1.8077e-01,\n",
       "           6.9956e-02,  8.9127e-03, -1.8365e-01, -1.1247e-01,  1.9685e-01,\n",
       "           3.7107e-03,  6.5596e-02,  7.7863e-02, -4.5734e-02, -1.5122e-02,\n",
       "          -1.2089e-01,  1.5620e-01,  4.8382e-02, -1.9863e-01,  1.1566e-01,\n",
       "          -1.7558e-01, -8.0683e-02, -3.6024e-02,  9.1467e-02, -5.9203e-02,\n",
       "          -6.1896e-02,  7.5169e-02,  3.1257e-02,  4.3976e-02, -9.8494e-02,\n",
       "          -6.1396e-03, -1.4352e-02, -6.0709e-02, -4.8127e-02, -1.1525e-01,\n",
       "          -8.0372e-02,  2.8901e-02, -5.2233e-02,  6.7757e-03,  9.1734e-02,\n",
       "           1.3070e-01,  1.5953e-01,  8.8138e-03,  1.3401e-01, -7.6659e-02,\n",
       "           8.3603e-02, -9.5557e-02,  4.7013e-02,  5.9766e-03,  1.0011e-02,\n",
       "           7.6062e-02, -6.6325e-02,  3.0848e-02, -1.5658e-02,  1.9066e-01,\n",
       "           2.8279e-02,  1.7440e-01, -6.0070e-02,  1.4882e-02,  1.5123e-01,\n",
       "          -6.4650e-02, -9.7383e-02, -5.3190e-02,  4.5808e-02,  8.4361e-02,\n",
       "          -1.4845e-01,  1.9642e-01, -7.1961e-02,  1.9631e-01,  1.0865e-01,\n",
       "          -1.4355e-01, -9.7917e-02,  1.0385e-01,  4.3094e-02,  6.6414e-02,\n",
       "           1.5030e-01,  1.5010e-01, -1.5071e-02, -4.5050e-02,  1.6611e-01,\n",
       "           1.6992e-02, -1.9860e-01,  1.5021e-02,  2.5937e-02, -2.2218e-02,\n",
       "           2.4087e-02, -1.1881e-01, -1.7577e-01,  7.1243e-02, -1.6439e-01,\n",
       "          -7.3573e-02, -1.3193e-01, -1.6456e-01, -1.7228e-01,  3.6621e-02,\n",
       "           4.2445e-02,  1.0091e-01, -1.3382e-01, -3.0692e-02, -1.9432e-01,\n",
       "          -9.3457e-02, -5.7430e-03,  1.5417e-01, -1.3316e-02, -1.4445e-01,\n",
       "          -1.9126e-01, -1.6478e-01,  1.6050e-01, -4.9046e-02,  3.3289e-02,\n",
       "           1.3652e-01,  1.6172e-01, -9.5312e-02, -5.3180e-02,  1.6389e-02,\n",
       "          -1.8916e-02, -9.7877e-02, -5.0261e-02,  2.6980e-02, -1.2025e-01,\n",
       "          -1.5392e-01,  5.7081e-02, -3.1825e-02,  1.4998e-02,  3.3995e-03,\n",
       "           6.0985e-03, -7.0484e-02], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([1.0601, 1.0600, 0.9401, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601, 0.9400,\n",
       "          0.9400, 0.9400, 1.0600, 0.9399, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400,\n",
       "          0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0601,\n",
       "          1.0592, 1.0601, 1.0600, 1.0599, 1.0601, 1.0600, 1.0600, 1.0600, 1.0600,\n",
       "          0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "          0.9399, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9399,\n",
       "          0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 0.9399, 0.9400,\n",
       "          1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0600,\n",
       "          0.9399, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0601,\n",
       "          1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "          1.0598, 0.9400, 1.0600, 0.9400, 1.0601, 1.0600, 0.9400, 0.9400, 1.0599,\n",
       "          1.0600, 1.0600, 0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600,\n",
       "          0.9400, 1.0601, 1.0601, 0.9400, 1.0600, 1.0601, 0.9400, 1.0600, 1.0600,\n",
       "          1.0600, 0.9399, 1.0601, 0.9401, 0.9400, 0.9400, 1.0600, 0.9400, 0.9400,\n",
       "          1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "          0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 1.0601,\n",
       "          1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 0.9400, 0.9401,\n",
       "          1.0600, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400, 1.0600, 1.0601, 0.9400,\n",
       "          1.0600, 1.0600, 0.9399, 1.0600, 1.0600, 1.0600, 1.0601, 0.9400, 1.0600,\n",
       "          1.0598, 0.9400, 1.0600, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "          1.0600, 1.0599, 0.9400, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600, 1.0600,\n",
       "          1.0601, 0.9403, 0.9400, 0.9399, 1.0601, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "          1.0601, 1.0601, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 0.9399,\n",
       "          0.9400, 0.9400, 1.0600, 1.0601, 0.9400, 0.9400, 0.9400, 0.9401, 1.0600,\n",
       "          0.9401, 1.0600, 0.9400, 0.9400, 1.0601, 0.9400, 1.0600, 1.0600, 1.0601,\n",
       "          1.0599, 1.0600, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 1.0600, 1.0600,\n",
       "          1.0600, 1.0600, 1.0601, 0.9400, 1.0600, 0.9400, 1.0599, 0.9399, 1.0601,\n",
       "          0.9400, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399, 1.0600, 0.9401,\n",
       "          1.0601, 1.0600, 1.0600, 0.9400, 0.9399, 1.0600, 0.9399, 0.9400, 0.9400,\n",
       "          0.9400, 0.9402, 1.0600, 1.0600, 1.0600, 0.9399, 0.9400, 0.9400, 1.0601,\n",
       "          1.0601, 1.0601, 0.9400, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 0.9400,\n",
       "          1.0600, 0.9402, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "          0.9399, 1.0600, 0.9400, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 0.9400,\n",
       "          1.0600, 0.9402, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          1.0600, 0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400,\n",
       "          1.0601, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0601, 0.9399,\n",
       "          0.9400, 1.0600, 0.9401, 1.0600, 0.9400, 0.9399, 1.0600, 1.0600, 1.0600,\n",
       "          0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 1.0601, 1.0600, 0.9399, 1.0600,\n",
       "          1.0600, 0.9400, 1.0598, 1.0601, 1.0600, 0.9400, 0.9400, 0.9400, 0.9401,\n",
       "          0.9400, 1.0600, 0.9399, 1.0601, 0.9401, 1.0600, 0.9399, 1.0601, 1.0599,\n",
       "          0.9399, 1.0600, 1.0600, 0.9400, 1.0600, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "          0.9401, 0.9400, 0.9400, 1.0600, 1.0601, 1.0600, 0.9400, 0.9400, 1.0601,\n",
       "          1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600, 1.0581, 0.9399, 1.0600,\n",
       "          1.0600, 1.0601, 1.0601, 0.9400, 1.0600, 0.9399, 1.0600, 1.0601, 0.9401,\n",
       "          1.0601, 0.9400, 1.0601, 0.9400, 1.0601, 1.0600, 0.9400, 1.0600, 0.9400,\n",
       "          1.0601, 0.9400, 0.9400, 1.0601, 1.0600, 1.0600, 0.9400, 1.0598, 1.0600,\n",
       "          0.9400, 1.0600, 0.9400, 0.9400, 1.0600, 0.9400, 0.9407, 1.0600, 1.0600,\n",
       "          0.9400, 0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600,\n",
       "          0.9399, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600, 1.0601,\n",
       "          1.0600, 1.0601, 1.0600, 0.9399, 0.9400, 1.0600, 1.0600, 0.9400, 1.0600,\n",
       "          0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 1.0600, 1.0600,\n",
       "          1.0601, 0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "          1.0600, 1.0601, 0.9400, 0.9402, 0.9399, 1.0600, 1.0601, 1.0601, 0.9400,\n",
       "          1.0600, 0.9400, 0.9399, 1.0600, 1.0601, 1.0600, 1.0601, 1.0600, 0.9400,\n",
       "          0.9400, 0.9399, 1.0600, 0.9400, 0.9400, 1.0601, 1.0600, 0.9400, 0.9401,\n",
       "          1.0600, 1.0598, 1.0600, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0597, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0599,  0.0599,  0.0600,\n",
       "           0.0512,  0.0600, -0.0600, -0.0600,  0.0600, -0.0598, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0596,  0.0599,  0.0598,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600,  0.0599, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600, -0.0594,  0.0600,  0.0600, -0.0600, -0.0598, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600,  0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0597,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0599, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600,  0.0599,  0.0600,  0.0593, -0.0600,  0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600,  0.0600,  0.0599, -0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0577, -0.0600,\n",
       "           0.0600, -0.0600,  0.0595, -0.0600, -0.0600, -0.0600,  0.0597, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0598,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600,  0.0596, -0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600, -0.0600, -0.0599,  0.0600, -0.0600,  0.0600,\n",
       "           0.0599, -0.0584,  0.0600, -0.0599,  0.0600,  0.0600, -0.0600,  0.0600,\n",
       "           0.0600, -0.0599, -0.0600, -0.0600,  0.0600, -0.0600,  0.0489, -0.0600,\n",
       "          -0.0599,  0.0600, -0.0599,  0.0600,  0.0586, -0.0600,  0.0600,  0.0600,\n",
       "          -0.0598,  0.0600, -0.0600,  0.0599,  0.0600,  0.0600, -0.0592,  0.0600,\n",
       "           0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0548, -0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0598,  0.0600,\n",
       "          -0.0600, -0.0598, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,  0.0600,\n",
       "           0.0596, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0599, -0.0600, -0.0600, -0.0599,  0.0599, -0.0600, -0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0599, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0598, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600,\n",
       "           0.0578,  0.0600,  0.0600,  0.0576, -0.0598, -0.0600, -0.0599,  0.0598,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0599,  0.0600,  0.0600, -0.0599,  0.0600,  0.0599, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0589,  0.0600,\n",
       "           0.0600,  0.0600,  0.0599,  0.0600, -0.0600, -0.0598, -0.0600, -0.0598,\n",
       "           0.0600, -0.0600, -0.0599,  0.0600,  0.0600, -0.0600, -0.0600, -0.0586,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600, -0.0600, -0.0598,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600, -0.0600,  0.0599,  0.0600,  0.0600,  0.0537,  0.0600,  0.0600,\n",
       "          -0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0599, -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0566,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0598,  0.0600,\n",
       "           0.0600,  0.0600,  0.0600,  0.0600, -0.0598, -0.0600, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600, -0.0600,  0.0600,  0.0600, -0.0600, -0.0588,  0.0600,\n",
       "           0.0600, -0.0600, -0.0600,  0.0600,  0.0573,  0.0599, -0.0600, -0.0600,\n",
       "           0.0600, -0.0600, -0.0600, -0.0599,  0.0600, -0.0600, -0.0600,  0.0600,\n",
       "          -0.0600, -0.0600, -0.0600, -0.0600,  0.0571,  0.0598, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2453, -0.0800, -0.0261,  0.2573,  0.0137],\n",
       "            [ 0.1347, -0.0993, -0.0091,  0.1237,  0.2133],\n",
       "            [-0.1203,  0.1583, -0.1118,  0.0746, -0.0516],\n",
       "            [ 0.0211,  0.1537,  0.0209, -0.0052, -0.1673],\n",
       "            [ 0.0071, -0.1311, -0.0563,  0.0044,  0.0009]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0394, -0.1376, -0.1337, -0.1827,  0.1238],\n",
       "            [ 0.1211, -0.0602, -0.0912, -0.1345, -0.0577],\n",
       "            [-0.2154, -0.1498, -0.0292,  0.0635, -0.0607],\n",
       "            [-0.0051,  0.2468, -0.2046, -0.0599, -0.1780],\n",
       "            [-0.0299, -0.1748, -0.1545, -0.1388, -0.1679]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2593, -0.0949,  0.1343, -0.0551,  0.2540],\n",
       "            [-0.0428, -0.1399, -0.0779,  0.0574,  0.1892],\n",
       "            [-0.2128, -0.1716,  0.1081,  0.0639, -0.0592],\n",
       "            [-0.1870,  0.1170, -0.1113, -0.1670,  0.0479],\n",
       "            [ 0.1192, -0.1164,  0.0632,  0.0048, -0.2199]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.0081, -0.0432, -0.1522, -0.0360,  0.1212],\n",
       "            [ 0.0993, -0.2594,  0.0096, -0.1371, -0.1064],\n",
       "            [-0.0940,  0.0671, -0.1217,  0.2246, -0.1447],\n",
       "            [-0.0669,  0.0071,  0.2307,  0.0134, -0.2541],\n",
       "            [-0.0932, -0.0058, -0.2276, -0.2369, -0.0368]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0216, -0.1973,  0.1075,  0.1047, -0.0592],\n",
       "            [-0.2475, -0.2583,  0.0632, -0.0388,  0.0058],\n",
       "            [-0.0071,  0.0473,  0.0826,  0.1176,  0.2552],\n",
       "            [ 0.1211, -0.0400,  0.0058, -0.1140,  0.0338],\n",
       "            [-0.0885,  0.1182,  0.1937,  0.1002,  0.0021]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0262, -0.0207, -0.0044, -0.1043,  0.0903],\n",
       "            [ 0.2437, -0.0761,  0.0686,  0.1320, -0.2127],\n",
       "            [-0.1985, -0.1377, -0.0134, -0.2302, -0.0669],\n",
       "            [-0.1081, -0.2339,  0.0013,  0.1274, -0.2081],\n",
       "            [-0.2247, -0.2600, -0.0780,  0.0998,  0.0049]]]], device='cuda:1',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0288,  0.1469,  0.2572,  0.1455,  0.0588,  0.0765, -0.1986,  0.0944,\n",
       "          -0.2509,  0.0802, -0.1385, -0.0133, -0.0170,  0.1253, -0.1885, -0.0091,\n",
       "           0.1322, -0.0832,  0.0583, -0.1532,  0.1548,  0.2562,  0.0436,  0.2036,\n",
       "           0.0478, -0.0392, -0.0107,  0.0334, -0.2536,  0.0020, -0.0894, -0.1814,\n",
       "           0.1275,  0.0119,  0.0621, -0.2426,  0.0614,  0.0997,  0.1022,  0.1255,\n",
       "           0.2229, -0.0302, -0.1128, -0.0646, -0.0236,  0.0625,  0.0871, -0.0654,\n",
       "          -0.1177,  0.0190, -0.2554,  0.0629, -0.0415, -0.1036,  0.0532,  0.0410,\n",
       "           0.2405,  0.1343, -0.0100, -0.0317, -0.0856,  0.2000, -0.1151, -0.1362],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400, 1.0600, 1.0600, 1.0600,\n",
       "          1.0600, 0.9399, 1.0600, 0.9399, 1.0600, 1.0600, 0.9401, 0.9400, 1.0600,\n",
       "          1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400, 0.9400,\n",
       "          1.0600, 1.0600, 1.0600, 1.0600, 1.0600, 0.9400, 0.9400, 0.9400, 1.0600,\n",
       "          0.9399, 1.0600, 1.0600, 0.9400, 1.0601, 0.9399, 1.0600, 1.0600, 0.9400,\n",
       "          1.0601, 1.0601, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 0.9399, 0.9399,\n",
       "          0.9400, 0.9400, 0.9400, 1.0600, 0.9400, 1.0600, 1.0600, 0.9400, 0.9400,\n",
       "          1.0600], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0600, -0.0600,  0.0600, -0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,\n",
       "          -0.0600, -0.0600,  0.0600,  0.0598,  0.0600, -0.0594, -0.0600, -0.0600,\n",
       "          -0.0600,  0.0600, -0.0600, -0.0599, -0.0600,  0.0600,  0.0600,  0.0600,\n",
       "          -0.0600,  0.0600,  0.0600,  0.0600, -0.0600, -0.0600,  0.0599,  0.0600,\n",
       "           0.0600, -0.0599,  0.0600, -0.0598,  0.0600, -0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600,  0.0600, -0.0600, -0.0600,  0.0600, -0.0600,\n",
       "           0.0600,  0.0600, -0.0600, -0.0600,  0.0600,  0.0600,  0.0600,  0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.3269,  0.3376,  0.1132],\n",
       "            [-0.3058,  0.0294,  0.2141],\n",
       "            [-0.0527,  0.0887,  0.0372]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0016, -0.2299, -0.0984],\n",
       "            [-0.2386, -0.0527,  0.0149],\n",
       "            [ 0.1953,  0.3674, -0.0410]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1030, -0.2454, -0.1495],\n",
       "            [-0.1238,  0.1354, -0.1034],\n",
       "            [ 0.0923,  0.0624,  0.0144]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0386,  0.1073, -0.3635],\n",
       "            [-0.1111, -0.2862, -0.0517],\n",
       "            [ 0.1275, -0.2230, -0.1134]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3510, -0.0179,  0.1793],\n",
       "            [ 0.1666, -0.3695, -0.3223],\n",
       "            [-0.1493, -0.3289,  0.0401]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0774, -0.0535,  0.0455],\n",
       "            [-0.0977,  0.3613,  0.3804],\n",
       "            [-0.0218,  0.3432, -0.2184]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1901,  0.1241,  0.0148],\n",
       "            [ 0.0026, -0.0838,  0.1118],\n",
       "            [-0.0647,  0.0506,  0.0888]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0708,  0.1378, -0.3528],\n",
       "            [-0.0389, -0.3458,  0.2679],\n",
       "            [ 0.1595, -0.0018, -0.0951]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0185, -0.0721,  0.3827],\n",
       "            [ 0.0474,  0.2076,  0.1898],\n",
       "            [-0.1008, -0.1253,  0.0094]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1627, -0.3132, -0.1671],\n",
       "            [-0.0197,  0.0824,  0.1439],\n",
       "            [ 0.2378,  0.0428, -0.1248]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1012,  0.2255, -0.3068],\n",
       "            [ 0.2680,  0.2954,  0.3061],\n",
       "            [ 0.3459, -0.2698,  0.1819]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0948,  0.1303, -0.1320],\n",
       "            [ 0.0118,  0.3515,  0.2337],\n",
       "            [ 0.1739, -0.0960,  0.0334]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0820,  0.2203,  0.2551],\n",
       "            [ 0.2838, -0.2233,  0.3808],\n",
       "            [ 0.1507, -0.1088, -0.2116]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0157, -0.2666,  0.3496],\n",
       "            [-0.1649,  0.1017,  0.1674],\n",
       "            [ 0.2523, -0.1366,  0.2932]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1053, -0.2206, -0.3085],\n",
       "            [ 0.0172, -0.2193, -0.3585],\n",
       "            [ 0.1307,  0.2647,  0.2088]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3489, -0.0409,  0.1418],\n",
       "            [-0.1525, -0.1919, -0.3430],\n",
       "            [ 0.1563,  0.0015, -0.0016]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3790,  0.3453, -0.0246],\n",
       "            [-0.2116, -0.0378,  0.0756],\n",
       "            [-0.1251,  0.1768,  0.3686]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0915,  0.0414,  0.1043],\n",
       "            [-0.0314,  0.1969,  0.0920],\n",
       "            [-0.0232,  0.2952,  0.3034]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1688, -0.0212, -0.1975],\n",
       "            [ 0.1439,  0.2162,  0.1378],\n",
       "            [ 0.2552,  0.1640, -0.0532]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2374, -0.2078,  0.3396],\n",
       "            [-0.0753,  0.1338,  0.2909],\n",
       "            [-0.0136, -0.1792, -0.0691]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1107,  0.0075,  0.0358],\n",
       "            [ 0.1824, -0.1787,  0.1207],\n",
       "            [-0.2644,  0.3380,  0.1370]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0057,  0.1525,  0.3118],\n",
       "            [ 0.0310, -0.2211, -0.0631],\n",
       "            [ 0.1472, -0.2173,  0.3301]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3352, -0.2602, -0.0159],\n",
       "            [ 0.1570, -0.0295, -0.0747],\n",
       "            [ 0.0281, -0.0734, -0.0079]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1196, -0.2341, -0.3577],\n",
       "            [ 0.1272, -0.1568,  0.1983],\n",
       "            [ 0.0186,  0.0980, -0.2567]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0377, -0.0359,  0.1783],\n",
       "            [-0.1740, -0.1516,  0.0580],\n",
       "            [ 0.0856, -0.3458, -0.1893]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2690, -0.3563,  0.2335],\n",
       "            [-0.0411, -0.0981,  0.3489],\n",
       "            [-0.1771, -0.2193, -0.1687]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1314, -0.2470,  0.3583],\n",
       "            [-0.2674, -0.3599,  0.0621],\n",
       "            [ 0.1936, -0.1130, -0.1922]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2492,  0.3375,  0.0783],\n",
       "            [-0.0212,  0.0599,  0.3692],\n",
       "            [-0.1984, -0.1535, -0.0773]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2603,  0.0260, -0.1428],\n",
       "            [-0.0401, -0.2312, -0.1798],\n",
       "            [-0.0849,  0.0914, -0.0168]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1678, -0.2232,  0.2834],\n",
       "            [ 0.1509, -0.2445,  0.2188],\n",
       "            [ 0.3497, -0.1100,  0.2170]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2511,  0.2410,  0.2098],\n",
       "            [-0.0581,  0.1774, -0.0636],\n",
       "            [-0.0036, -0.1822,  0.2093]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1864,  0.1593, -0.0715],\n",
       "            [-0.2306,  0.2433,  0.0857],\n",
       "            [ 0.0294,  0.1967,  0.3672]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2440,  0.0382,  0.3127],\n",
       "            [-0.3238, -0.2075, -0.2322],\n",
       "            [ 0.1198,  0.2592, -0.1291]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2633,  0.1645,  0.1530],\n",
       "            [-0.1981,  0.2618, -0.1290],\n",
       "            [-0.0431, -0.0884,  0.0061]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1068,  0.1621,  0.2843],\n",
       "            [-0.1677,  0.2400, -0.1533],\n",
       "            [-0.2368,  0.0697, -0.0595]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3442,  0.1361,  0.0835],\n",
       "            [ 0.0122,  0.1348, -0.1407],\n",
       "            [ 0.1459, -0.1719, -0.0624]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0914,  0.0408, -0.3109],\n",
       "            [ 0.1178, -0.2322,  0.1720],\n",
       "            [-0.1704, -0.1037,  0.2085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1608, -0.2221,  0.1762],\n",
       "            [-0.3180, -0.1872, -0.0319],\n",
       "            [-0.0112,  0.2361,  0.2956]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1258,  0.3427,  0.2691],\n",
       "            [-0.1393,  0.0355,  0.1253],\n",
       "            [-0.1241,  0.2254,  0.3576]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3155,  0.0849,  0.2717],\n",
       "            [-0.2048, -0.0372,  0.3863],\n",
       "            [ 0.1504,  0.0348, -0.2330]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1782,  0.3248,  0.1735],\n",
       "            [-0.2453,  0.3392,  0.1689],\n",
       "            [ 0.2192, -0.3849, -0.2056]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2633,  0.1378,  0.1518],\n",
       "            [ 0.0998,  0.1505,  0.1821],\n",
       "            [-0.0589, -0.0480,  0.2372]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0473, -0.0042,  0.0334],\n",
       "            [ 0.2647, -0.1813, -0.2456],\n",
       "            [ 0.2861,  0.2428,  0.1718]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0392, -0.2271,  0.3517],\n",
       "            [-0.1371, -0.0698,  0.2699],\n",
       "            [ 0.0666,  0.1801,  0.3521]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3562, -0.1411,  0.1616],\n",
       "            [ 0.2610,  0.1506, -0.0657],\n",
       "            [-0.0699, -0.0612, -0.1657]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3698,  0.2020, -0.2125],\n",
       "            [-0.0877, -0.0151, -0.1401],\n",
       "            [ 0.2638,  0.2625,  0.1872]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1861,  0.2028,  0.0016],\n",
       "            [ 0.2549, -0.3431,  0.3722],\n",
       "            [ 0.2300,  0.0349,  0.3412]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0641,  0.1496,  0.0051],\n",
       "            [-0.0117,  0.1895,  0.1370],\n",
       "            [-0.2003, -0.2441, -0.3928]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1091,  0.0538,  0.2580],\n",
       "            [-0.2588,  0.1165, -0.0851],\n",
       "            [ 0.3182,  0.2742,  0.2786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0951,  0.1799,  0.0644],\n",
       "            [-0.2126, -0.3342, -0.1788],\n",
       "            [-0.1753,  0.0506, -0.2686]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1528, -0.1101, -0.0323],\n",
       "            [-0.1342,  0.0568,  0.1518],\n",
       "            [ 0.1398, -0.1688,  0.1560]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2394, -0.1753, -0.2501],\n",
       "            [ 0.1648,  0.0962,  0.0427],\n",
       "            [ 0.3448,  0.2341, -0.1209]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1957, -0.3921,  0.1047],\n",
       "            [ 0.1317, -0.1083, -0.1607],\n",
       "            [ 0.0159, -0.2667, -0.0118]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1196,  0.0910, -0.2165],\n",
       "            [-0.3372,  0.0103,  0.2028],\n",
       "            [-0.2916, -0.0696,  0.2602]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3215, -0.2493,  0.0172],\n",
       "            [-0.1908,  0.1707,  0.3794],\n",
       "            [ 0.1062, -0.3278, -0.1574]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2033,  0.2321,  0.0229],\n",
       "            [ 0.1731, -0.0194,  0.1993],\n",
       "            [ 0.1371, -0.2059, -0.0495]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0664, -0.1708, -0.2554],\n",
       "            [-0.3875,  0.0671,  0.0416],\n",
       "            [ 0.1544, -0.2661, -0.0172]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2396,  0.2414,  0.1776],\n",
       "            [ 0.0442,  0.0775, -0.3594],\n",
       "            [ 0.2832, -0.0484,  0.1364]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0950, -0.1686,  0.2725],\n",
       "            [ 0.1011,  0.1122,  0.2413],\n",
       "            [-0.2664,  0.1229, -0.0232]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2130,  0.1265, -0.0875],\n",
       "            [-0.3864, -0.1423,  0.0252],\n",
       "            [ 0.0934, -0.1658,  0.2515]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2508,  0.1692,  0.1474],\n",
       "            [-0.0524,  0.3914, -0.2312],\n",
       "            [ 0.1528,  0.3175,  0.3161]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3885,  0.0282, -0.2465],\n",
       "            [ 0.2420,  0.1174,  0.2517],\n",
       "            [ 0.2067,  0.0136, -0.3403]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0145,  0.3831, -0.0084],\n",
       "            [ 0.0364, -0.0421, -0.1523],\n",
       "            [ 0.1596, -0.3494,  0.1648]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3706,  0.0076, -0.2769],\n",
       "            [-0.2486, -0.3272,  0.0434],\n",
       "            [ 0.2529, -0.2475, -0.0096]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0435, -0.0704,  0.2645,  0.2072,  0.0744, -0.0911, -0.2215,  0.3429,\n",
       "          -0.0841,  0.2657, -0.3546, -0.1920, -0.0277,  0.0157,  0.2278,  0.1193,\n",
       "          -0.1689,  0.3619, -0.1523, -0.1147,  0.0276,  0.2094,  0.3264,  0.1618,\n",
       "           0.3466, -0.0203, -0.2095, -0.2572,  0.2978,  0.0554, -0.2631,  0.1339,\n",
       "          -0.0883, -0.0553, -0.2902, -0.0872, -0.2794, -0.0442,  0.2209, -0.1531,\n",
       "           0.0538,  0.2231, -0.0400,  0.1907, -0.2147, -0.3298, -0.1419,  0.1246,\n",
       "           0.1688, -0.1833, -0.2531,  0.3512,  0.3374, -0.3904,  0.2344, -0.0654,\n",
       "           0.1455,  0.2170, -0.3737,  0.1172,  0.1883,  0.1038, -0.2175,  0.1139],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.9399, 1.0600, 0.9400, 1.0601, 1.0601, 1.0601, 1.0600, 0.9399, 0.9399,\n",
       "          1.0601, 0.9399, 1.0601, 0.9399, 0.9400, 1.0601, 0.9400, 1.0600, 1.0601,\n",
       "          0.9399, 1.0601, 0.9399, 1.0601, 1.0601, 0.9399, 0.9400, 1.0600, 0.9400,\n",
       "          0.9400, 1.0600, 1.0601, 1.0601, 1.0600, 1.0601, 1.0601, 1.0600, 0.9400,\n",
       "          1.0601, 1.0601, 1.0600, 1.0600, 1.0601, 1.0601, 0.9399, 1.0601, 0.9399,\n",
       "          0.9399, 1.0601, 1.0601, 0.9400, 0.9399, 0.9400, 0.9399, 1.0600, 0.9399,\n",
       "          1.0601, 0.9399, 1.0601, 1.0601, 0.9400, 0.9400, 1.0601, 1.0601, 0.9400,\n",
       "          0.9399], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0600,  0.0600, -0.0601,\n",
       "          -0.0601, -0.0600,  0.0601, -0.0601, -0.0600, -0.0601,  0.0600, -0.0601,\n",
       "          -0.0601, -0.0601,  0.0601,  0.0601,  0.0599,  0.0601,  0.0601,  0.0601,\n",
       "           0.0600,  0.0601, -0.0601, -0.0601,  0.0601, -0.0600, -0.0600,  0.0601,\n",
       "           0.0601,  0.0601, -0.0601,  0.0599, -0.0601, -0.0601, -0.0601, -0.0601,\n",
       "          -0.0601, -0.0601,  0.0601, -0.0601, -0.0601, -0.0601, -0.0600,  0.0601,\n",
       "          -0.0601, -0.0601,  0.0600, -0.0601,  0.0601,  0.0600,  0.0601, -0.0600,\n",
       "           0.0601, -0.0600,  0.0601,  0.0601, -0.0601, -0.0601,  0.0600, -0.0601],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0685, -0.0735, -0.0471],\n",
       "            [ 0.0703, -0.0732,  0.0719],\n",
       "            [-0.0601, -0.0651,  0.0486]],\n",
       "  \n",
       "           [[ 0.0664,  0.0697,  0.0646],\n",
       "            [ 0.0463,  0.0500,  0.0716],\n",
       "            [ 0.0511,  0.0535,  0.0607]],\n",
       "  \n",
       "           [[-0.0713, -0.0466, -0.0524],\n",
       "            [-0.0504, -0.0593, -0.0588],\n",
       "            [-0.0663, -0.0484, -0.0651]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0597, -0.0541, -0.0699],\n",
       "            [-0.0566, -0.0501, -0.0665],\n",
       "            [-0.0694, -0.0609,  0.0635]],\n",
       "  \n",
       "           [[-0.0725, -0.0571, -0.0681],\n",
       "            [-0.0563, -0.0719, -0.0703],\n",
       "            [-0.0588, -0.0653, -0.0662]],\n",
       "  \n",
       "           [[-0.0608,  0.0588,  0.0556],\n",
       "            [-0.0499,  0.0734,  0.0577],\n",
       "            [-0.0577,  0.0670,  0.0619]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0516, -0.0507, -0.0680],\n",
       "            [ 0.0698,  0.0655, -0.0490],\n",
       "            [-0.0674, -0.0602, -0.0553]],\n",
       "  \n",
       "           [[ 0.0567, -0.0654, -0.0642],\n",
       "            [ 0.0689, -0.0563, -0.0605],\n",
       "            [-0.0681, -0.0606, -0.0541]],\n",
       "  \n",
       "           [[-0.0618,  0.0678,  0.0563],\n",
       "            [-0.0545,  0.0525,  0.0619],\n",
       "            [ 0.0484,  0.0463,  0.0555]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0511, -0.0553, -0.0494],\n",
       "            [-0.0530,  0.0669,  0.0615],\n",
       "            [-0.0603,  0.0537, -0.0477]],\n",
       "  \n",
       "           [[ 0.0701,  0.0729, -0.0677],\n",
       "            [ 0.0578,  0.0559, -0.0735],\n",
       "            [ 0.0497,  0.0619, -0.0639]],\n",
       "  \n",
       "           [[ 0.0617, -0.0628, -0.0507],\n",
       "            [ 0.0466, -0.0573, -0.0515],\n",
       "            [ 0.0659,  0.0485, -0.0553]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0532, -0.0501, -0.0548],\n",
       "            [ 0.0633, -0.0671, -0.0606],\n",
       "            [ 0.0660, -0.0462, -0.0465]],\n",
       "  \n",
       "           [[-0.0738, -0.0622, -0.0554],\n",
       "            [ 0.0731, -0.0629, -0.0561],\n",
       "            [ 0.0484,  0.0550,  0.0506]],\n",
       "  \n",
       "           [[ 0.0721, -0.0504, -0.0471],\n",
       "            [ 0.0686, -0.0638, -0.0629],\n",
       "            [ 0.0659, -0.0722, -0.0562]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0560,  0.0478,  0.0597],\n",
       "            [ 0.0496,  0.0494,  0.0729],\n",
       "            [ 0.0468,  0.0558,  0.0507]],\n",
       "  \n",
       "           [[-0.0685, -0.0638, -0.0694],\n",
       "            [ 0.0650,  0.0551,  0.0574],\n",
       "            [ 0.0616,  0.0534,  0.0535]],\n",
       "  \n",
       "           [[ 0.0643,  0.0694,  0.0641],\n",
       "            [ 0.0497,  0.0612,  0.0463],\n",
       "            [ 0.0588,  0.0505,  0.0726]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0495,  0.0664,  0.0704],\n",
       "            [-0.0681,  0.0658,  0.0521],\n",
       "            [-0.0729, -0.0647,  0.0683]],\n",
       "  \n",
       "           [[-0.0479,  0.0556,  0.0638],\n",
       "            [-0.0481,  0.0612,  0.0548],\n",
       "            [-0.0724,  0.0649,  0.0464]],\n",
       "  \n",
       "           [[-0.0560,  0.0711,  0.0506],\n",
       "            [-0.0592,  0.0563,  0.0680],\n",
       "            [-0.0536, -0.0732,  0.0470]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0495,  0.0564,  0.0610],\n",
       "            [ 0.0689, -0.0734, -0.0560],\n",
       "            [ 0.0568, -0.0695, -0.0664]],\n",
       "  \n",
       "           [[ 0.0697,  0.0612,  0.0618],\n",
       "            [ 0.0725, -0.0682,  0.0589],\n",
       "            [-0.0713, -0.0538, -0.0605]],\n",
       "  \n",
       "           [[ 0.0637,  0.0528,  0.0557],\n",
       "            [ 0.0488,  0.0652,  0.0649],\n",
       "            [ 0.0656,  0.0514,  0.0550]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0475,  0.0577, -0.0557],\n",
       "            [-0.0675, -0.0558, -0.0555],\n",
       "            [-0.0681, -0.0723,  0.0580]],\n",
       "  \n",
       "           [[-0.0643, -0.0613,  0.0511],\n",
       "            [-0.0515, -0.0724, -0.0666],\n",
       "            [-0.0504, -0.0547, -0.0733]],\n",
       "  \n",
       "           [[ 0.0493,  0.0646,  0.0529],\n",
       "            [ 0.0624,  0.0588,  0.0586],\n",
       "            [ 0.0668, -0.0469, -0.0631]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0615,  0.0600,  0.0504],\n",
       "            [ 0.0479,  0.0606,  0.0473],\n",
       "            [ 0.0529,  0.0630,  0.0605]],\n",
       "  \n",
       "           [[-0.0645, -0.0554, -0.0527],\n",
       "            [ 0.0619,  0.0526,  0.0691],\n",
       "            [ 0.0591,  0.0514,  0.0676]],\n",
       "  \n",
       "           [[ 0.0496,  0.0515,  0.0528],\n",
       "            [ 0.0702,  0.0676,  0.0737],\n",
       "            [ 0.0601, -0.0470, -0.0606]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0711,  0.0702,  0.0731],\n",
       "            [-0.0532, -0.0705, -0.0591],\n",
       "            [-0.0615, -0.0487, -0.0654]],\n",
       "  \n",
       "           [[-0.0466,  0.0595,  0.0665],\n",
       "            [ 0.0532, -0.0620, -0.0471],\n",
       "            [ 0.0728, -0.0501, -0.0499]],\n",
       "  \n",
       "           [[-0.0685,  0.0534,  0.0610],\n",
       "            [ 0.0628,  0.0704,  0.0568],\n",
       "            [ 0.0474,  0.0714,  0.0694]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0701, -0.0592,  0.0622],\n",
       "            [-0.0520, -0.0712,  0.0604],\n",
       "            [-0.0503, -0.0543,  0.0720]],\n",
       "  \n",
       "           [[-0.0696, -0.0674,  0.0505],\n",
       "            [-0.0543,  0.0657,  0.0630],\n",
       "            [-0.0728, -0.0607,  0.0672]],\n",
       "  \n",
       "           [[-0.0686, -0.0596, -0.0692],\n",
       "            [-0.0462, -0.0732, -0.0559],\n",
       "            [-0.0694, -0.0712, -0.0686]]]], device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0485, -0.0588, -0.0485, -0.0485,  0.0507, -0.0551,  0.0462, -0.0599,\n",
       "           0.0591, -0.0725,  0.0719,  0.0534, -0.0627,  0.0674, -0.0556, -0.0608,\n",
       "          -0.0696,  0.0606, -0.0500,  0.0496,  0.0522,  0.0577,  0.0512, -0.0582,\n",
       "          -0.0613,  0.0612,  0.0601,  0.0671, -0.0514, -0.0647,  0.0737, -0.0544],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.9399, 1.0600, 0.9399, 0.9399, 1.0601, 0.9399, 0.9399, 0.9399, 0.9399,\n",
       "          0.9399, 1.0600, 0.9399, 1.0601, 0.9400, 1.0601, 1.0601, 0.9400, 1.0601,\n",
       "          1.0600, 0.9399, 0.9399, 0.9399, 0.9400, 0.9399, 0.9401, 0.9399, 0.9400,\n",
       "          0.9400, 0.9400, 0.9399, 0.9400, 0.9399], device='cuda:1',\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0601, -0.0601, -0.0601, -0.0601, -0.0600, -0.0601,  0.0601, -0.0601,\n",
       "           0.0600,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,  0.0601, -0.0600,\n",
       "          -0.0601, -0.0601, -0.0601,  0.0601,  0.0601,  0.0600,  0.0601,  0.0601,\n",
       "           0.0600, -0.0601, -0.0601, -0.0600,  0.0601, -0.0601,  0.0601, -0.0600],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0546,  0.0687,  0.0543,  ...,  0.0662,  0.0577,  0.0519],\n",
       "          [-0.0539, -0.0641, -0.0520,  ..., -0.0554, -0.0499, -0.0689],\n",
       "          [-0.0678, -0.0542, -0.0593,  ..., -0.0581, -0.0615, -0.0501],\n",
       "          ...,\n",
       "          [ 0.0483,  0.0717,  0.0532,  ...,  0.0562,  0.0645,  0.0606],\n",
       "          [-0.0515, -0.0538, -0.0653,  ..., -0.0483, -0.0619, -0.0636],\n",
       "          [ 0.0627,  0.0662,  0.0645,  ...,  0.0602,  0.0595,  0.0714]],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0576,  0.0579,  0.0701,  ..., -0.0676,  0.0651, -0.0672],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0708, -0.0533, -0.0507,  ..., -0.0629,  0.0693, -0.0670],\n",
       "          [-0.0683, -0.0579, -0.0638,  ...,  0.0639, -0.0534, -0.0578],\n",
       "          [ 0.0494, -0.0683,  0.0645,  ...,  0.0494, -0.0626, -0.0676],\n",
       "          ...,\n",
       "          [-0.0626, -0.0664, -0.0557,  ..., -0.0593, -0.0490, -0.0680],\n",
       "          [-0.0689, -0.0652, -0.0678,  ..., -0.0610, -0.0570, -0.0667],\n",
       "          [-0.0643, -0.0709, -0.0576,  ...,  0.0612, -0.0529, -0.0550]],\n",
       "         device='cuda:1', requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0687,  0.0668,  0.0645, -0.0582, -0.0487, -0.0568,  0.0591, -0.0634,\n",
       "          -0.0626, -0.0523], device='cuda:1', requires_grad=True)],\n",
       " 'lr': 0.8,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__ 57\n",
      "__doc__ 113\n",
      "__package__ 16\n",
      "__loader__ 16\n",
      "__spec__ 16\n",
      "__builtin__ 72\n",
      "__builtins__ 72\n",
      "_ih 192\n",
      "_oh 232\n",
      "_dh 64\n",
      "In 192\n",
      "Out 232\n",
      "get_ipython 64\n",
      "exit 48\n",
      "quit 48\n",
      "_ 51\n",
      "__ 51\n",
      "___ 51\n",
      "_i 147\n",
      "_ii 64\n",
      "_iii 74\n",
      "_i1 421\n",
      "torch 72\n",
      "nn 72\n",
      "F 72\n",
      "optim 72\n",
      "SummaryWriter 1192\n",
      "torchvision 72\n",
      "datasets 72\n",
      "transforms 72\n",
      "matplotlib 72\n",
      "plt 72\n",
      "np 72\n",
      "default_timer 72\n",
      "RandomArchitectureGenerator 2008\n",
      "_i2 320\n",
      "select_n_random 136\n",
      "_i3 1770\n",
      "matplotlib_imshow 136\n",
      "images_to_probs 136\n",
      "plot_classes_preds 136\n",
      "_i4 512\n",
      "batch_size 28\n",
      "transform 48\n",
      "trainset 48\n",
      "testset 48\n",
      "trainloader 48\n",
      "testloader 48\n",
      "_i5 341\n",
      "images 64\n",
      "labels 64\n",
      "rag 48\n",
      "_i6 729\n",
      "writer 48\n",
      "device 24\n",
      "_i7 1975\n",
      "batch_tt 176\n",
      "k 24\n",
      "num_epochs 28\n",
      "start_t 24\n",
      "epoch 24\n",
      "i 24\n",
      "data 88\n",
      "batch_st 24\n",
      "inputs 64\n",
      "_i8 1985\n",
      "_i9 1996\n",
      "_i10 57\n",
      "_i11 74\n",
      "getsizeof 72\n",
      "_i12 64\n",
      "_i13 147\n",
      "local_vars 632\n",
      "var 57\n",
      "obj 57\n",
      "_i14 143\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "local_vars = list(locals().items())\n",
    "for var, obj in local_vars:\n",
    "    print(var, getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.8\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optim.Adam(cont.parameters(), lr=lr,)   \n",
    "opt.zero_grad()\n",
    "outputs = cont(inputs)\n",
    "loss = criterion(outputs, labels).to(device)\n",
    "loss.backward()\n",
    "opt.step()\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.network_map['1:Conv_Node'].model.model[2].weight.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-13e5204b19cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for k,v in cont.module_dict.parameters():\n",
    "    print(v.weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'4:Conv_Node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-c29d96a27489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'4:Conv_Node'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_copy_to_script_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '4:Conv_Node'"
     ]
    }
   ],
   "source": [
    "list(cont.module_dict['4:Conv_Node'].modules())[2].weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (torch-evo-nn)",
   "language": "python",
   "name": "torch-evo-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
