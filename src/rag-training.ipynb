{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from genotype.genotype import RandomArchitectureGenerator\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels, classes):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST('mnist_test', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Setup the RAG model and send info to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final depth:4\n",
      "Number of nodes:10\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n",
      "Warning: Negative or zero parameter. node_id: 0\n",
      "Warning: Negative or zero parameter. initialised: False\n",
      "Warning: Negative or zero parameter. terminal: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "rag = RandomArchitectureGenerator(\n",
    "    prediction_classes=10,\n",
    "    min_depth=5,\n",
    "    max_depth=7,\n",
    "    image_size=int(images.shape[2]),\n",
    "    input_channels=int(images.shape[1]),\n",
    "    min_nodes=5\n",
    ")\n",
    "\n",
    "rag.get_architecture()\n",
    "cont = rag.controller()\n",
    "rag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('module_dict.8:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.0026, -0.2131, -0.2398],\n",
       "            [ 0.0441,  0.3042,  0.0367],\n",
       "            [ 0.0206,  0.0086,  0.2252]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1537, -0.1985,  0.0838],\n",
       "            [ 0.3100, -0.1721,  0.2800],\n",
       "            [ 0.0998, -0.1382, -0.2527]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2623,  0.3249, -0.3041],\n",
       "            [ 0.3008, -0.1164,  0.2419],\n",
       "            [ 0.2958, -0.1352,  0.1218]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.0917, -0.2317, -0.1724],\n",
       "            [ 0.2914,  0.1144, -0.0217],\n",
       "            [ 0.1703, -0.2199,  0.0719]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1616, -0.2350, -0.2404],\n",
       "            [-0.0568,  0.1986,  0.2501],\n",
       "            [-0.2588,  0.0929, -0.1801]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0052, -0.2581, -0.1848],\n",
       "            [-0.1305, -0.0196,  0.1477],\n",
       "            [ 0.0822,  0.3036,  0.3173]]]], requires_grad=True)),\n",
       " ('module_dict.8:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2500, -0.0671,  0.1731, -0.0804,  0.0853,  0.0989,  0.1046, -0.0825,\n",
       "          -0.2022,  0.2832, -0.2237, -0.0299,  0.2694,  0.3056,  0.2179,  0.1410,\n",
       "           0.1707,  0.1986, -0.2381,  0.2116, -0.1091,  0.3026, -0.0388, -0.2803,\n",
       "          -0.0962, -0.0040,  0.0203, -0.0032, -0.0911,  0.0576,  0.2217,  0.2866,\n",
       "           0.2947,  0.1712,  0.3227, -0.2582, -0.1524, -0.0142, -0.0250, -0.0826,\n",
       "          -0.0295, -0.2989, -0.2727, -0.0333,  0.1670, -0.1132, -0.2588, -0.1066,\n",
       "          -0.0135,  0.1933,  0.1004,  0.0531, -0.2260,  0.0627, -0.2165, -0.2588,\n",
       "          -0.0231, -0.0438, -0.1262, -0.0959, -0.1049, -0.1715, -0.0642, -0.0756,\n",
       "           0.2852,  0.0662, -0.0803, -0.2368, -0.0210, -0.2640,  0.2182, -0.0266,\n",
       "          -0.0572,  0.1605, -0.0742, -0.2453,  0.2072, -0.1954, -0.2594, -0.0941,\n",
       "           0.1117,  0.0805,  0.2631, -0.0270,  0.1281,  0.3260,  0.3170, -0.1245,\n",
       "           0.1785,  0.1445,  0.1272,  0.1716,  0.2030, -0.2036, -0.0290, -0.3205,\n",
       "           0.1855, -0.2433,  0.1837,  0.2203, -0.0988, -0.1029,  0.3110, -0.2965,\n",
       "           0.1205, -0.0381,  0.1903,  0.1421,  0.1200,  0.2185, -0.1820,  0.0768,\n",
       "           0.1032, -0.1179, -0.0471, -0.1628,  0.2980,  0.1912,  0.2269, -0.0839,\n",
       "           0.0079,  0.0243, -0.1622,  0.1591,  0.1024,  0.1636, -0.1217,  0.2688,\n",
       "           0.1959, -0.0284, -0.1936,  0.3207,  0.2995,  0.1558,  0.2996,  0.1351,\n",
       "           0.1059, -0.1556, -0.2221,  0.2475,  0.1934, -0.0029,  0.0426, -0.2634,\n",
       "          -0.3173,  0.0314,  0.0819,  0.2421,  0.0170,  0.0183,  0.0781,  0.2236,\n",
       "           0.0838,  0.2034,  0.2764, -0.1718, -0.0131,  0.2503,  0.0996,  0.3323,\n",
       "          -0.2080,  0.2895,  0.3198, -0.0842, -0.0868,  0.1968, -0.1196, -0.3258,\n",
       "          -0.0779,  0.2254,  0.0330, -0.0722, -0.0299, -0.2779, -0.1515, -0.2064,\n",
       "          -0.1689, -0.1014, -0.2911,  0.1186,  0.2899, -0.1422, -0.1640, -0.2069,\n",
       "          -0.1212, -0.1894,  0.1604, -0.1239,  0.0225, -0.0268, -0.1549,  0.2202,\n",
       "          -0.2559,  0.0280,  0.2221, -0.2578, -0.0595, -0.1876, -0.1031,  0.2067,\n",
       "          -0.3027,  0.1051,  0.2272, -0.0383,  0.1620,  0.0282, -0.0248, -0.3041,\n",
       "           0.2626, -0.3094, -0.3043, -0.2860, -0.2175, -0.1763,  0.0861, -0.1735,\n",
       "           0.0090, -0.1106,  0.0135, -0.3079, -0.1561,  0.1985,  0.0123,  0.0943,\n",
       "           0.2431,  0.3285,  0.2416,  0.1958, -0.2640,  0.2037, -0.0064, -0.1393,\n",
       "          -0.2824, -0.0265, -0.2780,  0.1648,  0.0457, -0.0502,  0.0649, -0.0843,\n",
       "          -0.0437, -0.0742,  0.1046, -0.0669,  0.0180, -0.0606,  0.2911, -0.1735,\n",
       "          -0.2515, -0.2920, -0.3149,  0.0689, -0.0913, -0.2920,  0.1254, -0.3256,\n",
       "           0.0977,  0.1472, -0.2246,  0.0881, -0.2083, -0.2622, -0.1175,  0.1711,\n",
       "           0.1962,  0.2876, -0.0359,  0.0407, -0.1913, -0.0822, -0.2084, -0.1221,\n",
       "          -0.2937, -0.1729, -0.2576, -0.2837,  0.0657, -0.3048,  0.1241, -0.1223,\n",
       "          -0.0577,  0.1986, -0.1973,  0.2658, -0.2183,  0.0315,  0.1281, -0.0706,\n",
       "           0.0968, -0.2116,  0.2258, -0.1659, -0.1780,  0.2170,  0.1634,  0.3196,\n",
       "          -0.0464, -0.1827, -0.3302, -0.1952,  0.0039, -0.0704, -0.1375, -0.1335,\n",
       "           0.2017,  0.3099,  0.1244,  0.3043,  0.2320, -0.0886, -0.3288, -0.2177,\n",
       "          -0.3103, -0.1930,  0.0996, -0.0847,  0.2609, -0.1943,  0.2770,  0.1924,\n",
       "           0.2208, -0.1173,  0.0806,  0.0487,  0.2289, -0.2880, -0.1608, -0.0514,\n",
       "           0.3244,  0.0068, -0.0164,  0.2562, -0.0482, -0.2519, -0.0050,  0.3032,\n",
       "           0.3027, -0.0112,  0.1207,  0.3240, -0.2169, -0.3187, -0.0440, -0.2742,\n",
       "          -0.2231, -0.0563,  0.3033, -0.0225,  0.0366, -0.0981,  0.2179, -0.0205,\n",
       "          -0.1406, -0.1387,  0.0244, -0.1821, -0.1990,  0.0414, -0.0377, -0.1129,\n",
       "           0.1216, -0.2345, -0.3137, -0.0951,  0.0376,  0.0167,  0.2644,  0.3076,\n",
       "           0.2063,  0.1580, -0.2449,  0.0162, -0.2526, -0.1486, -0.2523,  0.0612,\n",
       "           0.2771,  0.2984, -0.1733, -0.0933,  0.2206, -0.0953, -0.0389, -0.3250,\n",
       "           0.3037, -0.0924,  0.1709,  0.2065, -0.1265, -0.3315, -0.1842,  0.1635,\n",
       "          -0.3078, -0.1739,  0.0076,  0.2597,  0.1398,  0.2504,  0.2437,  0.3306,\n",
       "           0.1264, -0.2177, -0.0517,  0.2786, -0.0444,  0.0069, -0.1468, -0.1408,\n",
       "          -0.0817,  0.2744,  0.0126, -0.1633,  0.0180,  0.1509, -0.1951,  0.1358,\n",
       "           0.0030, -0.3233, -0.0620,  0.2154,  0.1983,  0.2159,  0.3322,  0.2258,\n",
       "          -0.2201, -0.1217,  0.2210, -0.1413, -0.0454,  0.1620, -0.1231, -0.3059,\n",
       "           0.1143,  0.2023, -0.1786, -0.2769,  0.1767,  0.1278, -0.2068,  0.1361,\n",
       "           0.2010, -0.2290,  0.1019,  0.2791,  0.1210,  0.1670,  0.0837,  0.1392,\n",
       "          -0.0945,  0.3333,  0.0848,  0.0995, -0.2895,  0.2819,  0.1295,  0.1251,\n",
       "          -0.0997, -0.0400, -0.2063, -0.0367, -0.0798, -0.0090,  0.3188,  0.3125,\n",
       "          -0.1307, -0.1809, -0.1831,  0.0906, -0.1135,  0.2324,  0.2225, -0.2934,\n",
       "          -0.0599,  0.1228,  0.1394,  0.0607,  0.0960, -0.2052,  0.0635, -0.1276,\n",
       "           0.2681, -0.1313, -0.0189,  0.0733,  0.2899, -0.1947, -0.1494,  0.1690,\n",
       "           0.1736,  0.0827, -0.3005,  0.0916,  0.0141,  0.0465,  0.0187, -0.2277,\n",
       "          -0.0108, -0.2643,  0.0078,  0.3008,  0.2083,  0.1356, -0.0138,  0.2106,\n",
       "          -0.0853,  0.1706, -0.2988, -0.0361,  0.0543, -0.0026,  0.2016, -0.1351],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.8:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n",
       " ('module_dict.8:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n",
       " ('module_dict.7:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0237,  0.1042,  0.0453, -0.0992, -0.0503],\n",
       "            [ 0.0285, -0.0117, -0.1840,  0.1270,  0.1176],\n",
       "            [-0.1721, -0.0128,  0.0114,  0.1706,  0.1996],\n",
       "            [ 0.0886, -0.0432, -0.1769, -0.0328, -0.0646],\n",
       "            [-0.1596,  0.1577, -0.1597,  0.0102,  0.0064]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1953,  0.0948,  0.0989, -0.0428, -0.0331],\n",
       "            [-0.0895, -0.1802,  0.1399, -0.0518,  0.1320],\n",
       "            [-0.1618,  0.1367, -0.1038, -0.0203,  0.0722],\n",
       "            [ 0.1470, -0.1936, -0.1317, -0.1962, -0.1294],\n",
       "            [ 0.0428, -0.1059,  0.0112,  0.1072, -0.1108]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0206,  0.0196, -0.1071,  0.0030,  0.1439],\n",
       "            [-0.1632, -0.0061, -0.0121, -0.0071, -0.1597],\n",
       "            [ 0.0876,  0.1699,  0.1123, -0.1289,  0.0088],\n",
       "            [ 0.0021,  0.0093, -0.0687,  0.1169,  0.0552],\n",
       "            [-0.1381, -0.0323, -0.0416, -0.1451, -0.0536]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.0336,  0.1273, -0.1131,  0.1482, -0.1896],\n",
       "            [ 0.1490, -0.1913,  0.0959,  0.1904, -0.0925],\n",
       "            [-0.0537, -0.0448, -0.0738,  0.1925,  0.1905],\n",
       "            [-0.0403, -0.0149, -0.0669, -0.0865,  0.1892],\n",
       "            [-0.1077, -0.0581, -0.1586,  0.1518, -0.0578]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0673,  0.1455, -0.0892, -0.0116,  0.0755],\n",
       "            [ 0.1422, -0.1080,  0.1085, -0.1482, -0.0651],\n",
       "            [ 0.0700, -0.1103, -0.1431, -0.0283,  0.1297],\n",
       "            [-0.0991,  0.1330, -0.1671, -0.0631, -0.0543],\n",
       "            [ 0.0334, -0.0989,  0.0956,  0.1674,  0.1269]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1569, -0.1050, -0.0418, -0.0656,  0.1000],\n",
       "            [ 0.1387,  0.0559,  0.1705,  0.0335, -0.1267],\n",
       "            [ 0.0843,  0.0344,  0.1118, -0.1632, -0.1217],\n",
       "            [-0.0735,  0.1813, -0.1875,  0.0110,  0.0914],\n",
       "            [-0.1412, -0.1574,  0.1875,  0.0867,  0.1114]]]], requires_grad=True)),\n",
       " ('module_dict.7:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.8636e-02,  6.1252e-02, -8.6226e-02,  5.7563e-02,  2.9936e-02,\n",
       "          -1.3539e-01,  1.3296e-01,  8.0705e-02, -1.4290e-02, -6.0117e-02,\n",
       "           1.8961e-01, -1.7835e-01, -1.5261e-01,  1.9555e-01, -1.1421e-01,\n",
       "           1.9485e-01, -1.1831e-02,  8.8455e-02,  1.6082e-02,  1.7238e-02,\n",
       "           1.0996e-01,  4.8159e-02, -1.3647e-01, -6.1220e-02, -1.7238e-02,\n",
       "          -7.0265e-02,  1.6688e-01, -1.2789e-01,  1.1023e-02, -4.9263e-02,\n",
       "           9.4464e-04,  8.9833e-02, -1.8644e-02,  1.8490e-01, -6.0298e-02,\n",
       "          -1.2087e-01,  5.9096e-03, -1.7399e-01, -9.4222e-02,  1.3560e-02,\n",
       "           8.1934e-02,  1.0852e-01,  2.4454e-02, -5.1678e-02, -2.7721e-02,\n",
       "          -1.0690e-01, -1.7800e-01,  7.0081e-02, -2.8263e-03, -1.8904e-04,\n",
       "          -7.8884e-02,  1.1054e-01, -1.7237e-01, -3.3864e-02, -1.6241e-01,\n",
       "          -8.7011e-02, -1.0467e-01,  1.3762e-01, -1.9459e-01,  1.2241e-01,\n",
       "          -1.2107e-01, -6.4495e-02,  1.9738e-01,  1.9171e-01,  1.6087e-01,\n",
       "           1.3294e-01, -1.6351e-01,  1.5595e-01,  7.0261e-02,  7.2754e-02,\n",
       "           8.3992e-02,  1.0058e-01, -1.5179e-01,  1.1410e-01, -7.5435e-02,\n",
       "           1.7096e-01, -6.5104e-02, -6.7685e-02,  7.8093e-02, -1.0692e-01,\n",
       "           5.5733e-02, -1.0841e-01,  9.0913e-02,  1.8292e-01,  1.6394e-01,\n",
       "          -1.5153e-01, -3.2881e-02, -1.9397e-01, -9.4536e-02, -1.2206e-01,\n",
       "          -3.8160e-02, -1.1719e-01,  3.3327e-02, -1.3572e-01,  1.6053e-01,\n",
       "          -2.4338e-02,  1.1883e-01, -1.9301e-01, -1.6053e-01, -1.1335e-01,\n",
       "          -1.3733e-01,  8.0523e-02, -1.3902e-01,  9.2484e-02,  9.2595e-02,\n",
       "          -1.4575e-01, -1.1508e-01, -1.3760e-01,  1.7417e-01,  1.3625e-01,\n",
       "          -7.9913e-02, -1.5827e-01, -5.2082e-02,  8.6813e-02, -1.5432e-01,\n",
       "           1.0708e-01, -1.2207e-01, -5.0065e-02,  8.5599e-02, -6.9736e-02,\n",
       "          -1.7185e-01, -1.0028e-01,  1.6565e-01, -7.5669e-02,  1.3349e-01,\n",
       "          -5.3434e-02, -1.1232e-02,  4.4270e-03,  5.3834e-02,  7.2708e-02,\n",
       "           1.9438e-02, -7.2801e-03, -1.1576e-01,  2.2590e-03,  2.7498e-02,\n",
       "           9.7215e-02, -1.0290e-01,  1.5797e-01,  8.9728e-02, -4.5589e-02,\n",
       "           9.2463e-02, -2.3625e-02,  5.6708e-02,  3.6849e-02, -6.7992e-02,\n",
       "           1.0438e-01, -8.7995e-02, -1.4247e-01,  1.3644e-01,  3.6797e-02,\n",
       "          -1.6954e-01,  3.4635e-02,  1.1471e-01, -6.4646e-02, -1.4092e-01,\n",
       "          -1.2838e-01, -5.2905e-02, -1.3257e-01,  1.1587e-01, -8.4222e-02,\n",
       "          -1.4596e-01, -1.1832e-01,  1.3259e-01,  5.9778e-02,  1.2141e-01,\n",
       "           6.3233e-02,  1.9263e-01,  1.2841e-01, -5.6804e-02,  1.0279e-01,\n",
       "           1.1675e-01, -7.7461e-02,  1.0072e-01, -1.5698e-02,  1.7655e-01,\n",
       "          -1.2726e-02, -1.7144e-01,  1.9975e-01, -1.2444e-01, -1.0419e-01,\n",
       "           1.1485e-01,  4.5625e-02, -2.1437e-02, -1.7604e-01,  1.6074e-01,\n",
       "           2.5288e-02, -1.6347e-01,  6.4123e-02,  6.8631e-02, -1.5280e-01,\n",
       "           3.7528e-02, -1.6833e-01,  2.2736e-02,  1.2797e-01, -1.7015e-01,\n",
       "          -7.1751e-02,  1.0270e-01,  5.4716e-02, -6.3576e-02,  1.3799e-01,\n",
       "          -1.1594e-01, -2.2548e-02, -4.0584e-02, -4.5540e-03,  2.5307e-02,\n",
       "          -4.4661e-02, -1.0028e-01, -1.7989e-01, -1.7396e-01,  1.9619e-01,\n",
       "           3.1298e-02, -1.8148e-01,  1.2576e-01, -1.6159e-01, -2.7099e-02,\n",
       "          -6.4896e-02,  1.7360e-01, -1.1656e-01,  1.7449e-01, -4.9267e-02,\n",
       "           1.4547e-01,  2.4240e-02, -5.2148e-02,  1.7284e-01,  1.1561e-01,\n",
       "           8.3253e-02, -1.8709e-01, -6.2907e-02, -1.4490e-01,  6.1386e-02,\n",
       "           8.4526e-02, -1.9935e-01, -9.4749e-02,  1.9319e-01, -1.0076e-01,\n",
       "          -8.8898e-02, -5.8432e-02,  8.2282e-03,  1.6843e-01,  9.0920e-02,\n",
       "          -1.0651e-02,  3.2901e-02, -1.8244e-02,  1.9891e-01, -1.2969e-01,\n",
       "           7.0957e-02,  1.4353e-01, -5.6395e-02, -9.6600e-02,  1.6792e-01,\n",
       "           1.4077e-01,  1.7474e-01, -4.8312e-02, -1.2353e-01, -9.3131e-02,\n",
       "           1.8661e-01, -1.5510e-01,  1.8402e-01, -5.0097e-02,  8.3292e-02,\n",
       "           1.1834e-01,  7.6392e-02, -1.2837e-01, -1.1015e-01,  8.6662e-02,\n",
       "           6.7432e-02,  1.5869e-01, -1.4877e-01,  1.4190e-01,  1.1902e-01,\n",
       "           3.9941e-02,  2.4675e-02,  1.1839e-01,  6.7109e-02, -1.6552e-01,\n",
       "          -9.3623e-02,  1.0024e-01,  8.8104e-02,  1.6965e-01, -1.0168e-01,\n",
       "           1.7304e-01, -4.7994e-02, -3.0223e-02,  1.5739e-01,  1.0016e-01,\n",
       "          -7.6868e-02,  1.6120e-01,  1.0179e-01, -6.6384e-02, -8.6558e-02,\n",
       "           5.8350e-03,  1.9186e-01,  1.3633e-01,  1.8043e-02,  1.1314e-01,\n",
       "           1.4526e-01, -8.2004e-02, -1.5441e-01,  8.0736e-02,  1.3271e-02,\n",
       "          -1.6373e-01,  1.6780e-01,  3.8612e-02, -1.0760e-01, -1.2912e-01,\n",
       "          -1.3622e-01,  1.1288e-01, -2.8173e-02, -1.0943e-01, -1.4441e-01,\n",
       "           1.1957e-01, -2.0469e-02,  1.7218e-01, -9.1042e-02,  3.6980e-02,\n",
       "          -1.6584e-01, -1.6868e-01,  1.9174e-01, -7.7476e-02,  1.2206e-01,\n",
       "           1.3720e-01, -8.8427e-02,  3.1798e-02, -1.8332e-02, -1.1961e-01,\n",
       "          -1.8835e-01,  1.1415e-02,  1.6033e-01,  7.5945e-02, -3.2349e-02,\n",
       "           8.5259e-02, -1.6649e-02,  9.3876e-02,  1.2152e-01,  4.8324e-02,\n",
       "           1.6457e-01, -1.4691e-01,  1.1969e-01,  7.9430e-03, -8.5898e-02,\n",
       "          -1.8257e-01,  1.3023e-01,  6.9679e-02,  1.9638e-01, -1.0096e-01,\n",
       "          -3.7160e-02, -1.3527e-01,  7.1869e-02, -1.4380e-01,  7.5008e-02,\n",
       "           1.3418e-01,  5.8349e-02,  1.4898e-01, -9.1043e-02,  1.6630e-01,\n",
       "          -1.4088e-01,  1.1302e-01, -7.4915e-02, -4.0816e-03, -1.2282e-01,\n",
       "          -1.4338e-01, -1.6521e-02, -1.0506e-01,  1.6803e-02,  1.4777e-01,\n",
       "           1.6826e-01,  8.6317e-02, -1.9004e-01,  2.1234e-02, -1.8504e-01,\n",
       "          -5.4337e-02, -2.9290e-02,  5.9613e-02,  5.0058e-02,  9.8964e-02,\n",
       "           1.3727e-01,  3.3805e-02,  1.5241e-01, -1.1473e-02, -1.7180e-01,\n",
       "          -1.1012e-01,  1.7226e-01, -1.3178e-01,  4.3148e-02,  1.2240e-01,\n",
       "          -1.0271e-01,  1.6191e-01, -6.0075e-02, -1.5922e-01,  1.1680e-01,\n",
       "           6.9283e-02,  7.6101e-02, -5.6238e-02,  1.4789e-01,  4.5966e-02,\n",
       "          -4.7879e-02, -6.3078e-02, -8.6418e-02, -3.7207e-02, -4.9268e-02,\n",
       "           1.6761e-01, -1.8604e-01, -1.9472e-01,  6.4201e-02,  1.7691e-01,\n",
       "           1.4555e-01,  1.1550e-01, -1.2405e-01,  1.5634e-01,  1.0996e-01,\n",
       "           1.4266e-01, -1.5006e-01, -1.6709e-01,  1.4858e-01, -1.8168e-01,\n",
       "          -1.6457e-01, -1.6848e-01, -5.6477e-02,  1.8385e-01,  6.3518e-02,\n",
       "           9.0551e-02,  7.5069e-02,  1.1848e-01,  1.9176e-02, -1.3918e-01,\n",
       "          -1.2959e-01,  1.3688e-01, -1.4139e-01,  1.6760e-01,  2.3254e-02,\n",
       "          -1.0310e-01, -5.0214e-03,  1.0911e-01, -1.9475e-02,  1.2298e-01,\n",
       "          -1.9410e-01,  4.4782e-02,  1.8676e-01,  1.0931e-01, -1.7081e-01,\n",
       "           7.7606e-02,  1.7839e-01, -1.1804e-02, -1.3076e-01,  1.0383e-01,\n",
       "          -5.4807e-02,  1.9362e-01, -1.5602e-01,  5.4862e-02, -5.4653e-02,\n",
       "          -2.7796e-02,  1.8701e-01,  8.7199e-02, -7.2204e-02, -5.4648e-02,\n",
       "          -1.7078e-01,  1.8369e-01,  4.3810e-02, -3.8307e-02, -3.9282e-02,\n",
       "          -9.7241e-02, -1.6816e-01,  4.7965e-02,  1.2327e-01, -1.6357e-01,\n",
       "          -3.6782e-02,  1.7865e-01,  4.6387e-02,  1.6183e-01, -1.3113e-01,\n",
       "          -9.4845e-02, -4.1315e-02, -1.3387e-01,  1.8235e-01, -1.4502e-01,\n",
       "           1.1314e-01, -1.3120e-01,  1.1283e-01,  1.8505e-01,  9.3960e-02,\n",
       "           1.7856e-01,  6.7438e-02,  1.1827e-01, -5.2156e-02, -5.1300e-02,\n",
       "          -9.7262e-02,  4.3597e-02, -6.6909e-03, -9.6650e-02,  1.1665e-01,\n",
       "           1.1648e-01,  1.7917e-01, -3.7512e-02, -2.5811e-02,  1.7981e-01,\n",
       "          -4.6438e-02,  7.9427e-03,  5.1988e-02,  1.1502e-01,  5.8413e-03,\n",
       "           1.6629e-01,  3.3844e-02, -1.2683e-01,  1.8421e-02,  4.5765e-02,\n",
       "          -1.8364e-01, -1.7454e-03,  3.0998e-03,  1.3819e-01,  4.2254e-02,\n",
       "           8.6085e-02, -8.2205e-02], requires_grad=True)),\n",
       " ('module_dict.7:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n",
       " ('module_dict.7:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n",
       " ('module_dict.6:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 1.3741e-02, -1.3684e-02,  5.6985e-03],\n",
       "            [ 9.3148e-03,  9.2406e-03,  7.5319e-03],\n",
       "            [ 1.0980e-02,  9.8661e-03, -8.8961e-03]],\n",
       "  \n",
       "           [[ 5.4102e-03,  3.7414e-03,  6.7717e-03],\n",
       "            [ 1.1442e-02, -5.3577e-03,  7.2442e-03],\n",
       "            [-7.9742e-03,  5.7827e-03, -6.2036e-03]],\n",
       "  \n",
       "           [[ 1.2193e-02,  5.1054e-03,  8.2629e-03],\n",
       "            [ 7.8866e-03,  6.1107e-03,  7.3835e-03],\n",
       "            [-1.4616e-02,  1.0618e-02, -1.2613e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.1010e-02,  1.0558e-02, -9.1741e-03],\n",
       "            [-8.2233e-04, -8.1908e-03,  1.3451e-02],\n",
       "            [ 1.6440e-03,  6.4153e-03,  4.7806e-03]],\n",
       "  \n",
       "           [[-7.0823e-03,  2.0152e-03, -1.2958e-02],\n",
       "            [ 3.7640e-03, -1.3791e-02, -4.7198e-03],\n",
       "            [ 7.7125e-03, -1.0961e-02, -8.4929e-03]],\n",
       "  \n",
       "           [[ 6.6976e-04,  3.8074e-03, -9.2157e-04],\n",
       "            [-9.8487e-03, -5.6118e-03,  7.9752e-03],\n",
       "            [ 1.4483e-02, -1.0427e-02, -1.1514e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-9.4443e-03, -1.1981e-02,  1.2181e-02],\n",
       "            [-1.0228e-02,  3.9017e-03,  8.6659e-03],\n",
       "            [ 1.2227e-02,  2.0045e-03,  1.7343e-03]],\n",
       "  \n",
       "           [[-9.6125e-03,  8.0804e-04, -2.9639e-03],\n",
       "            [ 2.0111e-03,  7.3063e-04, -1.9598e-03],\n",
       "            [-1.1420e-02, -8.4107e-03,  2.6519e-03]],\n",
       "  \n",
       "           [[ 1.3381e-02, -1.0534e-02,  4.7350e-03],\n",
       "            [-1.0944e-02,  1.2561e-02,  8.2564e-03],\n",
       "            [-7.4841e-03,  5.2535e-04, -9.8057e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 9.5345e-03, -1.3614e-02,  5.5936e-04],\n",
       "            [-5.2535e-04, -1.0288e-02,  9.4860e-04],\n",
       "            [-1.2987e-02, -1.2111e-02, -6.6655e-03]],\n",
       "  \n",
       "           [[ 1.3545e-02,  1.0708e-02, -3.9419e-03],\n",
       "            [-5.4317e-03, -1.5595e-03, -8.2290e-03],\n",
       "            [ 1.2873e-02,  8.7850e-04,  4.4686e-03]],\n",
       "  \n",
       "           [[-1.1982e-02, -3.2741e-03, -1.2313e-02],\n",
       "            [ 3.9200e-03, -1.7463e-03, -6.2552e-03],\n",
       "            [ 8.9491e-03, -1.2113e-02,  4.9338e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-3.8204e-03,  3.9091e-03,  9.9102e-03],\n",
       "            [ 7.6527e-03,  4.7447e-03, -1.9982e-03],\n",
       "            [ 6.4276e-03,  2.8420e-03, -7.6951e-03]],\n",
       "  \n",
       "           [[-8.7546e-03, -1.0644e-02,  6.2551e-03],\n",
       "            [-1.2906e-02, -8.6350e-04,  6.5062e-04],\n",
       "            [ 4.6118e-03, -3.9018e-03, -1.2068e-02]],\n",
       "  \n",
       "           [[-8.4403e-03,  4.5917e-03,  6.3904e-03],\n",
       "            [ 5.7382e-03, -6.3276e-03, -1.2972e-02],\n",
       "            [-1.1028e-02, -2.4093e-03,  1.4298e-02]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 6.8349e-03,  1.2487e-02, -1.2082e-02],\n",
       "            [ 6.8437e-03, -1.3656e-02,  9.9401e-03],\n",
       "            [ 1.2275e-03,  6.1360e-03, -7.9652e-03]],\n",
       "  \n",
       "           [[-8.5015e-03,  4.6306e-03,  6.5548e-03],\n",
       "            [ 8.6751e-03, -1.6443e-03, -1.3800e-02],\n",
       "            [ 6.9372e-03, -1.8726e-03,  1.1277e-02]],\n",
       "  \n",
       "           [[-3.9122e-03, -9.0660e-03, -1.4288e-02],\n",
       "            [ 1.4403e-02,  6.8164e-03,  1.9760e-03],\n",
       "            [ 2.6293e-03,  5.9095e-03,  2.5089e-03]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 7.1874e-03,  6.5212e-03,  4.7237e-03],\n",
       "            [-1.1983e-02,  1.3633e-02, -6.3873e-03],\n",
       "            [ 9.4366e-03,  5.4892e-03, -5.2797e-03]],\n",
       "  \n",
       "           [[-1.7871e-03, -7.4574e-03, -1.3055e-03],\n",
       "            [-1.1104e-02,  6.0807e-03,  1.0350e-02],\n",
       "            [ 8.3068e-03,  5.5122e-03,  1.4114e-04]],\n",
       "  \n",
       "           [[ 1.1289e-02, -1.0924e-02, -9.5808e-03],\n",
       "            [ 1.3261e-03, -2.5160e-03, -1.3163e-03],\n",
       "            [ 7.8294e-03,  1.1894e-02,  6.1059e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 3.9823e-04, -9.9296e-03,  9.9567e-03],\n",
       "            [-5.7619e-03, -1.0860e-02, -1.2124e-02],\n",
       "            [-1.1041e-02,  2.4259e-03, -2.9294e-03]],\n",
       "  \n",
       "           [[ 1.1250e-02, -9.9570e-03, -1.1355e-02],\n",
       "            [-6.6525e-03,  1.4052e-02,  1.3846e-02],\n",
       "            [ 1.3003e-03,  4.5374e-03,  4.7708e-03]],\n",
       "  \n",
       "           [[-8.1031e-03, -5.5765e-03, -4.8119e-03],\n",
       "            [ 6.8386e-04,  3.5095e-03, -5.7938e-03],\n",
       "            [ 8.0639e-03,  1.4266e-02, -4.9638e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-5.6059e-05,  7.4188e-03, -2.3661e-04],\n",
       "            [-1.0914e-02,  9.5495e-03,  1.1231e-02],\n",
       "            [-1.3161e-02, -8.1064e-03,  4.0420e-03]],\n",
       "  \n",
       "           [[ 1.0464e-02, -1.3092e-02,  4.1445e-03],\n",
       "            [-8.6324e-03,  9.5907e-04, -6.5441e-03],\n",
       "            [ 8.0169e-03, -6.8802e-03, -1.0171e-02]],\n",
       "  \n",
       "           [[-4.5419e-03,  7.0470e-03,  2.8415e-03],\n",
       "            [ 1.2767e-02,  5.3357e-04, -5.5936e-03],\n",
       "            [ 1.4511e-02, -1.3415e-02, -7.7515e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-1.4580e-02, -5.8175e-03,  8.2158e-03],\n",
       "            [-4.5261e-03, -5.7967e-03,  1.3988e-02],\n",
       "            [-6.0006e-03, -4.7862e-03, -1.3928e-02]],\n",
       "  \n",
       "           [[-6.0045e-03, -2.6972e-03,  1.2367e-02],\n",
       "            [-9.5159e-03,  1.3838e-02,  1.1866e-02],\n",
       "            [ 8.4002e-03,  1.0280e-02, -7.8104e-03]],\n",
       "  \n",
       "           [[ 1.9486e-03,  1.3917e-02, -2.9206e-03],\n",
       "            [-3.0134e-03,  4.7112e-03, -1.2157e-02],\n",
       "            [ 1.3321e-02,  4.4359e-03, -8.9451e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[ 3.7528e-03,  2.6234e-03, -8.1698e-03],\n",
       "            [-2.9258e-03, -7.1363e-03, -8.2410e-04],\n",
       "            [ 5.5056e-03,  3.5841e-03,  4.3904e-03]],\n",
       "  \n",
       "           [[ 1.1964e-02,  5.2480e-03, -4.6848e-03],\n",
       "            [ 1.3477e-02, -1.2916e-02,  1.0592e-02],\n",
       "            [ 1.0114e-02, -3.4184e-03,  1.3504e-02]],\n",
       "  \n",
       "           [[-2.6949e-03, -1.1021e-02,  1.7269e-03],\n",
       "            [-3.2861e-03,  1.1589e-02, -1.2328e-02],\n",
       "            [ 7.6352e-03,  1.8601e-03, -8.9884e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.6909e-03, -1.9920e-03,  1.2010e-02],\n",
       "            [ 8.1646e-03,  5.2838e-04,  1.3141e-03],\n",
       "            [ 8.6295e-04,  1.3472e-02,  6.1610e-04]],\n",
       "  \n",
       "           [[ 9.1202e-03,  7.8895e-03, -8.6524e-03],\n",
       "            [ 1.1773e-02,  6.9174e-03, -8.7061e-03],\n",
       "            [-1.3336e-02, -9.5600e-03, -1.5676e-03]],\n",
       "  \n",
       "           [[-2.9573e-03, -1.4192e-02,  2.5041e-03],\n",
       "            [ 9.3319e-03, -1.1839e-02,  7.7742e-03],\n",
       "            [-2.3860e-03, -1.3534e-02,  2.7861e-03]]]], requires_grad=True)),\n",
       " ('module_dict.6:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.1102e-02,  1.4313e-02,  4.9768e-03,  1.4361e-02, -1.1516e-02,\n",
       "           1.2057e-02,  2.5147e-04, -4.6589e-03, -8.1362e-03, -4.3191e-04,\n",
       "           2.4430e-03,  9.2980e-03, -1.3811e-02, -4.3190e-03, -6.2307e-03,\n",
       "           1.7462e-03, -1.3310e-02, -1.0537e-02,  1.2626e-02,  1.1807e-02,\n",
       "          -6.3754e-03,  1.4181e-02, -8.4784e-04,  1.0872e-02, -9.1402e-03,\n",
       "          -9.7164e-03,  7.2981e-03,  3.3874e-05,  1.1012e-02, -7.2827e-03,\n",
       "           8.1553e-03, -9.1332e-03,  1.4164e-02, -1.3331e-03, -3.3790e-03,\n",
       "          -1.0144e-02,  1.4526e-02,  7.5911e-03, -8.5424e-03, -3.9378e-03,\n",
       "          -7.8224e-03, -1.3407e-02,  8.8931e-03, -5.5676e-03,  3.3261e-03,\n",
       "           2.0845e-03,  9.5993e-03, -4.3718e-03, -6.1775e-03, -7.3056e-04,\n",
       "           1.2159e-02, -2.1170e-04,  2.8062e-03, -4.8140e-03,  6.7490e-03,\n",
       "          -7.3168e-03,  2.5882e-04,  1.1203e-02, -8.9974e-03, -5.5879e-03,\n",
       "           1.0499e-02, -6.2766e-03, -4.8828e-03, -3.5225e-03, -3.6142e-03,\n",
       "          -8.9297e-03, -4.0649e-03, -1.3265e-02, -9.3581e-03,  6.4208e-03,\n",
       "          -8.4901e-03, -3.4061e-03, -4.5331e-03, -8.6995e-03,  6.3294e-03,\n",
       "          -7.3334e-03, -4.3990e-03, -1.2059e-02,  1.4645e-02,  1.3812e-02,\n",
       "          -1.2799e-02, -4.6368e-03, -8.1492e-03,  5.8309e-03, -1.1539e-02,\n",
       "          -1.3391e-02,  4.5799e-03, -1.3598e-02,  9.5406e-03,  4.9262e-03,\n",
       "          -1.1092e-02, -5.5574e-03,  1.0090e-02, -8.3339e-03, -3.6651e-03,\n",
       "          -1.2341e-03, -1.3303e-02, -1.0653e-02, -1.0151e-02,  6.3795e-03,\n",
       "          -1.4471e-02, -9.3390e-03, -1.1894e-02,  1.4475e-02, -6.7613e-03,\n",
       "          -7.0909e-03, -1.4388e-02,  1.0918e-02,  8.1944e-03, -4.5883e-04,\n",
       "          -1.3993e-02,  9.6806e-04,  7.8986e-03,  1.3720e-02, -1.2385e-02,\n",
       "          -1.4630e-03, -1.8114e-03,  9.2861e-03, -6.0345e-03, -9.1332e-03,\n",
       "          -9.9242e-04,  3.6294e-04, -8.5354e-03,  6.5979e-03, -2.2401e-03,\n",
       "          -6.4743e-03,  3.4941e-04,  9.8604e-03,  5.3060e-03,  3.6600e-03,\n",
       "          -5.6888e-03, -3.3183e-03,  9.2340e-03, -3.0692e-03,  9.6450e-03,\n",
       "          -1.2999e-02,  1.6404e-03,  1.1264e-02, -8.9048e-03,  1.3821e-02,\n",
       "          -5.5818e-03,  8.0817e-03,  1.2297e-02,  7.8790e-03, -6.3535e-03,\n",
       "           4.4514e-03,  4.4687e-03,  5.3482e-03,  1.3516e-02, -2.9806e-03,\n",
       "           1.1275e-03,  5.6768e-04,  4.2015e-03,  3.4086e-03,  1.2291e-02,\n",
       "           1.3127e-02,  9.2216e-03, -1.3626e-03, -9.8440e-03, -1.4222e-02,\n",
       "           1.3224e-02, -8.2992e-04,  1.1570e-02,  7.8188e-03,  6.2980e-03,\n",
       "           2.9955e-03, -4.0819e-03, -1.4419e-02, -6.0600e-03,  9.7974e-03,\n",
       "          -1.0611e-02,  5.6422e-03, -2.3267e-03,  1.3616e-03,  3.9612e-03,\n",
       "          -1.2948e-02, -1.4189e-02,  1.4665e-02, -7.8422e-03,  4.6603e-03,\n",
       "           5.2594e-03, -8.8742e-03,  1.1692e-02, -2.8238e-03, -3.1695e-03,\n",
       "          -7.0948e-03, -7.9565e-03, -9.3306e-03,  1.2471e-02,  2.3525e-03,\n",
       "          -3.4834e-03,  3.6998e-03, -1.1854e-02,  6.2651e-03,  8.3823e-03,\n",
       "          -1.0792e-02, -1.0251e-02,  1.4100e-02, -1.2851e-02,  7.9252e-03,\n",
       "          -1.0621e-02,  1.3201e-02,  9.9236e-03, -2.4937e-04,  1.2144e-03,\n",
       "          -1.2196e-02, -3.3298e-03, -7.2613e-03,  3.5580e-03, -4.1040e-03,\n",
       "          -7.1141e-03, -9.2374e-03,  8.6896e-03,  3.4494e-03,  5.2039e-04,\n",
       "           3.9416e-03,  5.1469e-03,  2.5694e-03,  7.4242e-03,  5.9186e-03,\n",
       "           9.3324e-04, -1.2424e-02, -9.8887e-03,  1.2144e-02, -3.5299e-03,\n",
       "           1.2513e-02, -8.1579e-03, -3.3445e-03, -4.1610e-03,  8.4117e-03,\n",
       "          -5.2430e-03, -2.0545e-03, -1.2687e-02, -3.3540e-03, -1.0163e-02,\n",
       "          -1.3277e-02, -2.9788e-03, -3.5578e-04,  7.4207e-03, -4.5747e-04,\n",
       "           8.4002e-03,  4.0997e-03,  7.0254e-03, -1.4301e-02,  1.1835e-02,\n",
       "           6.7242e-03, -6.6898e-03, -5.2169e-03,  1.0246e-02, -8.9568e-03,\n",
       "           3.4592e-03,  5.1306e-04, -1.4052e-02,  9.2537e-04,  3.6943e-03,\n",
       "           3.2702e-03], requires_grad=True)),\n",
       " ('module_dict.6:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1.], requires_grad=True)),\n",
       " ('module_dict.6:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.5:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 9.6598e-03,  1.1564e-02, -3.7641e-03],\n",
       "            [ 3.2449e-03,  4.5329e-03, -1.3531e-02],\n",
       "            [-1.3852e-02, -3.4067e-03,  1.4575e-02]],\n",
       "  \n",
       "           [[-4.3350e-03,  1.4658e-02,  4.1454e-03],\n",
       "            [ 6.1036e-03, -1.4400e-02, -8.5112e-03],\n",
       "            [-3.8807e-03, -1.2234e-02, -1.1710e-02]],\n",
       "  \n",
       "           [[ 2.1188e-03, -1.1991e-03,  1.3280e-02],\n",
       "            [-1.4034e-02, -1.3421e-02, -8.8389e-03],\n",
       "            [ 6.9581e-03,  7.2293e-03, -9.1492e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-1.0199e-03,  6.7536e-03, -5.3650e-03],\n",
       "            [ 1.1333e-02, -1.4109e-02, -8.3718e-03],\n",
       "            [-7.6761e-03,  9.6273e-03, -3.0692e-03]],\n",
       "  \n",
       "           [[-1.3567e-02, -3.8569e-03, -1.4013e-02],\n",
       "            [-2.8972e-03, -2.8939e-03, -1.2627e-02],\n",
       "            [ 4.0916e-03,  1.4508e-02, -9.3682e-03]],\n",
       "  \n",
       "           [[-5.6953e-03,  3.9897e-04, -1.1327e-02],\n",
       "            [ 9.3979e-03,  1.3239e-02, -4.8258e-03],\n",
       "            [ 1.2141e-02,  6.9522e-03, -8.4198e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-5.9752e-03,  4.0774e-03,  7.9289e-03],\n",
       "            [-4.7076e-03,  2.0907e-03, -6.8386e-03],\n",
       "            [ 7.9994e-04,  1.0221e-02, -8.4630e-03]],\n",
       "  \n",
       "           [[ 1.3622e-02, -8.3166e-03, -9.5613e-03],\n",
       "            [ 4.5923e-03,  8.2279e-03, -1.0443e-02],\n",
       "            [ 1.2278e-02,  4.5796e-03,  8.9245e-03]],\n",
       "  \n",
       "           [[-1.4590e-02,  1.0382e-02,  1.6361e-03],\n",
       "            [ 2.6684e-03,  9.3934e-03,  2.5910e-03],\n",
       "            [-1.4243e-02, -1.1518e-02,  1.2509e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-1.4432e-03,  1.3101e-02,  9.2522e-03],\n",
       "            [ 6.4170e-03, -1.4517e-03, -3.7343e-03],\n",
       "            [-3.6146e-03, -1.1212e-02,  2.6429e-03]],\n",
       "  \n",
       "           [[-1.2228e-02, -1.2188e-02, -3.0234e-03],\n",
       "            [ 4.3887e-03,  1.6809e-03,  9.1468e-03],\n",
       "            [ 1.3184e-02,  5.1551e-03,  2.1531e-03]],\n",
       "  \n",
       "           [[ 1.2607e-02, -2.4793e-03,  6.0416e-03],\n",
       "            [ 2.2170e-03,  7.5604e-03, -1.2201e-02],\n",
       "            [ 9.7410e-04,  7.2941e-03, -1.3004e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.0788e-03,  5.4673e-03,  9.6454e-03],\n",
       "            [ 1.1699e-02, -7.3234e-03, -4.8163e-03],\n",
       "            [-9.8016e-03, -3.1810e-03, -8.1699e-03]],\n",
       "  \n",
       "           [[ 2.0969e-03,  1.0630e-02,  5.3986e-03],\n",
       "            [-6.1983e-04,  5.6225e-03, -9.2526e-03],\n",
       "            [ 1.0398e-02, -3.3379e-03,  9.0393e-03]],\n",
       "  \n",
       "           [[-1.0778e-02, -5.1570e-04,  1.2531e-02],\n",
       "            [-1.4257e-02, -7.4488e-03,  8.5291e-03],\n",
       "            [ 5.2381e-03, -3.2621e-03, -8.5004e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 6.7040e-03, -1.4310e-02,  8.7381e-03],\n",
       "            [ 1.4723e-02,  6.9544e-03,  1.3720e-02],\n",
       "            [ 1.1185e-02, -5.0162e-03, -1.0810e-02]],\n",
       "  \n",
       "           [[-1.1434e-02,  4.6326e-03,  1.0164e-02],\n",
       "            [-1.1163e-03,  1.4666e-02,  2.0786e-03],\n",
       "            [ 3.1405e-03, -1.1668e-02,  1.4059e-02]],\n",
       "  \n",
       "           [[-2.8787e-03, -5.1329e-03,  1.0255e-02],\n",
       "            [-1.0258e-02,  5.9074e-03, -8.6984e-03],\n",
       "            [-2.2130e-03, -8.9009e-03,  2.8921e-03]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-5.9418e-03,  1.3902e-03, -1.4416e-02],\n",
       "            [-1.2513e-02, -6.5693e-03,  1.0263e-02],\n",
       "            [ 7.8816e-03, -3.8049e-03, -1.2493e-02]],\n",
       "  \n",
       "           [[-8.2291e-03, -2.6407e-03, -1.5933e-03],\n",
       "            [ 2.6421e-03,  6.2405e-03,  8.1927e-03],\n",
       "            [ 1.4331e-02,  2.8992e-03,  6.4556e-03]],\n",
       "  \n",
       "           [[ 1.4029e-02,  1.2908e-02,  1.0586e-02],\n",
       "            [-2.2395e-04, -1.3211e-02,  6.2064e-03],\n",
       "            [ 2.8166e-04,  6.7485e-03,  4.6268e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 2.4111e-04, -9.8002e-03, -3.3973e-03],\n",
       "            [-1.5859e-03,  6.6665e-03,  1.3326e-02],\n",
       "            [-2.7636e-03, -3.8212e-03, -1.2597e-02]],\n",
       "  \n",
       "           [[ 6.5155e-04,  9.2606e-04,  1.3013e-02],\n",
       "            [ 2.7008e-03, -5.1593e-03, -1.0347e-02],\n",
       "            [ 1.1867e-03,  1.3696e-02, -5.8654e-03]],\n",
       "  \n",
       "           [[-1.1956e-02, -4.5545e-03, -6.5029e-03],\n",
       "            [ 1.7464e-03,  1.3948e-02, -1.4121e-02],\n",
       "            [ 1.0073e-02,  1.1299e-02,  1.2505e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 1.1093e-02,  4.3060e-03,  7.8344e-03],\n",
       "            [ 1.1402e-02, -1.1362e-02, -7.3209e-03],\n",
       "            [ 1.0732e-02, -1.1746e-02, -1.0563e-03]],\n",
       "  \n",
       "           [[ 1.2921e-02,  1.0327e-03,  6.5106e-05],\n",
       "            [-8.9295e-03,  2.1858e-03,  8.6049e-03],\n",
       "            [-1.1364e-02,  5.8801e-03,  1.3497e-02]],\n",
       "  \n",
       "           [[ 2.7395e-03, -9.3675e-03, -1.6545e-03],\n",
       "            [-3.6250e-04, -1.2521e-02, -3.8480e-03],\n",
       "            [ 1.3028e-02,  2.9622e-03,  9.2716e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.0737e-02,  1.4519e-02,  1.1114e-02],\n",
       "            [-1.2244e-02, -1.3446e-02, -4.4388e-03],\n",
       "            [ 6.2300e-03, -7.6289e-03,  1.6097e-03]],\n",
       "  \n",
       "           [[ 1.4126e-02,  8.1070e-03, -5.8483e-03],\n",
       "            [-3.7483e-03,  2.3379e-03, -1.7430e-03],\n",
       "            [-1.3395e-03, -6.7072e-03, -7.8368e-04]],\n",
       "  \n",
       "           [[-9.4515e-03, -1.0355e-03,  7.3503e-03],\n",
       "            [ 4.6232e-03, -5.8765e-03, -1.6726e-03],\n",
       "            [ 1.0008e-03,  9.8537e-04, -1.4626e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 4.5067e-03,  2.8481e-03,  4.8342e-03],\n",
       "            [ 1.9996e-03,  2.2901e-03, -6.1008e-03],\n",
       "            [-2.9838e-03, -2.9549e-04, -8.4612e-03]],\n",
       "  \n",
       "           [[-9.4772e-03,  1.4343e-02,  1.1300e-03],\n",
       "            [ 3.4582e-03,  3.7398e-03,  1.0873e-02],\n",
       "            [ 1.4234e-02, -8.7943e-03,  3.3466e-04]],\n",
       "  \n",
       "           [[-8.1117e-04,  1.2166e-02,  1.0749e-02],\n",
       "            [ 1.1985e-02,  9.2383e-04, -1.0880e-02],\n",
       "            [ 1.2148e-02,  1.1356e-02,  5.7696e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-6.8124e-03, -1.0970e-02,  2.8767e-04],\n",
       "            [-1.7845e-03,  9.7500e-03,  3.5086e-03],\n",
       "            [ 4.6904e-03,  1.1298e-02, -7.5799e-03]],\n",
       "  \n",
       "           [[-2.4801e-03, -1.1529e-02, -2.6055e-03],\n",
       "            [-3.7460e-03, -8.9927e-04, -1.3684e-02],\n",
       "            [ 1.2364e-03,  3.1061e-03,  5.5203e-03]],\n",
       "  \n",
       "           [[ 6.0473e-03,  1.1176e-02, -1.6630e-03],\n",
       "            [-4.4333e-03, -1.3256e-02, -1.0394e-02],\n",
       "            [ 9.6945e-03,  1.1526e-02,  8.2346e-03]]]], requires_grad=True)),\n",
       " ('module_dict.5:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 3.3806e-03,  6.3595e-03, -1.4267e-03, -7.1911e-03,  6.4087e-03,\n",
       "          -1.4030e-02,  1.1882e-02,  8.1080e-03, -4.1379e-03, -5.8854e-03,\n",
       "           1.4304e-03,  1.4375e-02, -1.4269e-02, -1.4706e-02, -4.3255e-03,\n",
       "          -6.5422e-03, -1.1557e-02, -5.5208e-03, -1.2501e-02,  2.7994e-03,\n",
       "          -2.2758e-04, -6.4889e-03,  9.1655e-04,  2.7041e-03,  1.4338e-02,\n",
       "          -1.4313e-02,  4.3566e-03, -1.0713e-02, -3.2617e-03,  1.3323e-02,\n",
       "           1.4083e-02,  7.0026e-04, -5.9310e-03,  1.0641e-02, -4.8233e-04,\n",
       "           7.5004e-03,  6.0999e-03, -2.9892e-03, -1.1712e-02, -1.0864e-02,\n",
       "          -1.3293e-02, -4.1392e-03, -8.3105e-05,  8.0049e-03,  2.2508e-03,\n",
       "          -6.0630e-03,  1.0785e-03, -5.8963e-03, -2.5599e-04, -4.0074e-03,\n",
       "          -3.8278e-03,  1.4378e-02, -1.2281e-02, -3.4203e-03, -4.5641e-03,\n",
       "           1.0791e-02, -5.7783e-03,  1.1696e-02, -2.1355e-03,  6.9183e-03,\n",
       "           1.8639e-03,  1.3681e-02,  1.0828e-02, -5.3066e-03,  1.7065e-03,\n",
       "          -1.0611e-03,  5.1249e-03, -8.3880e-03, -1.4077e-02, -2.0703e-03,\n",
       "          -1.2505e-02,  3.3441e-03, -3.8937e-03, -7.1663e-03,  1.9221e-03,\n",
       "           4.7199e-04,  1.6043e-03, -1.0976e-02, -1.3244e-02,  3.7025e-03,\n",
       "          -5.6802e-03,  4.5857e-03,  1.6200e-03,  9.9995e-03,  1.1666e-03,\n",
       "           1.1053e-03,  7.1228e-03, -8.0481e-04,  1.4025e-02,  1.1304e-02,\n",
       "           2.1685e-03,  4.8790e-03, -1.1334e-02, -8.2315e-03,  3.9182e-03,\n",
       "          -1.3497e-02, -9.5585e-03, -6.4096e-03, -4.7737e-03,  8.3385e-03,\n",
       "          -8.5239e-03,  1.6787e-03,  1.3970e-02, -1.2062e-02, -9.3226e-03,\n",
       "          -8.5130e-03, -3.9848e-04, -2.1823e-04,  8.5254e-05,  5.6780e-03,\n",
       "           1.1682e-02,  3.7988e-03,  1.3209e-02,  1.0413e-02,  3.1769e-03,\n",
       "           1.2862e-02, -4.5888e-03, -8.7584e-03,  1.2065e-02,  3.4156e-03,\n",
       "          -1.2476e-02, -1.0344e-02,  1.1124e-02,  3.7356e-03, -3.2518e-03,\n",
       "           8.5434e-03, -3.9059e-03, -3.5382e-04], requires_grad=True)),\n",
       " ('module_dict.5:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.], requires_grad=True)),\n",
       " ('module_dict.5:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n",
       " ('module_dict.2:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.1840,  0.0874, -0.3036],\n",
       "            [ 0.2363,  0.1010, -0.1064],\n",
       "            [-0.2415, -0.2650,  0.0820]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1724,  0.0823,  0.2658],\n",
       "            [ 0.3072,  0.2726,  0.1145],\n",
       "            [ 0.1828, -0.1909, -0.3030]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0869,  0.3196, -0.1660],\n",
       "            [-0.0920, -0.1208,  0.1377],\n",
       "            [ 0.0101, -0.0875, -0.0806]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2000, -0.0097, -0.3167],\n",
       "            [-0.0269,  0.3141,  0.3283],\n",
       "            [ 0.1166, -0.2520,  0.0995]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0350, -0.2318, -0.2709],\n",
       "            [ 0.2205, -0.2955, -0.2083],\n",
       "            [ 0.2233, -0.2815,  0.0605]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0526,  0.2505, -0.1185],\n",
       "            [-0.1929, -0.1492, -0.0051],\n",
       "            [-0.3015, -0.1655, -0.0656]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0801, -0.1770,  0.1168],\n",
       "            [ 0.3147,  0.2020,  0.1568],\n",
       "            [ 0.0157, -0.0583, -0.0778]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2606,  0.1155, -0.1110],\n",
       "            [ 0.0767,  0.0794,  0.1823],\n",
       "            [ 0.2178, -0.0206, -0.1696]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1806, -0.1004,  0.1549],\n",
       "            [ 0.1799, -0.1198, -0.1153],\n",
       "            [-0.2594,  0.2403, -0.0208]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1863,  0.1672, -0.1428],\n",
       "            [-0.1483, -0.0128, -0.2305],\n",
       "            [-0.0528, -0.2268, -0.2307]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1198,  0.3229, -0.1415],\n",
       "            [-0.0487,  0.0907,  0.0462],\n",
       "            [ 0.1521, -0.2247,  0.1137]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1349,  0.1380,  0.0149],\n",
       "            [ 0.1207, -0.1011, -0.0098],\n",
       "            [-0.1372, -0.2252, -0.0164]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0451, -0.1105,  0.2900],\n",
       "            [ 0.3095,  0.2467,  0.2498],\n",
       "            [-0.2298,  0.1618,  0.0854]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0116, -0.2329,  0.2647],\n",
       "            [-0.1799, -0.1271,  0.0424],\n",
       "            [-0.2688,  0.0937, -0.2650]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1959,  0.0692,  0.2226],\n",
       "            [-0.1304,  0.0633, -0.3128],\n",
       "            [-0.0709, -0.2901,  0.3119]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0675,  0.1883,  0.2530],\n",
       "            [ 0.1754,  0.1487,  0.1068],\n",
       "            [-0.2246,  0.2185,  0.3330]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2409,  0.2081,  0.0989],\n",
       "            [ 0.0040, -0.0165,  0.2694],\n",
       "            [-0.0597, -0.3084, -0.1063]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1264, -0.2678,  0.2411],\n",
       "            [ 0.2186, -0.1653, -0.1035],\n",
       "            [-0.2723,  0.1803, -0.0776]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1389,  0.1160,  0.2411],\n",
       "            [-0.2495,  0.0722, -0.1770],\n",
       "            [ 0.1056,  0.2511, -0.1089]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2192,  0.0220,  0.1408],\n",
       "            [-0.2593,  0.1628,  0.1068],\n",
       "            [-0.3037,  0.1291,  0.2468]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0748,  0.3040, -0.0248],\n",
       "            [-0.1889,  0.1364,  0.2625],\n",
       "            [-0.2669,  0.1702, -0.3306]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0266,  0.2909,  0.1152],\n",
       "            [-0.2120,  0.2034,  0.0015],\n",
       "            [-0.1754, -0.1905,  0.1761]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1254, -0.1434, -0.2995],\n",
       "            [-0.1846,  0.1347, -0.1741],\n",
       "            [-0.0117,  0.0522, -0.0940]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0815,  0.2824,  0.3110],\n",
       "            [ 0.0349,  0.2997, -0.3194],\n",
       "            [ 0.0826,  0.0850, -0.2226]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0805,  0.1313, -0.2596],\n",
       "            [ 0.1158, -0.2255,  0.3238],\n",
       "            [ 0.1661,  0.1929,  0.1580]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1760,  0.2445, -0.0380],\n",
       "            [ 0.3227,  0.0993, -0.0933],\n",
       "            [ 0.2163,  0.2168,  0.2497]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0087,  0.2228, -0.3232],\n",
       "            [-0.2201,  0.1755, -0.1143],\n",
       "            [-0.1379, -0.1050, -0.2602]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2954, -0.2139,  0.1526],\n",
       "            [ 0.1126, -0.0793, -0.0264],\n",
       "            [ 0.3209, -0.2286,  0.1225]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0337, -0.1356, -0.0727],\n",
       "            [-0.0950,  0.0501,  0.0455],\n",
       "            [-0.0275, -0.1449, -0.2195]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2022, -0.0564,  0.2061],\n",
       "            [ 0.2964,  0.0524, -0.2427],\n",
       "            [-0.2113, -0.3117, -0.3317]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0339,  0.1586,  0.3253],\n",
       "            [ 0.0325,  0.2067, -0.1443],\n",
       "            [-0.2124,  0.0140, -0.0350]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3120, -0.0138, -0.3245],\n",
       "            [-0.2889,  0.1090,  0.0822],\n",
       "            [ 0.1274, -0.1803, -0.2661]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2751,  0.1758, -0.1966],\n",
       "            [ 0.0863,  0.0193, -0.0208],\n",
       "            [ 0.1996, -0.1062,  0.0092]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2025,  0.0710,  0.2417],\n",
       "            [-0.3200,  0.2363, -0.2206],\n",
       "            [ 0.3332,  0.1638, -0.1757]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0796, -0.1556, -0.3082],\n",
       "            [ 0.1322, -0.2919, -0.0285],\n",
       "            [ 0.1053,  0.1332, -0.1125]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2226,  0.2174,  0.2759],\n",
       "            [ 0.0213, -0.1916,  0.1886],\n",
       "            [ 0.1990, -0.0524, -0.2598]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2318,  0.0405,  0.1151],\n",
       "            [-0.2853,  0.2186,  0.1683],\n",
       "            [ 0.2209,  0.0748, -0.2744]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1654,  0.0158, -0.3192],\n",
       "            [ 0.3005, -0.0330, -0.2931],\n",
       "            [ 0.0544,  0.1810,  0.0008]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0465, -0.0623, -0.2606],\n",
       "            [-0.0505, -0.2702, -0.1971],\n",
       "            [ 0.1807, -0.1089, -0.1302]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1946, -0.2402,  0.0611],\n",
       "            [ 0.2614,  0.0492, -0.2501],\n",
       "            [ 0.2541, -0.2007, -0.2714]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1306,  0.0840, -0.2196],\n",
       "            [-0.0833, -0.1576,  0.1048],\n",
       "            [-0.1389, -0.2857, -0.2141]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1846,  0.0110,  0.0063],\n",
       "            [ 0.1636,  0.1066,  0.0116],\n",
       "            [ 0.2417, -0.1375,  0.1749]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3130, -0.2756, -0.2185],\n",
       "            [ 0.2965, -0.0492, -0.2935],\n",
       "            [ 0.0251, -0.2197,  0.0330]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1088,  0.1125, -0.0042],\n",
       "            [ 0.1470,  0.2915,  0.0645],\n",
       "            [ 0.3298,  0.0956, -0.1298]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1250, -0.0810,  0.1406],\n",
       "            [ 0.2475, -0.3002, -0.3326],\n",
       "            [-0.0413,  0.3255, -0.1927]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2639,  0.1540,  0.2256],\n",
       "            [ 0.2851, -0.1368,  0.2167],\n",
       "            [ 0.2052,  0.2081,  0.1978]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0808, -0.0733,  0.3196],\n",
       "            [ 0.1028,  0.0569, -0.0044],\n",
       "            [-0.2480,  0.0769,  0.2134]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0823, -0.2702,  0.1722],\n",
       "            [-0.2900,  0.2036, -0.3101],\n",
       "            [-0.2739,  0.1032,  0.1626]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0401,  0.0064,  0.2999],\n",
       "            [ 0.0318,  0.2884,  0.2629],\n",
       "            [ 0.0948, -0.1288,  0.0546]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2283,  0.1764, -0.1641],\n",
       "            [ 0.3059, -0.3052,  0.2705],\n",
       "            [ 0.0101,  0.2580,  0.1414]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1385,  0.0777,  0.3171],\n",
       "            [ 0.0917, -0.1418,  0.0415],\n",
       "            [ 0.0909,  0.1101,  0.0432]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3293,  0.0199,  0.2293],\n",
       "            [-0.1896,  0.2324, -0.0544],\n",
       "            [-0.2798, -0.1650, -0.0159]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1275,  0.2202,  0.1009],\n",
       "            [-0.1032,  0.0267,  0.1935],\n",
       "            [ 0.0627, -0.2574,  0.0467]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2486,  0.0721,  0.2789],\n",
       "            [-0.2864,  0.1896,  0.0558],\n",
       "            [ 0.2755,  0.0446,  0.1040]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2928,  0.2347,  0.2216],\n",
       "            [-0.1278,  0.1033, -0.3200],\n",
       "            [-0.0863, -0.2426,  0.2088]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1412,  0.1793,  0.0078],\n",
       "            [-0.2340, -0.2601, -0.0158],\n",
       "            [-0.1418,  0.1021,  0.0428]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1628, -0.2044, -0.0169],\n",
       "            [-0.2748,  0.0831,  0.1145],\n",
       "            [-0.3037, -0.1082,  0.2054]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2307,  0.1404, -0.2787],\n",
       "            [ 0.0785, -0.2828, -0.0636],\n",
       "            [ 0.1925,  0.3232, -0.1482]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1699, -0.2554, -0.1615],\n",
       "            [ 0.2862,  0.2470, -0.1256],\n",
       "            [-0.2857,  0.1067, -0.1115]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2313,  0.1388, -0.1224],\n",
       "            [-0.2877,  0.3046, -0.2290],\n",
       "            [ 0.3150, -0.1087, -0.2961]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1058,  0.0219,  0.2916],\n",
       "            [ 0.0825,  0.2661, -0.3087],\n",
       "            [ 0.2432,  0.1401, -0.1295]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2229, -0.2133,  0.3087],\n",
       "            [ 0.1075, -0.1148,  0.2850],\n",
       "            [ 0.0221,  0.0440, -0.0064]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0170, -0.1951, -0.2526],\n",
       "            [ 0.2716, -0.3118,  0.1338],\n",
       "            [ 0.0733, -0.0847, -0.0296]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2996, -0.1561,  0.1773],\n",
       "            [-0.0663,  0.1100,  0.2629],\n",
       "            [-0.2882,  0.0956, -0.1816]]]], requires_grad=True)),\n",
       " ('module_dict.2:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1464,  0.0666, -0.1309,  0.0492, -0.2300,  0.1557,  0.0725, -0.3024,\n",
       "          -0.2656, -0.2769, -0.0018, -0.2261,  0.2943,  0.2971, -0.0493,  0.2452,\n",
       "           0.1222,  0.1459, -0.0837,  0.1986,  0.1990,  0.1957,  0.1549,  0.0131,\n",
       "          -0.1704, -0.3182,  0.1461, -0.2485,  0.2433, -0.2879, -0.1435, -0.2125,\n",
       "           0.1196,  0.0286, -0.3021, -0.3110, -0.0291,  0.2785, -0.1187, -0.0023,\n",
       "          -0.0040,  0.0840, -0.0988, -0.3060, -0.2113, -0.0815,  0.1380,  0.2071,\n",
       "          -0.1109,  0.0220,  0.3258,  0.1055,  0.0630,  0.1810, -0.1007, -0.2348,\n",
       "          -0.1736, -0.2903,  0.3064, -0.1441,  0.0756,  0.1318, -0.1852, -0.0587],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.2:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n",
       " ('module_dict.2:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.1:Conv_Node.model.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-5.7396e-03,  5.4518e-03, -4.3635e-03,  ...,  5.8052e-04,\n",
       "             -3.9633e-03,  6.0471e-03],\n",
       "            [ 1.4941e-03,  2.6348e-03,  4.6209e-03,  ..., -3.6590e-03,\n",
       "              2.4278e-03, -5.2438e-03],\n",
       "            [-6.7377e-03, -6.3781e-03, -4.6647e-04,  ...,  4.7718e-03,\n",
       "              4.8691e-03,  5.3106e-03],\n",
       "            ...,\n",
       "            [-1.4805e-03,  4.4255e-03,  6.0374e-03,  ...,  6.8001e-03,\n",
       "              2.5791e-03, -5.1274e-03],\n",
       "            [ 7.6154e-04, -4.6761e-03,  7.0741e-03,  ..., -4.2968e-03,\n",
       "             -5.3762e-03, -4.3601e-03],\n",
       "            [-1.9260e-03, -3.8259e-03,  5.9416e-03,  ...,  9.5434e-04,\n",
       "              4.4726e-03, -5.7272e-03]],\n",
       "  \n",
       "           [[-3.6001e-03, -5.9985e-03, -2.1337e-03,  ...,  9.2296e-05,\n",
       "              1.8774e-03,  1.0923e-04],\n",
       "            [ 2.0757e-03, -5.2044e-03, -2.5479e-03,  ...,  2.2431e-03,\n",
       "              1.7886e-03, -3.4110e-03],\n",
       "            [ 1.6599e-03,  1.6500e-03,  1.6849e-03,  ..., -3.6671e-03,\n",
       "              3.7097e-03,  6.1826e-03],\n",
       "            ...,\n",
       "            [ 6.9269e-04, -7.1014e-03,  1.0875e-03,  ..., -7.0162e-03,\n",
       "             -6.3118e-04, -8.4209e-04],\n",
       "            [ 2.4965e-03, -3.3355e-03, -5.8854e-03,  ..., -3.1249e-03,\n",
       "              1.7070e-03,  3.0128e-03],\n",
       "            [-6.7492e-03,  1.1794e-03, -4.1554e-03,  ...,  1.1374e-03,\n",
       "              5.0318e-03, -3.8744e-03]],\n",
       "  \n",
       "           [[ 5.1990e-03, -3.3923e-03,  2.2544e-03,  ..., -4.0008e-03,\n",
       "             -6.1335e-03, -1.7449e-03],\n",
       "            [ 2.1605e-03,  2.0773e-03,  4.0030e-03,  ..., -5.9644e-03,\n",
       "              4.5677e-03,  8.4972e-04],\n",
       "            [-2.6292e-03,  3.1423e-03, -4.0707e-03,  ...,  2.4186e-06,\n",
       "             -5.9310e-03, -7.0179e-03],\n",
       "            ...,\n",
       "            [ 1.6746e-04,  3.3386e-03, -5.5281e-03,  ..., -7.1077e-03,\n",
       "             -2.7153e-03,  8.1725e-04],\n",
       "            [ 6.0169e-03,  1.8342e-03, -8.8236e-04,  ..., -1.7526e-03,\n",
       "             -2.0169e-03, -8.8387e-04],\n",
       "            [ 4.2178e-03, -2.5955e-03,  5.3332e-03,  ...,  6.0135e-03,\n",
       "              1.9227e-03, -4.8883e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-1.3446e-03, -2.6848e-03, -3.5559e-03,  ...,  1.4703e-03,\n",
       "             -4.2066e-03,  8.2527e-04],\n",
       "            [ 6.5548e-03, -1.9509e-03,  3.5559e-03,  ...,  7.5216e-05,\n",
       "              8.5081e-06,  1.2766e-03],\n",
       "            [-3.7863e-03, -7.4256e-04,  7.9327e-04,  ..., -2.9637e-03,\n",
       "              4.8360e-03,  4.0987e-03],\n",
       "            ...,\n",
       "            [ 5.3964e-03, -7.8745e-04, -2.6754e-03,  ...,  1.1139e-03,\n",
       "              1.9761e-03,  3.8307e-03],\n",
       "            [ 6.0916e-03, -1.1307e-03, -3.4477e-03,  ...,  1.2721e-03,\n",
       "              3.8983e-04,  1.0055e-04],\n",
       "            [-4.0376e-03, -1.2464e-03, -4.2794e-03,  ..., -1.2056e-03,\n",
       "              3.0391e-03, -3.8006e-04]],\n",
       "  \n",
       "           [[-1.5007e-03,  1.8969e-03, -7.0747e-03,  ..., -2.1641e-03,\n",
       "             -5.7751e-03,  9.5298e-04],\n",
       "            [ 1.4940e-03,  5.6834e-03,  9.0929e-04,  ...,  5.9564e-03,\n",
       "              5.3126e-03, -1.5803e-03],\n",
       "            [ 1.0267e-03,  5.2881e-03, -2.9835e-03,  ..., -4.5006e-03,\n",
       "             -4.8503e-03,  4.0149e-03],\n",
       "            ...,\n",
       "            [ 3.4063e-03, -2.4182e-03, -3.3479e-03,  ...,  1.2172e-03,\n",
       "             -4.1884e-03,  5.9664e-03],\n",
       "            [ 5.0811e-03, -1.8952e-03,  2.4460e-03,  ...,  5.3878e-03,\n",
       "             -5.3843e-03, -3.2810e-03],\n",
       "            [-7.2408e-03,  9.0930e-04,  7.2073e-03,  ...,  2.3815e-03,\n",
       "             -3.2211e-03,  1.5400e-03]],\n",
       "  \n",
       "           [[-3.6508e-03, -4.5724e-03,  6.7184e-03,  ...,  9.7311e-04,\n",
       "              1.5345e-03,  2.6007e-03],\n",
       "            [ 6.1502e-03, -4.0883e-03, -3.4811e-03,  ...,  1.8881e-04,\n",
       "              2.7174e-04,  1.8056e-03],\n",
       "            [ 8.3476e-04,  5.8769e-03,  3.0668e-03,  ...,  7.4519e-04,\n",
       "              5.1766e-03,  7.1351e-03],\n",
       "            ...,\n",
       "            [-2.0729e-03, -7.6007e-04, -5.7506e-03,  ...,  2.7582e-03,\n",
       "             -5.4231e-05, -2.7887e-03],\n",
       "            [ 3.9978e-03,  3.5144e-03,  4.5591e-03,  ..., -1.6548e-03,\n",
       "             -3.9751e-03, -2.8438e-03],\n",
       "            [-4.0936e-03,  2.9282e-03,  3.4032e-03,  ..., -1.4921e-04,\n",
       "              6.4777e-03, -1.9486e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-4.5654e-03, -4.4417e-03,  3.9585e-03,  ..., -5.7440e-03,\n",
       "              5.2144e-04,  4.1815e-03],\n",
       "            [ 5.4742e-03,  7.1565e-03, -1.8434e-03,  ..., -6.9332e-03,\n",
       "             -9.6105e-04, -6.5641e-03],\n",
       "            [-2.6574e-03, -4.8377e-03,  6.5596e-03,  ...,  4.6233e-03,\n",
       "             -6.3100e-03, -5.5219e-03],\n",
       "            ...,\n",
       "            [-3.7524e-03, -5.4503e-03,  2.5702e-03,  ..., -7.1412e-03,\n",
       "              4.3835e-03, -6.8631e-03],\n",
       "            [ 7.0112e-03, -2.0201e-03, -5.0200e-03,  ...,  2.0177e-03,\n",
       "             -1.1897e-03,  5.4519e-03],\n",
       "            [ 4.7283e-03,  5.8276e-03, -6.8508e-03,  ...,  5.3663e-04,\n",
       "              4.3336e-03, -2.7989e-03]],\n",
       "  \n",
       "           [[-3.7054e-03, -1.8021e-03,  2.5497e-04,  ..., -4.4871e-03,\n",
       "             -4.2203e-03,  5.9359e-03],\n",
       "            [-2.1030e-03,  2.7007e-03, -2.9669e-03,  ..., -1.3753e-05,\n",
       "             -5.0180e-03,  4.4341e-03],\n",
       "            [ 6.8963e-03,  2.8364e-03, -8.8089e-04,  ..., -2.5704e-03,\n",
       "              5.3021e-03, -3.5926e-03],\n",
       "            ...,\n",
       "            [-1.0317e-04,  1.6658e-03, -3.3962e-03,  ..., -2.4405e-03,\n",
       "              4.5983e-03,  5.2615e-03],\n",
       "            [ 5.1026e-03, -5.7196e-03, -1.5294e-03,  ...,  6.0903e-03,\n",
       "             -3.5550e-03,  1.5446e-03],\n",
       "            [ 4.5348e-03,  1.9207e-03, -2.8769e-03,  ...,  2.7353e-03,\n",
       "             -3.4235e-04,  1.9236e-03]],\n",
       "  \n",
       "           [[ 3.0243e-04,  6.2531e-03, -6.7301e-03,  ..., -2.8855e-03,\n",
       "             -5.9754e-03, -6.2542e-03],\n",
       "            [-4.5537e-03,  6.9955e-03,  6.7724e-03,  ..., -3.5820e-03,\n",
       "             -5.0101e-03, -1.1918e-03],\n",
       "            [-6.6770e-03, -2.3182e-03,  8.2441e-04,  ..., -3.1143e-03,\n",
       "              3.4035e-03, -1.1943e-03],\n",
       "            ...,\n",
       "            [ 3.8412e-03,  5.2771e-04, -5.3257e-03,  ..., -1.5647e-03,\n",
       "              2.0678e-03,  6.6866e-03],\n",
       "            [-2.6840e-03,  6.2342e-03, -4.3102e-03,  ...,  6.2501e-03,\n",
       "              6.2029e-03,  5.2713e-03],\n",
       "            [-4.8129e-03, -6.2797e-03, -4.1703e-03,  ...,  3.4705e-03,\n",
       "             -9.7366e-04,  1.0858e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.0818e-03,  3.6856e-03, -3.6851e-03,  ..., -3.1711e-03,\n",
       "              4.0437e-03,  2.3942e-03],\n",
       "            [-7.0495e-03, -6.7381e-04,  3.2264e-04,  ...,  1.6392e-03,\n",
       "              5.9895e-03, -2.4377e-03],\n",
       "            [-1.8715e-03,  6.7986e-03,  7.8188e-04,  ..., -3.9950e-03,\n",
       "              2.0323e-03,  1.5984e-03],\n",
       "            ...,\n",
       "            [-5.6883e-03, -5.9961e-03, -5.0121e-04,  ..., -4.0078e-03,\n",
       "              7.0309e-03,  6.5297e-03],\n",
       "            [-3.7538e-03, -4.6074e-03,  2.5961e-03,  ..., -5.2428e-03,\n",
       "             -1.9203e-03,  5.5314e-03],\n",
       "            [ 1.6818e-03,  1.6049e-04,  1.6315e-04,  ...,  6.1341e-03,\n",
       "              2.5132e-03,  4.8316e-03]],\n",
       "  \n",
       "           [[-2.0192e-03, -1.5198e-03, -3.2104e-03,  ..., -3.4015e-03,\n",
       "             -4.1171e-03, -4.6029e-03],\n",
       "            [ 9.1236e-04, -4.9852e-03,  1.7188e-03,  ...,  4.3113e-03,\n",
       "              4.2551e-03,  4.1417e-03],\n",
       "            [ 1.4643e-03, -5.8631e-03, -3.8138e-03,  ..., -1.9518e-03,\n",
       "              4.9387e-03,  2.8348e-03],\n",
       "            ...,\n",
       "            [-6.1691e-03, -5.0890e-03,  3.1595e-03,  ...,  4.5166e-03,\n",
       "             -3.2772e-03,  2.6179e-03],\n",
       "            [ 3.0707e-03,  6.7248e-03,  2.2192e-03,  ..., -3.8382e-03,\n",
       "             -4.3138e-03,  6.3741e-03],\n",
       "            [-6.5643e-03, -3.9992e-03, -1.8516e-03,  ..., -5.6542e-03,\n",
       "              2.9492e-03, -1.3428e-03]],\n",
       "  \n",
       "           [[-2.0092e-03,  6.2056e-03, -7.7576e-04,  ...,  1.7787e-03,\n",
       "             -4.6253e-03,  6.8704e-03],\n",
       "            [-1.7997e-04, -1.9234e-03, -1.7979e-03,  ..., -5.6499e-03,\n",
       "             -5.2105e-03, -2.8766e-03],\n",
       "            [ 3.1630e-03,  5.9619e-04, -2.7114e-03,  ..., -1.9713e-03,\n",
       "              1.5251e-03, -5.7814e-03],\n",
       "            ...,\n",
       "            [ 1.8031e-03,  3.5691e-03,  7.1322e-03,  ...,  3.2094e-03,\n",
       "              3.5784e-03,  4.1803e-03],\n",
       "            [-3.7048e-03,  4.6229e-03, -1.2530e-03,  ..., -2.2375e-03,\n",
       "             -5.9946e-03, -4.3032e-03],\n",
       "            [-5.1287e-03,  4.7834e-03, -3.7258e-03,  ...,  6.0445e-03,\n",
       "             -5.4100e-03,  7.0217e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-5.7284e-03,  3.0132e-03,  5.1389e-03,  ...,  2.9918e-03,\n",
       "              4.1580e-04,  1.4126e-03],\n",
       "            [ 3.1015e-03, -6.6781e-03, -2.9110e-03,  ...,  1.3668e-03,\n",
       "             -4.8940e-04, -1.8233e-03],\n",
       "            [-5.2713e-03,  3.2804e-03, -9.3004e-04,  ...,  1.0317e-03,\n",
       "              2.7390e-03, -3.0305e-03],\n",
       "            ...,\n",
       "            [-4.1521e-03, -2.0972e-03,  5.8613e-03,  ...,  1.8524e-04,\n",
       "              2.7353e-03,  4.5003e-03],\n",
       "            [ 2.6180e-03,  1.9260e-03, -6.9399e-03,  ...,  5.5565e-03,\n",
       "             -3.9617e-03, -7.1142e-03],\n",
       "            [ 2.7547e-03,  3.7685e-03,  2.6924e-03,  ..., -6.5153e-03,\n",
       "             -4.4675e-03,  5.5888e-03]],\n",
       "  \n",
       "           [[-3.3045e-03, -5.9072e-03,  3.9135e-04,  ...,  7.8451e-04,\n",
       "             -5.0784e-04,  4.4301e-03],\n",
       "            [ 6.9520e-04,  6.2754e-03, -7.1780e-03,  ...,  4.3770e-03,\n",
       "              4.7904e-03,  1.5637e-03],\n",
       "            [-6.8199e-03,  4.3816e-03,  3.2030e-03,  ...,  7.2839e-03,\n",
       "              5.3643e-03,  2.1143e-03],\n",
       "            ...,\n",
       "            [-6.7487e-03,  1.3759e-03,  2.3590e-03,  ..., -5.7889e-03,\n",
       "              2.1926e-03,  1.6632e-03],\n",
       "            [ 1.1830e-03, -6.2730e-03, -3.6791e-03,  ..., -6.7972e-03,\n",
       "             -6.3110e-04,  6.6836e-03],\n",
       "            [-4.5857e-03, -6.0957e-03,  2.7840e-03,  ...,  3.6542e-04,\n",
       "             -5.1135e-03,  4.7710e-03]],\n",
       "  \n",
       "           [[ 1.4963e-03,  7.1467e-03, -2.2112e-03,  ...,  2.7000e-04,\n",
       "             -3.2370e-03, -1.1414e-03],\n",
       "            [-3.3964e-03, -6.6040e-03,  1.9389e-03,  ...,  2.3603e-03,\n",
       "              3.2016e-03,  6.9779e-03],\n",
       "            [ 8.4508e-04, -6.5283e-03,  5.5592e-03,  ..., -5.8018e-03,\n",
       "             -2.3509e-03,  8.4178e-04],\n",
       "            ...,\n",
       "            [-6.8634e-04,  5.2021e-03,  1.7736e-03,  ...,  9.4922e-04,\n",
       "              2.0184e-03, -7.2806e-03],\n",
       "            [-9.8970e-04, -2.5607e-03, -3.5440e-03,  ..., -9.3183e-05,\n",
       "              3.5034e-03, -5.6608e-04],\n",
       "            [ 6.5755e-03, -4.8789e-03, -6.9032e-03,  ...,  2.5923e-03,\n",
       "             -4.1271e-05,  7.2031e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.9466e-03,  7.0253e-03, -4.9350e-03,  ..., -6.4346e-04,\n",
       "              6.7982e-03, -6.0485e-03],\n",
       "            [ 2.1613e-03, -5.4006e-05,  4.5460e-03,  ..., -5.8127e-03,\n",
       "              6.2457e-03,  7.0446e-03],\n",
       "            [-2.1984e-03, -3.4782e-03, -6.7067e-03,  ..., -6.6173e-03,\n",
       "              5.5349e-05, -2.3319e-03],\n",
       "            ...,\n",
       "            [-5.5579e-03,  4.6648e-03,  4.2262e-03,  ..., -4.7505e-03,\n",
       "             -4.9355e-03, -4.9378e-03],\n",
       "            [ 3.8124e-03,  3.5039e-03,  5.0905e-03,  ..., -2.3359e-03,\n",
       "             -6.6020e-03, -1.0358e-03],\n",
       "            [-5.6922e-03,  6.8432e-03,  6.2539e-03,  ...,  6.9955e-03,\n",
       "              4.3514e-03,  5.6131e-03]],\n",
       "  \n",
       "           [[-6.5611e-03,  3.2944e-03,  3.7918e-03,  ...,  9.4961e-04,\n",
       "             -7.2422e-03,  1.3038e-03],\n",
       "            [-2.9869e-03,  1.8237e-03, -3.0844e-03,  ..., -5.4107e-03,\n",
       "              6.1414e-03, -8.0286e-04],\n",
       "            [-2.1876e-03, -4.2587e-03,  1.9765e-04,  ..., -4.2510e-03,\n",
       "             -1.0323e-03, -4.6296e-03],\n",
       "            ...,\n",
       "            [-3.2800e-03,  3.7238e-03,  4.6763e-03,  ...,  6.5558e-03,\n",
       "             -5.8634e-03,  2.6154e-03],\n",
       "            [-2.7397e-03, -2.9279e-03,  5.8296e-03,  ...,  7.2448e-03,\n",
       "             -4.8818e-03,  2.6537e-03],\n",
       "            [-5.8951e-03, -1.6857e-03,  2.3320e-03,  ...,  2.2802e-03,\n",
       "              1.1959e-03, -2.3312e-04]],\n",
       "  \n",
       "           [[-7.2656e-03, -5.3941e-03,  3.4806e-03,  ...,  1.4296e-03,\n",
       "              2.0836e-03, -4.2970e-03],\n",
       "            [ 3.8506e-04, -3.5037e-03, -4.3291e-03,  ...,  3.8851e-03,\n",
       "              3.9767e-03,  3.3316e-03],\n",
       "            [-5.8670e-04,  1.6980e-03,  6.5760e-03,  ...,  4.4430e-03,\n",
       "             -2.3535e-03,  6.9274e-04],\n",
       "            ...,\n",
       "            [ 3.4552e-03, -4.5349e-03,  5.7015e-03,  ...,  5.3890e-03,\n",
       "              5.9980e-03, -4.6328e-03],\n",
       "            [ 3.8210e-03,  5.8430e-04,  1.0233e-03,  ..., -7.0339e-04,\n",
       "              5.7717e-03,  4.7229e-03],\n",
       "            [ 4.9598e-03, -4.1154e-03,  5.3640e-04,  ...,  1.8194e-03,\n",
       "              1.3392e-04,  1.6245e-03]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-2.3451e-03, -2.6311e-03, -6.2287e-03,  ..., -4.5315e-03,\n",
       "              4.6286e-03,  1.3194e-03],\n",
       "            [ 3.5107e-04,  5.5491e-03,  6.1091e-04,  ..., -5.1325e-03,\n",
       "             -3.2257e-03,  3.2984e-03],\n",
       "            [ 1.0874e-03,  2.9196e-03,  7.0716e-03,  ...,  4.6811e-03,\n",
       "              7.0490e-03,  2.2965e-03],\n",
       "            ...,\n",
       "            [-2.7082e-03,  1.4951e-04,  4.7634e-03,  ...,  7.1677e-04,\n",
       "              6.4660e-03, -1.7458e-03],\n",
       "            [-3.7372e-04,  7.1853e-03, -2.4221e-03,  ..., -7.6381e-04,\n",
       "             -6.2634e-03,  3.0868e-03],\n",
       "            [-4.3151e-03,  5.9991e-03,  4.6723e-03,  ..., -5.7896e-03,\n",
       "              3.4853e-03, -1.2832e-03]],\n",
       "  \n",
       "           [[ 6.1786e-03, -6.2341e-03,  3.7825e-03,  ...,  5.4178e-03,\n",
       "             -1.9876e-03,  5.4821e-03],\n",
       "            [-6.9129e-03,  1.1241e-03,  2.3708e-03,  ..., -5.0940e-03,\n",
       "             -2.0510e-03,  5.0176e-03],\n",
       "            [ 5.7774e-03, -3.4008e-03,  1.0660e-03,  ..., -1.7382e-03,\n",
       "             -2.4798e-03,  5.2883e-03],\n",
       "            ...,\n",
       "            [ 7.1343e-03,  1.8907e-04, -6.6350e-04,  ...,  6.9898e-04,\n",
       "             -1.2008e-03,  7.1160e-03],\n",
       "            [-3.9048e-03, -6.3870e-03,  3.5309e-03,  ...,  5.1110e-03,\n",
       "              5.7939e-03, -1.5718e-03],\n",
       "            [-5.0648e-03, -3.8948e-03, -7.0764e-03,  ..., -6.9608e-03,\n",
       "              3.2132e-03,  4.5796e-03]],\n",
       "  \n",
       "           [[-5.3550e-03, -2.8585e-03,  1.1543e-03,  ..., -2.2538e-03,\n",
       "              8.6944e-04,  4.1615e-03],\n",
       "            [-5.1870e-03, -1.8767e-03, -5.9943e-03,  ...,  5.9840e-03,\n",
       "              6.2621e-03, -3.0485e-03],\n",
       "            [ 4.6799e-03, -1.4244e-03,  6.3689e-03,  ..., -3.7812e-03,\n",
       "              3.0009e-03,  5.5116e-03],\n",
       "            ...,\n",
       "            [-1.6294e-05,  4.3898e-03, -3.3005e-03,  ..., -2.6705e-05,\n",
       "              1.0986e-03,  7.1153e-03],\n",
       "            [ 5.9057e-03, -4.5317e-03, -3.6127e-03,  ...,  1.1394e-04,\n",
       "             -6.6051e-03, -6.5154e-03],\n",
       "            [-6.5406e-03,  2.8252e-03,  7.1574e-03,  ...,  1.5133e-03,\n",
       "             -2.9111e-03,  2.9047e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-3.2143e-03, -3.9832e-03, -6.7455e-03,  ...,  4.5305e-03,\n",
       "             -6.3256e-03, -2.0181e-03],\n",
       "            [ 6.9501e-03, -2.1405e-04,  5.4466e-03,  ..., -6.5931e-03,\n",
       "             -7.1036e-03, -6.1623e-03],\n",
       "            [-1.5827e-03, -3.6895e-05,  7.1629e-03,  ...,  4.8608e-03,\n",
       "             -4.9410e-05, -2.3599e-03],\n",
       "            ...,\n",
       "            [ 6.1649e-03,  2.5445e-03,  2.5825e-03,  ...,  6.5605e-03,\n",
       "              6.6361e-03,  5.2584e-03],\n",
       "            [ 6.3322e-03,  4.7401e-03, -7.1629e-03,  ...,  3.7044e-03,\n",
       "              2.0150e-03, -6.4017e-03],\n",
       "            [-5.7690e-03, -6.4427e-03, -2.9079e-03,  ...,  6.0385e-03,\n",
       "              1.1057e-03,  6.4109e-03]],\n",
       "  \n",
       "           [[ 9.6184e-04, -2.9342e-03,  3.4816e-03,  ..., -1.9932e-03,\n",
       "             -4.9104e-03,  2.4611e-03],\n",
       "            [-3.0825e-03,  5.6283e-04, -1.6571e-03,  ..., -7.0970e-03,\n",
       "              4.9178e-03,  2.5316e-04],\n",
       "            [ 5.7926e-03,  6.7167e-03,  6.0073e-03,  ...,  1.2030e-03,\n",
       "             -3.0971e-03, -2.6171e-03],\n",
       "            ...,\n",
       "            [ 3.9015e-03,  5.2360e-03,  7.9374e-04,  ...,  3.2195e-03,\n",
       "              2.9943e-03, -6.6695e-03],\n",
       "            [ 1.8953e-03,  2.3015e-03, -6.3563e-03,  ...,  1.9774e-03,\n",
       "              1.1499e-03, -3.2382e-03],\n",
       "            [ 1.4425e-04,  2.4535e-03,  4.9562e-04,  ..., -6.2994e-03,\n",
       "              6.3415e-03, -4.0774e-03]],\n",
       "  \n",
       "           [[ 3.3262e-03, -4.0820e-03, -5.4565e-03,  ..., -4.1058e-03,\n",
       "             -3.8985e-03,  7.0275e-03],\n",
       "            [ 6.8390e-03,  3.4088e-03, -6.8813e-03,  ..., -5.7111e-03,\n",
       "             -4.3414e-03,  5.4482e-03],\n",
       "            [-4.5927e-03,  4.7596e-03,  2.9507e-03,  ..., -6.2685e-03,\n",
       "              5.9223e-03, -2.0807e-03],\n",
       "            ...,\n",
       "            [-2.2496e-03,  4.0665e-03,  3.7219e-03,  ...,  6.9610e-03,\n",
       "              2.5013e-03, -2.4040e-03],\n",
       "            [ 1.9685e-03, -4.2123e-03, -7.2307e-03,  ...,  1.2692e-04,\n",
       "             -3.0847e-03,  2.3457e-03],\n",
       "            [-3.6896e-03, -1.4444e-04,  4.8964e-03,  ...,  8.4606e-05,\n",
       "              6.6166e-03, -6.0683e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[ 6.8557e-03,  6.0982e-03, -1.6922e-03,  ...,  6.4218e-03,\n",
       "              6.9486e-03, -6.2528e-03],\n",
       "            [ 1.8731e-03,  2.4286e-04, -1.6966e-03,  ...,  2.4906e-03,\n",
       "              5.2160e-03,  6.0651e-03],\n",
       "            [ 1.8756e-03, -1.2891e-03,  5.2483e-03,  ...,  2.7236e-04,\n",
       "              6.6952e-03,  6.2141e-03],\n",
       "            ...,\n",
       "            [ 1.4732e-03,  4.0688e-03, -4.2821e-03,  ...,  2.9125e-04,\n",
       "             -4.7282e-04, -3.5701e-03],\n",
       "            [-2.1911e-03,  4.8505e-03, -4.5703e-03,  ..., -4.4026e-04,\n",
       "              6.4524e-03,  1.0213e-03],\n",
       "            [ 4.1482e-04, -6.0796e-03, -3.3033e-03,  ..., -3.2914e-03,\n",
       "             -1.6210e-03, -3.0830e-03]],\n",
       "  \n",
       "           [[ 6.9018e-03,  6.8002e-03, -2.1148e-03,  ..., -6.4596e-04,\n",
       "              2.7205e-03, -1.3258e-03],\n",
       "            [ 6.9049e-03, -1.5233e-03, -1.5470e-03,  ...,  5.4678e-03,\n",
       "              7.0999e-04,  4.6611e-03],\n",
       "            [-3.1313e-03,  5.6485e-03, -4.8504e-03,  ..., -5.1669e-03,\n",
       "              2.1458e-03, -5.9259e-04],\n",
       "            ...,\n",
       "            [ 3.9132e-03,  3.2766e-03, -6.3644e-03,  ..., -6.9170e-03,\n",
       "             -1.7263e-03,  7.1916e-04],\n",
       "            [-1.6560e-03, -5.7009e-04, -4.6004e-03,  ..., -6.5124e-03,\n",
       "             -5.0945e-04,  2.7705e-03],\n",
       "            [ 4.1461e-03,  1.6841e-04,  6.7729e-03,  ..., -1.4203e-03,\n",
       "             -2.7552e-03,  4.6467e-03]],\n",
       "  \n",
       "           [[ 2.9153e-05,  6.3595e-03,  6.2093e-03,  ..., -9.4478e-04,\n",
       "             -4.5990e-03, -6.1637e-03],\n",
       "            [-2.1772e-03, -4.4131e-03, -1.5816e-03,  ..., -1.3273e-04,\n",
       "              5.7462e-04,  1.2478e-03],\n",
       "            [-6.4016e-03,  4.0933e-03,  4.1003e-03,  ..., -3.1172e-03,\n",
       "              2.9661e-03,  6.6599e-04],\n",
       "            ...,\n",
       "            [ 3.8891e-03,  7.8095e-04, -6.0578e-03,  ..., -7.3516e-04,\n",
       "              4.6789e-03, -1.4746e-03],\n",
       "            [ 4.8952e-03,  5.7245e-03,  1.8497e-03,  ..., -1.3392e-03,\n",
       "             -4.2382e-03, -6.6038e-03],\n",
       "            [-3.0814e-04, -5.2819e-03,  4.6219e-03,  ...,  1.7805e-03,\n",
       "             -4.2604e-03,  8.5543e-04]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 2.4073e-03,  5.7742e-03,  4.7050e-03,  ..., -3.2199e-03,\n",
       "              3.8678e-03,  2.8816e-03],\n",
       "            [-7.7491e-04,  5.1215e-03, -3.9852e-03,  ..., -6.1869e-03,\n",
       "             -3.7067e-03, -1.5021e-03],\n",
       "            [ 3.8443e-03, -4.5162e-04, -6.9717e-03,  ...,  4.6003e-03,\n",
       "              4.9678e-03, -6.6988e-03],\n",
       "            ...,\n",
       "            [ 3.2198e-03,  1.4936e-03,  1.7249e-03,  ..., -4.1526e-03,\n",
       "              6.0118e-03, -4.9800e-04],\n",
       "            [-1.8005e-03, -3.4501e-03, -3.9579e-03,  ..., -2.2193e-03,\n",
       "              8.1493e-04, -5.1123e-03],\n",
       "            [-1.2377e-04,  4.8944e-03, -3.8691e-03,  ...,  6.7922e-03,\n",
       "              6.4013e-03, -1.9746e-03]],\n",
       "  \n",
       "           [[-4.4797e-04, -1.5877e-03, -5.4521e-03,  ..., -2.7915e-04,\n",
       "             -4.7935e-05,  4.6477e-03],\n",
       "            [ 4.0630e-03,  1.9553e-03, -7.0434e-03,  ...,  3.6540e-03,\n",
       "             -4.2579e-03, -1.1782e-03],\n",
       "            [ 7.0277e-03,  1.3347e-05, -3.1157e-03,  ..., -2.0194e-03,\n",
       "              7.8155e-04, -6.1152e-03],\n",
       "            ...,\n",
       "            [ 2.9090e-03,  2.5060e-04,  3.9104e-03,  ..., -1.3772e-03,\n",
       "             -6.2479e-03,  5.7130e-03],\n",
       "            [ 5.1992e-03,  3.4836e-03, -3.7974e-03,  ...,  1.0664e-03,\n",
       "              1.8708e-03, -2.5726e-03],\n",
       "            [-8.4631e-04, -1.6598e-03,  6.8365e-03,  ..., -3.5866e-03,\n",
       "             -7.3580e-04,  1.9358e-03]],\n",
       "  \n",
       "           [[-6.6455e-03, -4.4754e-03,  2.2299e-03,  ...,  1.2256e-03,\n",
       "              5.8097e-03,  4.6268e-03],\n",
       "            [ 1.8263e-03, -6.4964e-03, -6.0581e-04,  ..., -7.0536e-03,\n",
       "              1.4811e-03,  5.9865e-03],\n",
       "            [-4.8290e-03, -4.3404e-03, -6.6384e-03,  ..., -5.7299e-03,\n",
       "              5.4068e-03,  4.0329e-03],\n",
       "            ...,\n",
       "            [ 4.1079e-03, -7.4058e-04,  3.0332e-03,  ...,  1.2451e-04,\n",
       "             -6.3176e-03,  5.1342e-03],\n",
       "            [-3.2038e-03, -6.5515e-03,  5.7876e-03,  ...,  5.3142e-03,\n",
       "             -7.1129e-03,  1.4915e-03],\n",
       "            [-2.6096e-03, -4.2552e-03,  5.4976e-03,  ...,  6.8452e-03,\n",
       "              6.9202e-03,  7.5283e-04]]],\n",
       "  \n",
       "  \n",
       "          [[[ 4.8896e-03, -6.0840e-03,  8.7375e-04,  ...,  3.9381e-03,\n",
       "              4.6589e-03,  6.0627e-05],\n",
       "            [ 2.1306e-03,  4.6194e-04,  6.0165e-05,  ...,  4.7092e-03,\n",
       "             -1.0597e-03, -5.4456e-03],\n",
       "            [ 5.4695e-04, -3.6448e-03, -4.7775e-03,  ...,  6.1724e-04,\n",
       "             -5.5390e-03,  3.8542e-03],\n",
       "            ...,\n",
       "            [-1.7223e-03, -5.6419e-03, -3.2616e-03,  ..., -2.1071e-03,\n",
       "              1.0898e-03,  5.1279e-03],\n",
       "            [ 2.9459e-03, -5.0880e-03,  5.4856e-03,  ...,  4.4828e-03,\n",
       "             -3.1681e-03,  6.7910e-03],\n",
       "            [ 5.3091e-03,  4.6700e-03,  2.5623e-03,  ..., -3.5032e-03,\n",
       "              1.2827e-03, -3.9335e-03]],\n",
       "  \n",
       "           [[ 7.0255e-03, -6.9054e-03,  4.0741e-04,  ..., -3.0708e-03,\n",
       "              1.0373e-03, -4.7636e-03],\n",
       "            [-3.2497e-03,  1.3176e-04,  5.7878e-03,  ..., -2.3595e-03,\n",
       "             -3.7453e-03, -7.1192e-03],\n",
       "            [ 1.1669e-03, -3.8621e-03, -3.1454e-04,  ...,  7.2179e-03,\n",
       "              2.9150e-04, -1.3121e-03],\n",
       "            ...,\n",
       "            [ 4.8277e-03, -2.7884e-04, -6.7876e-03,  ...,  1.0491e-03,\n",
       "             -5.8175e-03, -5.0646e-03],\n",
       "            [-6.6353e-03, -6.4007e-03,  2.5376e-03,  ..., -4.9930e-03,\n",
       "              1.4078e-03, -5.0754e-03],\n",
       "            [-2.8961e-03,  5.6841e-03, -6.4319e-03,  ...,  6.1462e-03,\n",
       "              3.6282e-04,  5.3397e-03]],\n",
       "  \n",
       "           [[ 2.0328e-03,  1.0201e-03,  6.6849e-03,  ..., -7.1728e-03,\n",
       "              4.0534e-03, -3.2097e-03],\n",
       "            [-2.8922e-03,  4.8276e-03, -7.1643e-03,  ...,  3.5144e-03,\n",
       "              3.2111e-04, -2.9233e-03],\n",
       "            [-1.6680e-03,  8.9427e-04,  4.2930e-03,  ...,  6.4291e-03,\n",
       "             -4.5129e-03, -5.9007e-03],\n",
       "            ...,\n",
       "            [-2.1478e-03,  6.4928e-03, -4.4464e-03,  ..., -3.7693e-03,\n",
       "             -7.2602e-03,  7.2844e-03],\n",
       "            [ 4.9135e-03, -5.3159e-03, -5.3700e-03,  ...,  1.9325e-03,\n",
       "             -4.2084e-03,  3.1534e-03],\n",
       "            [-2.0246e-03, -6.0780e-03,  5.3627e-03,  ...,  5.7563e-04,\n",
       "             -4.8053e-03,  4.8175e-03]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-6.7404e-03, -2.9672e-03, -4.8085e-03,  ...,  1.3500e-03,\n",
       "             -1.2822e-03, -4.3055e-03],\n",
       "            [ 1.8335e-04, -2.5085e-03, -5.3098e-03,  ...,  5.8053e-03,\n",
       "             -4.7521e-03,  7.0329e-03],\n",
       "            [-4.3852e-03,  6.8027e-03, -2.9647e-03,  ...,  6.2295e-03,\n",
       "             -9.1629e-04, -3.2044e-05],\n",
       "            ...,\n",
       "            [ 4.5036e-03, -6.9105e-03,  4.4680e-04,  ..., -2.8851e-03,\n",
       "              4.9980e-04,  3.3607e-05],\n",
       "            [ 2.9581e-03, -5.9746e-03,  2.9739e-03,  ..., -5.9464e-03,\n",
       "             -9.2497e-04,  4.3652e-03],\n",
       "            [ 3.0143e-03,  7.0652e-03,  3.5201e-03,  ...,  4.9846e-03,\n",
       "              5.5198e-03, -2.8237e-03]],\n",
       "  \n",
       "           [[ 3.6250e-03, -4.9610e-03, -1.7839e-03,  ..., -4.9297e-03,\n",
       "             -4.4525e-04,  4.6782e-03],\n",
       "            [-7.0912e-03,  6.6678e-04, -9.3900e-04,  ...,  5.0273e-03,\n",
       "              2.1208e-03,  1.8991e-03],\n",
       "            [ 4.0371e-03,  6.2653e-03,  1.6421e-03,  ...,  3.6652e-03,\n",
       "              3.7427e-03,  1.4742e-03],\n",
       "            ...,\n",
       "            [ 7.2271e-03, -3.3101e-03, -7.1012e-03,  ...,  6.5589e-03,\n",
       "             -1.4106e-03, -3.7557e-03],\n",
       "            [-4.0118e-03, -5.3223e-03,  2.0826e-03,  ..., -3.9175e-04,\n",
       "              5.4199e-03,  3.4816e-03],\n",
       "            [ 4.3508e-03, -1.1454e-03,  4.8476e-04,  ..., -3.4863e-03,\n",
       "              1.5868e-04,  6.2446e-03]],\n",
       "  \n",
       "           [[ 5.3892e-03, -5.3258e-03, -2.6092e-03,  ...,  6.3797e-03,\n",
       "             -4.4225e-03,  6.2824e-03],\n",
       "            [-4.7001e-03, -6.1473e-03,  4.1288e-03,  ...,  7.0543e-03,\n",
       "             -5.1494e-03,  4.6504e-03],\n",
       "            [-5.6353e-04, -1.8402e-03,  6.0824e-04,  ..., -6.7437e-03,\n",
       "              5.4749e-03, -6.9439e-03],\n",
       "            ...,\n",
       "            [-6.6298e-03,  2.2434e-03, -4.0342e-03,  ..., -4.1943e-03,\n",
       "             -1.2454e-05,  6.3688e-03],\n",
       "            [-7.2248e-03, -6.8747e-03, -3.7321e-03,  ...,  9.5907e-04,\n",
       "              3.0993e-03, -5.3489e-03],\n",
       "            [ 2.6408e-03,  6.3762e-03,  5.1820e-03,  ...,  5.1732e-03,\n",
       "              9.6721e-04,  4.9630e-03]]]], requires_grad=True)),\n",
       " ('module_dict.1:Conv_Node.model.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 5.8561e-03,  5.1220e-04,  5.6401e-05,  5.4280e-03, -4.1210e-03,\n",
       "           4.6622e-03, -4.7556e-03, -5.7045e-03,  3.1256e-03,  1.1063e-03,\n",
       "           6.0174e-05, -1.8299e-03, -4.8135e-03, -8.7821e-04, -6.7631e-03,\n",
       "          -2.6409e-03, -5.3005e-03,  2.0968e-04,  1.4369e-03, -5.0457e-03,\n",
       "           5.5203e-03,  1.8910e-03, -6.7856e-03,  5.2221e-03, -7.0935e-03,\n",
       "          -1.5505e-03, -1.8168e-03,  2.5645e-04, -3.2049e-03,  2.8659e-03,\n",
       "           3.1511e-03, -1.1317e-03, -6.1721e-03, -3.8615e-03, -6.5673e-03,\n",
       "          -1.0966e-03, -4.7627e-03,  1.3078e-03, -6.5904e-03, -3.1144e-03,\n",
       "          -5.4124e-03,  1.6305e-04, -3.1244e-03, -1.4772e-03,  7.4169e-04,\n",
       "          -5.5397e-03, -7.9457e-04, -4.5743e-03, -7.2665e-03, -2.8118e-03,\n",
       "           4.4095e-03, -1.4522e-03,  4.3752e-04,  7.2237e-03, -6.8571e-03,\n",
       "          -2.7131e-03, -1.6069e-03, -6.8835e-03, -3.8069e-03,  5.6632e-03,\n",
       "          -5.0754e-03, -4.2263e-03,  1.4259e-03,  5.0932e-03, -6.0287e-03,\n",
       "          -3.2995e-03,  1.7034e-06, -1.9298e-04, -2.9391e-03, -5.1436e-03,\n",
       "          -4.4691e-03,  1.7675e-03, -1.2459e-03,  6.9884e-03, -5.6330e-04,\n",
       "           6.9577e-03,  5.3894e-03,  5.4953e-03,  6.7563e-03,  1.2372e-03,\n",
       "          -2.5795e-03,  3.5564e-03, -4.9381e-03, -4.8021e-03, -9.6752e-04,\n",
       "          -5.9689e-03, -2.6278e-03,  6.0852e-03,  5.0032e-04,  2.8022e-03,\n",
       "          -4.9460e-03, -8.2791e-04,  4.4212e-03,  4.0146e-03,  3.9775e-03,\n",
       "           1.2429e-03,  3.6218e-03,  7.0726e-03, -6.6366e-03, -5.9779e-03,\n",
       "          -5.2013e-03, -6.1126e-03, -4.6835e-03, -3.8565e-03, -5.3955e-03,\n",
       "           5.2818e-03, -1.0902e-03, -6.2995e-03,  2.0533e-03, -4.6031e-03,\n",
       "          -6.2285e-03, -3.8851e-03,  1.9771e-03,  3.2005e-03,  6.8034e-03,\n",
       "           6.8740e-03,  1.5078e-03,  5.2665e-03,  6.2523e-05,  1.4737e-03,\n",
       "          -4.3072e-04,  3.3463e-03, -4.0700e-03, -2.1032e-03, -6.0396e-03,\n",
       "           1.2366e-03,  6.3800e-03,  4.5002e-03, -5.8268e-03, -3.9397e-03,\n",
       "          -1.6170e-04,  7.9608e-05,  4.3510e-03, -8.7555e-04, -4.5191e-03,\n",
       "           4.1897e-03,  2.8705e-03, -4.1616e-03,  5.5567e-03,  5.0657e-03,\n",
       "           2.5752e-03, -1.1368e-03,  4.0215e-03, -2.3740e-03,  4.5271e-03,\n",
       "           4.2861e-04,  3.1312e-03,  3.9857e-04, -1.3559e-03, -2.1039e-03,\n",
       "          -1.2390e-03,  1.1333e-03, -3.9976e-03,  5.8062e-03, -1.1439e-03,\n",
       "           1.1808e-03, -6.6683e-03, -3.5243e-03,  3.8571e-03, -7.1525e-03,\n",
       "           4.0383e-03, -2.5557e-03,  1.3935e-03, -1.4641e-03,  1.3598e-03,\n",
       "           5.2433e-03,  5.7435e-06, -4.2861e-03,  3.9240e-03, -4.4833e-03,\n",
       "          -6.5951e-04,  5.9835e-03,  6.6180e-03,  1.6741e-03,  5.8022e-03,\n",
       "          -7.0871e-03,  3.7060e-03, -6.0779e-03,  4.8565e-03, -3.8318e-03,\n",
       "          -3.9517e-03, -1.3061e-04,  4.5294e-03, -5.4275e-03,  4.2298e-04,\n",
       "           6.2509e-03, -1.1298e-03, -1.3873e-03, -1.8382e-03,  7.0672e-03,\n",
       "          -1.7807e-03,  4.1617e-03,  6.1539e-03,  1.6528e-03,  3.2813e-03,\n",
       "           7.2564e-03,  4.9879e-03,  5.4604e-03, -6.7672e-03,  7.3670e-04,\n",
       "           3.8899e-03, -5.5248e-03, -1.9463e-03, -1.5525e-03, -4.8874e-03,\n",
       "           3.7697e-04, -1.3809e-03,  5.4588e-03,  7.0634e-03, -4.4658e-03,\n",
       "          -2.2196e-03, -1.8906e-03, -5.7879e-03,  6.3280e-03,  2.0987e-03,\n",
       "          -3.6001e-03,  5.2663e-03,  6.6650e-04, -4.6161e-03,  1.5254e-03,\n",
       "           1.0560e-03,  3.8688e-03,  3.6420e-03,  7.2652e-03,  1.5355e-03,\n",
       "           4.0691e-03, -3.5626e-03, -3.7951e-03, -5.3630e-03,  1.4014e-03,\n",
       "          -1.1852e-03, -4.0555e-04,  9.9689e-04,  3.4685e-03, -5.3688e-03,\n",
       "           1.4474e-03, -1.0825e-03, -5.9473e-03,  4.8710e-03, -4.3691e-03,\n",
       "          -5.4385e-03,  7.1955e-03,  2.6146e-03,  3.7785e-04, -3.0373e-03,\n",
       "           2.2030e-03,  9.2072e-04,  3.1038e-04, -6.8552e-03,  3.8708e-03,\n",
       "          -5.0665e-03, -4.6118e-03, -3.1749e-03, -7.0925e-03,  1.9502e-04,\n",
       "           1.9101e-03,  7.0324e-03,  2.2177e-04,  4.3739e-03, -2.6691e-03,\n",
       "           6.9921e-03, -5.2391e-03, -5.1850e-03, -6.6279e-03, -6.0789e-03,\n",
       "          -1.1108e-03,  6.6816e-03,  6.8047e-03,  5.1429e-04,  6.7254e-03,\n",
       "           6.9717e-03, -1.8875e-03, -6.7029e-04, -1.3050e-03,  1.8524e-03,\n",
       "           4.7253e-03,  3.1390e-03,  2.6583e-03,  3.4130e-03, -2.0199e-03,\n",
       "           2.0733e-04,  4.9533e-03,  7.2289e-03, -3.7986e-03, -6.0086e-03,\n",
       "           6.2414e-03, -5.9204e-03, -3.3881e-03,  1.8524e-03, -5.3844e-03,\n",
       "          -6.8024e-03,  5.1856e-03,  4.7495e-03,  5.7560e-03, -8.3284e-04,\n",
       "          -3.0946e-03, -4.7661e-03, -4.2929e-03,  5.8527e-03, -3.9772e-03,\n",
       "           6.1462e-03, -4.3943e-04, -4.3365e-03,  5.8853e-03, -2.7891e-03,\n",
       "          -6.3999e-03,  7.2116e-03,  2.4112e-03,  4.7030e-03,  3.5599e-03,\n",
       "          -2.9520e-03, -1.5944e-03,  5.5998e-03, -6.2845e-03,  2.1376e-03,\n",
       "          -1.1881e-03,  5.0180e-03,  4.5941e-04, -1.4693e-03, -3.6845e-03,\n",
       "           3.7469e-03, -5.1065e-03,  4.4837e-04,  7.1832e-04, -1.6842e-03,\n",
       "           4.1582e-03, -1.1556e-03, -2.6701e-03, -3.9644e-03, -1.7508e-03,\n",
       "          -6.8104e-03,  3.8499e-03,  3.4299e-03, -3.8737e-03, -5.8991e-03,\n",
       "          -4.3571e-03, -7.0442e-03,  1.0960e-03,  2.5292e-03,  5.4243e-04,\n",
       "           7.4646e-04,  7.2111e-03,  2.0546e-03, -6.1107e-03, -5.4254e-03,\n",
       "           6.9053e-03,  2.8898e-03,  6.8127e-03, -1.9979e-03,  3.0001e-03,\n",
       "          -3.1458e-04,  6.1746e-03, -1.7433e-03, -4.8004e-04, -5.0893e-03,\n",
       "          -2.2892e-03, -6.4721e-03, -7.0815e-03, -4.3007e-03,  3.2427e-03,\n",
       "           3.0406e-03, -5.4884e-03,  5.4786e-03, -8.6308e-05,  9.6355e-04,\n",
       "           2.1365e-03,  3.8616e-03, -2.9168e-03, -4.6702e-03, -1.2725e-03,\n",
       "          -6.6973e-03, -1.3633e-03,  7.9865e-04,  6.0003e-03, -1.8505e-03,\n",
       "           3.3574e-03,  2.7443e-03, -7.2897e-03, -2.1765e-03,  3.6167e-03,\n",
       "           6.9906e-03, -5.1676e-03, -6.2153e-03,  2.7089e-03,  5.6643e-03,\n",
       "          -6.4032e-03, -5.2714e-03, -7.4602e-04,  7.0104e-03, -1.4726e-03,\n",
       "          -6.5564e-03, -1.5377e-03,  2.3768e-03, -7.1408e-03, -5.2666e-06,\n",
       "          -8.0262e-05, -2.9432e-03, -4.6146e-04, -2.3828e-03,  6.4189e-03,\n",
       "          -6.9057e-03,  4.9389e-03,  5.3057e-03, -1.8448e-03, -5.0066e-03,\n",
       "          -2.3972e-03, -5.5833e-03,  2.3933e-03,  4.2316e-03, -5.8954e-03,\n",
       "           3.4139e-03, -6.5285e-03, -2.0494e-03,  5.9790e-03,  2.7564e-03,\n",
       "           6.6978e-03, -2.7620e-03, -5.8744e-03,  3.1688e-03,  1.2503e-03,\n",
       "           5.1896e-03,  4.0578e-03, -3.7004e-03,  3.9510e-03, -3.5888e-03,\n",
       "          -5.3791e-04,  5.2273e-03,  1.3798e-03,  3.6181e-03,  1.3265e-03,\n",
       "          -6.4198e-03,  4.0570e-03,  1.3672e-03, -4.0179e-03, -6.0474e-03,\n",
       "          -6.7246e-03, -6.3019e-03, -4.0284e-03,  3.3912e-03, -5.0856e-03,\n",
       "           5.8616e-03,  5.9610e-03, -6.3347e-03,  6.2039e-03, -2.2729e-03,\n",
       "          -5.4084e-03,  8.5656e-04, -2.6148e-03, -4.5822e-03, -5.4096e-03,\n",
       "           4.9813e-03, -4.2182e-03,  1.7711e-03,  2.2217e-03,  4.8304e-03,\n",
       "          -4.9346e-03,  2.7555e-03,  7.1165e-03,  5.2638e-03,  7.1250e-03,\n",
       "          -6.5650e-03,  6.0363e-03, -1.4502e-03,  2.3027e-03,  6.2671e-03,\n",
       "           3.3874e-04,  3.6536e-03,  6.1503e-03,  7.6365e-04,  5.9901e-03,\n",
       "          -4.3686e-04, -5.4889e-03, -5.3864e-03, -7.2697e-03,  5.5464e-03,\n",
       "          -1.0529e-03,  5.6652e-03,  4.8346e-03,  7.2811e-03, -7.3617e-04,\n",
       "          -6.3531e-03,  5.0861e-03, -3.6972e-03,  6.3988e-03, -5.1323e-03,\n",
       "          -5.6243e-03, -3.0557e-03, -4.2888e-03,  2.8563e-03,  4.8494e-03,\n",
       "           2.7774e-03,  2.4855e-03,  2.3316e-03, -3.0481e-03, -6.4849e-03,\n",
       "           3.1324e-03,  1.6611e-03, -2.3965e-03, -3.4682e-04, -3.2252e-03,\n",
       "           3.9576e-03,  4.8157e-03,  7.2687e-04, -2.4421e-03, -2.6536e-03,\n",
       "          -8.6359e-04,  8.7834e-04,  1.1110e-03,  1.2173e-03,  6.8714e-03,\n",
       "           8.1320e-04,  4.6528e-03], requires_grad=True)),\n",
       " ('module_dict.1:Conv_Node.model.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n",
       " ('module_dict.1:Conv_Node.model.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n",
       " ('module_dict.-1:Output_Node.model.1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0010,  0.0006, -0.0005,  ..., -0.0005, -0.0011,  0.0017],\n",
       "          [ 0.0008, -0.0014,  0.0004,  ..., -0.0005, -0.0004,  0.0018],\n",
       "          [ 0.0010, -0.0002, -0.0017,  ..., -0.0015, -0.0015, -0.0006],\n",
       "          ...,\n",
       "          [-0.0012,  0.0005,  0.0012,  ...,  0.0003,  0.0015, -0.0016],\n",
       "          [-0.0014,  0.0007,  0.0014,  ..., -0.0018,  0.0009, -0.0002],\n",
       "          [ 0.0010,  0.0017, -0.0004,  ...,  0.0017, -0.0007, -0.0010]],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.-1:Output_Node.model.1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0007, -0.0010,  0.0003,  ..., -0.0017, -0.0017, -0.0002],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.-1:Output_Node.model.4.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0110,  0.0065, -0.0083,  ...,  0.0087, -0.0088,  0.0050],\n",
       "          [-0.0076, -0.0070,  0.0054,  ...,  0.0086,  0.0110, -0.0087],\n",
       "          [ 0.0102,  0.0035,  0.0097,  ..., -0.0010, -0.0092,  0.0113],\n",
       "          ...,\n",
       "          [ 0.0026, -0.0112, -0.0048,  ..., -0.0051,  0.0086,  0.0046],\n",
       "          [-0.0044,  0.0067, -0.0016,  ...,  0.0109, -0.0099, -0.0017],\n",
       "          [ 0.0018,  0.0088,  0.0007,  ..., -0.0006, -0.0031,  0.0094]],\n",
       "         requires_grad=True)),\n",
       " ('module_dict.-1:Output_Node.model.4.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0087, -0.0060,  0.0087, -0.0031,  0.0101,  0.0032,  0.0009,  0.0063,\n",
       "          -0.0029,  0.0084], requires_grad=True))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cont.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\models.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  v = F.softmax(v)\n"
     ]
    }
   ],
   "source": [
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# writer.add_image('images', grid, 0)\n",
    "# writer.add_graph(my_nn, images)\n",
    "cont(images)\n",
    "\n",
    "running_loss = 0.0\n",
    "\n",
    "cont.to(device)\n",
    "optimizer = optim.Adam(cont.parameters(), lr=0.001,)   \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# can add milestones in later if needed\n",
    "# milestones = [k for k in range(0, num_epochs*len(trainloader), 50)]\n",
    "\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "All input tensors must be on the same device. Received cuda:1 and cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-84477f279927>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\genotype.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, node, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                         \u001b[1;31m# print(f'Arrived at {self.node_name()}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, node, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                         \u001b[1;31m# print(f'Arrived at {self.node_name()}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, node, tensor)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m# print(f'Just ran through: {self.node_name()}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidated_processing_stack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidated_processing_stack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch-evo-nn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\OneDrive - UNSW\\University\\Postgraduate\\Year 3 Trimester 2\\COMP9417\\Major Project\\src\\genotype\\nodes.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    457\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;31m# Pad the smaller tensor with zeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: All input tensors must be on the same device. Received cuda:1 and cpu"
     ]
    }
   ],
   "source": [
    "batch_tt = np.empty(shape=(10,))\n",
    "k=0\n",
    "num_epochs = 2\n",
    "start_t = default_timer()\n",
    "for epoch in range(num_epochs-1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        batch_st = default_timer() \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = [d.to(device) for d in data]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cont(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        batch_et = default_timer()\n",
    "        \n",
    "        batch_tt[k] = batch_et - batch_st\n",
    "        \n",
    "        k+=1\n",
    "        \n",
    "        if i % 10 == 9:    # every 10 batches...\n",
    "            \n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 10,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            writer.add_scalar('Learning rate',+\n",
    "                            optimizer.param_groups[0]['lr'],\n",
    "                            epoch * len(trainloader) + i)\n",
    "            writer.add_scalar('Average batch time',\n",
    "                            np.mean(batch_tt).item(),\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            batch_tt = np.empty(shape=(10,))\n",
    "            k=0\n",
    "        \n",
    "\n",
    "\n",
    "end_t = default_timer()\n",
    "\n",
    "total_t = end_t - start_t\n",
    "\n",
    "writer.add_scalar('Total training time',\n",
    "                   total_t,\n",
    "                epoch * len(trainloader) + i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (torch-evo-nn)",
   "language": "python",
   "name": "torch-evo-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
